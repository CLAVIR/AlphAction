2022-04-26 15:47:28,501 alphaction INFO: Using 1 GPUs
2022-04-26 15:47:28,501 alphaction INFO: Namespace(adjust_lr=False, config_file='/root/baseline_zoo/AlphAction/config_files/robalo.yaml', distributed=False, local_rank=0, no_head=True, opts=['SOLVER.BASE_LR', '0.000125', 'SOLVER.STEPS', '(560000, 720000)', 'SOLVER.MAX_ITER', '880000', 'SOLVER.VIDEOS_PER_BATCH', '2', 'TEST.VIDEOS_PER_BATCH', '2'], seed=2, skip_test=False, skip_val=False, tfboard=True, transfer_weight=True)
2022-04-26 15:47:28,501 alphaction INFO: Collecting env info (might take some time)
2022-04-26 15:47:29,268 alphaction INFO: 
PyTorch version: 1.4.0
Is debug build: No
CUDA used to build PyTorch: 10.1

OS: Ubuntu 18.04.6 LTS
GCC version: (Ubuntu 7.5.0-3ubuntu1~18.04) 7.5.0
CMake version: version 3.10.2

Python version: 3.6
Is CUDA available: Yes
CUDA runtime version: 10.1.243
GPU models and configuration: 
GPU 0: NVIDIA GeForce RTX 2080
GPU 1: NVIDIA GeForce RTX 2080 Ti

Nvidia driver version: 510.60.02
cuDNN version: Could not collect

Versions of relevant libraries:
[pip3] numpy==1.19.5
[pip3] torch==1.4.0
[pip3] torchvision==0.5.0
[conda] Could not collect
2022-04-26 15:47:29,269 alphaction INFO: Loaded configuration file /root/baseline_zoo/AlphAction/config_files/robalo.yaml
2022-04-26 15:47:29,269 alphaction INFO: 
MODEL:
  WEIGHT: "data/models/pretrained_models/SlowFast-ResNet50-4x16.pth"
  BACKBONE:
    CONV_BODY: "Slowfast-Resnet50"
    FROZEN_BN: True
    SLOWFAST:
      BETA: 0.125
      LATERAL: "tconv"
      SLOW:
        ACTIVE: True
        CONV3_NONLOCAL: False
        CONV4_NONLOCAL: False
      FAST:
        ACTIVE: True
        CONV3_NONLOCAL: False
        CONV4_NONLOCAL: False
  NONLOCAL:
    USE_ZERO_INIT_CONV: False
    BN_INIT_GAMMA: 0.0
    FROZEN_BN: True
  ROI_ACTION_HEAD:
    FEATURE_EXTRACTOR: "2MLPFeatureExtractor"
    POOLER_TYPE: "align3d"
    MEAN_BEFORE_POOLER: True
    POOLER_RESOLUTION: 7
    POOLER_SCALE: 0.0625
    POOLER_SAMPLING_RATIO: 0
    NUM_CLASSES: 80
    PROPOSAL_PER_CLIP: 10
    DROPOUT_RATE: 0.2
  IA_STRUCTURE:
    ACTIVE: False
INPUT:
  FRAME_NUM: 64
  FRAME_SAMPLE_RATE: 1
  TAU: 16
  ALPHA: 8
  SLOW_JITTER: True
  COLOR_JITTER: True
DATASETS:
  TRAIN: ("lfv_robalo_train_ava_video",)
  TEST: ("lfv_robalo_val_ava_video",)
DATALOADER:
  NUM_WORKERS: 4
  SIZE_DIVISIBILITY: 16
SOLVER:
  BASE_LR: 0.0004
  WARMUP_FACTOR: 0.25
  BIAS_LR_FACTOR: 2
  WEIGHT_DECAY: 1e-7
  STEPS: (50000, 70000)
  WARMUP_ITERS: 2000
  MAX_ITER: 90000
  CHECKPOINT_PERIOD: 100
  EVAL_PERIOD: 100
  VIDEOS_PER_BATCH: 16
TEST:
  BOX_THRESH: 0.8
  ACTION_THRESH: 0.
  VIDEOS_PER_BATCH: 16
OUTPUT_DIR: "data/output/resnet50_4x16f_baseline_robalo"
2022-04-26 15:47:29,269 alphaction INFO: Running with config:
DATALOADER:
  ASPECT_RATIO_GROUPING: True
  NUM_WORKERS: 4
  SIZE_DIVISIBILITY: 16
DATASETS:
  TEST: ('lfv_robalo_val_ava_video',)
  TRAIN: ('lfv_robalo_train_ava_video',)
INPUT:
  ALPHA: 8
  COLOR_JITTER: True
  FRAME_NUM: 64
  FRAME_SAMPLE_RATE: 1
  HUE_JITTER: 20.0
  MAX_SIZE_TEST: 464
  MAX_SIZE_TRAIN: 464
  MIN_SIZE_TEST: 256
  MIN_SIZE_TRAIN: 256
  PIXEL_MEAN: [122.7717, 115.9465, 102.9801]
  PIXEL_STD: [57.375, 57.375, 57.375]
  SAT_JITTER: 0.1
  SLOW_JITTER: True
  TAU: 16
  TO_BGR: False
  VAL_JITTER: 0.1
MODEL:
  BACKBONE:
    BN_EPSILON: 1e-05
    BN_INIT_GAMMA: 0.0
    BN_MOMENTUM: 0.1
    CONV_BODY: Slowfast-Resnet50
    FROZEN_BN: True
    I3D:
      CONV3_GROUP_NL: False
      CONV3_NONLOCAL: True
      CONV4_NONLOCAL: True
    SLOWFAST:
      BETA: 0.125
      FAST:
        ACTIVE: True
        CONV3_GROUP_NL: False
        CONV3_NONLOCAL: False
        CONV4_NONLOCAL: False
      LATERAL: tconv
      SLOW:
        ACTIVE: True
        CONV3_GROUP_NL: False
        CONV3_NONLOCAL: False
        CONV4_NONLOCAL: False
  IA_STRUCTURE:
    ACTIVE: False
    CONV_INIT_STD: 0.01
    DIM_IN: 2304
    DIM_INNER: 512
    DIM_OUT: 512
    DROPOUT: 0.0
    FUSION: concat
    I_BLOCK_LIST: ['P', 'O', 'M', 'P', 'O', 'M']
    LAYER_NORM: False
    LENGTH: (30, 30)
    MAX_OBJECT: 0
    MAX_PERSON: 25
    MAX_PER_SEC: 5
    MEMORY_RATE: 1
    NO_BIAS: False
    PENALTY: True
    ROI_DIM_REDUCE: True
    STRUCTURE: serial
    TEMPORAL_POSITION: True
    USE_ZERO_INIT_CONV: True
  NONLOCAL:
    BN_EPSILON: 1e-05
    BN_INIT_GAMMA: 0.0
    BN_MOMENTUM: 0.1
    CONV_INIT_STD: 0.01
    FROZEN_BN: True
    NO_BIAS: False
    USE_BN: True
    USE_MAXPOOL: True
    USE_SCALE: True
    USE_SOFTMAX: True
    USE_ZERO_INIT_CONV: False
  ROI_ACTION_HEAD:
    DROPOUT_RATE: 0.2
    FEATURE_EXTRACTOR: 2MLPFeatureExtractor
    FOCAL_LOSS:
      ALPHA: -1.0
      GAMMA: 2.0
    MEAN_BEFORE_POOLER: True
    MLP_HEAD_DIM: 1024
    NUM_CLASSES: 80
    NUM_OBJECT_MANIPULATION_CLASSES: 49
    NUM_PERSON_INTERACTION_CLASSES: 17
    NUM_PERSON_MOVEMENT_CLASSES: 14
    OBJECT_LOSS_WEIGHT: 49.0
    PERSON_LOSS_WEIGHT: 17.0
    POOLER_RESOLUTION: 7
    POOLER_SAMPLING_RATIO: 0
    POOLER_SCALE: 0.0625
    POOLER_TYPE: align3d
    POSE_LOSS_WEIGHT: 1.2
    PREDICTOR: FCPredictor
    PROPOSAL_PER_CLIP: 10
  WEIGHT: data/models/pretrained_models/SlowFast-ResNet50-4x16.pth
OUTPUT_DIR: data/output/resnet50_4x16f_baseline_robalo
SOLVER:
  BASE_LR: 0.000125
  BIAS_LR_FACTOR: 2
  CHECKPOINT_PERIOD: 100
  EVAL_PERIOD: 100
  GAMMA: 0.1
  IA_LR_FACTOR: 1.0
  MAX_ITER: 880000
  MOMENTUM: 0.9
  SCHEDULER: warmup_multi_step
  STEPS: (560000, 720000)
  VIDEOS_PER_BATCH: 2
  WARMUP_FACTOR: 0.25
  WARMUP_ITERS: 2000
  WARMUP_METHOD: linear
  WARMUP_ON: True
  WEIGHT_DECAY: 1e-07
  WEIGHT_DECAY_BIAS: 0.0
  WEIGHT_DECAY_BN: 0.0
TEST:
  ACTION_THRESH: 0.0
  BOX_THRESH: 0.8
  EXTEND_SCALE: (0.1, 0.05)
  VIDEOS_PER_BATCH: 2
2022-04-26 15:47:31,424 alphaction.utils.checkpoint INFO: Loading checkpoint from data/output/resnet50_4x16f_baseline_robalo/model_0000100.pth
2022-04-26 15:47:32,043 alphaction.utils.model_serialization INFO: backbone.fast.Tconv1.conv.bias                         loaded from backbone.fast.Tconv1.conv.bias                         of shape (16,)
2022-04-26 15:47:32,043 alphaction.utils.model_serialization INFO: backbone.fast.Tconv1.conv.weight                       loaded from backbone.fast.Tconv1.conv.weight                       of shape (16, 8, 5, 1, 1)
2022-04-26 15:47:32,043 alphaction.utils.model_serialization INFO: backbone.fast.Tconv2.conv.bias                         loaded from backbone.fast.Tconv2.conv.bias                         of shape (64,)
2022-04-26 15:47:32,043 alphaction.utils.model_serialization INFO: backbone.fast.Tconv2.conv.weight                       loaded from backbone.fast.Tconv2.conv.weight                       of shape (64, 32, 5, 1, 1)
2022-04-26 15:47:32,044 alphaction.utils.model_serialization INFO: backbone.fast.Tconv3.conv.bias                         loaded from backbone.fast.Tconv3.conv.bias                         of shape (128,)
2022-04-26 15:47:32,044 alphaction.utils.model_serialization INFO: backbone.fast.Tconv3.conv.weight                       loaded from backbone.fast.Tconv3.conv.weight                       of shape (128, 64, 5, 1, 1)
2022-04-26 15:47:32,044 alphaction.utils.model_serialization INFO: backbone.fast.Tconv4.conv.bias                         loaded from backbone.fast.Tconv4.conv.bias                         of shape (256,)
2022-04-26 15:47:32,044 alphaction.utils.model_serialization INFO: backbone.fast.Tconv4.conv.weight                       loaded from backbone.fast.Tconv4.conv.weight                       of shape (256, 128, 5, 1, 1)
2022-04-26 15:47:32,044 alphaction.utils.model_serialization INFO: backbone.fast.bn1.bias                                 loaded from backbone.fast.bn1.bias                                 of shape (8,)
2022-04-26 15:47:32,044 alphaction.utils.model_serialization INFO: backbone.fast.bn1.running_mean                         loaded from backbone.fast.bn1.running_mean                         of shape (8,)
2022-04-26 15:47:32,044 alphaction.utils.model_serialization INFO: backbone.fast.bn1.running_var                          loaded from backbone.fast.bn1.running_var                          of shape (8,)
2022-04-26 15:47:32,044 alphaction.utils.model_serialization INFO: backbone.fast.bn1.weight                               loaded from backbone.fast.bn1.weight                               of shape (8,)
2022-04-26 15:47:32,044 alphaction.utils.model_serialization INFO: backbone.fast.conv1.weight                             loaded from backbone.fast.conv1.weight                             of shape (8, 3, 5, 7, 7)
2022-04-26 15:47:32,044 alphaction.utils.model_serialization INFO: backbone.fast.res_nl1.res_0.btnk.conv1.bn.bias         loaded from backbone.fast.res_nl1.res_0.btnk.conv1.bn.bias         of shape (8,)
2022-04-26 15:47:32,044 alphaction.utils.model_serialization INFO: backbone.fast.res_nl1.res_0.btnk.conv1.bn.running_mean loaded from backbone.fast.res_nl1.res_0.btnk.conv1.bn.running_mean of shape (8,)
2022-04-26 15:47:32,044 alphaction.utils.model_serialization INFO: backbone.fast.res_nl1.res_0.btnk.conv1.bn.running_var  loaded from backbone.fast.res_nl1.res_0.btnk.conv1.bn.running_var  of shape (8,)
2022-04-26 15:47:32,044 alphaction.utils.model_serialization INFO: backbone.fast.res_nl1.res_0.btnk.conv1.bn.weight       loaded from backbone.fast.res_nl1.res_0.btnk.conv1.bn.weight       of shape (8,)
2022-04-26 15:47:32,044 alphaction.utils.model_serialization INFO: backbone.fast.res_nl1.res_0.btnk.conv1.conv.weight     loaded from backbone.fast.res_nl1.res_0.btnk.conv1.conv.weight     of shape (8, 8, 3, 1, 1)
2022-04-26 15:47:32,044 alphaction.utils.model_serialization INFO: backbone.fast.res_nl1.res_0.btnk.conv2.bn.bias         loaded from backbone.fast.res_nl1.res_0.btnk.conv2.bn.bias         of shape (8,)
2022-04-26 15:47:32,044 alphaction.utils.model_serialization INFO: backbone.fast.res_nl1.res_0.btnk.conv2.bn.running_mean loaded from backbone.fast.res_nl1.res_0.btnk.conv2.bn.running_mean of shape (8,)
2022-04-26 15:47:32,044 alphaction.utils.model_serialization INFO: backbone.fast.res_nl1.res_0.btnk.conv2.bn.running_var  loaded from backbone.fast.res_nl1.res_0.btnk.conv2.bn.running_var  of shape (8,)
2022-04-26 15:47:32,044 alphaction.utils.model_serialization INFO: backbone.fast.res_nl1.res_0.btnk.conv2.bn.weight       loaded from backbone.fast.res_nl1.res_0.btnk.conv2.bn.weight       of shape (8,)
2022-04-26 15:47:32,044 alphaction.utils.model_serialization INFO: backbone.fast.res_nl1.res_0.btnk.conv2.conv.weight     loaded from backbone.fast.res_nl1.res_0.btnk.conv2.conv.weight     of shape (8, 8, 1, 3, 3)
2022-04-26 15:47:32,044 alphaction.utils.model_serialization INFO: backbone.fast.res_nl1.res_0.btnk.conv3.bn.bias         loaded from backbone.fast.res_nl1.res_0.btnk.conv3.bn.bias         of shape (32,)
2022-04-26 15:47:32,044 alphaction.utils.model_serialization INFO: backbone.fast.res_nl1.res_0.btnk.conv3.bn.running_mean loaded from backbone.fast.res_nl1.res_0.btnk.conv3.bn.running_mean of shape (32,)
2022-04-26 15:47:32,044 alphaction.utils.model_serialization INFO: backbone.fast.res_nl1.res_0.btnk.conv3.bn.running_var  loaded from backbone.fast.res_nl1.res_0.btnk.conv3.bn.running_var  of shape (32,)
2022-04-26 15:47:32,044 alphaction.utils.model_serialization INFO: backbone.fast.res_nl1.res_0.btnk.conv3.bn.weight       loaded from backbone.fast.res_nl1.res_0.btnk.conv3.bn.weight       of shape (32,)
2022-04-26 15:47:32,045 alphaction.utils.model_serialization INFO: backbone.fast.res_nl1.res_0.btnk.conv3.conv.weight     loaded from backbone.fast.res_nl1.res_0.btnk.conv3.conv.weight     of shape (32, 8, 1, 1, 1)
2022-04-26 15:47:32,045 alphaction.utils.model_serialization INFO: backbone.fast.res_nl1.res_0.shortcut.bn.bias           loaded from backbone.fast.res_nl1.res_0.shortcut.bn.bias           of shape (32,)
2022-04-26 15:47:32,045 alphaction.utils.model_serialization INFO: backbone.fast.res_nl1.res_0.shortcut.bn.running_mean   loaded from backbone.fast.res_nl1.res_0.shortcut.bn.running_mean   of shape (32,)
2022-04-26 15:47:32,045 alphaction.utils.model_serialization INFO: backbone.fast.res_nl1.res_0.shortcut.bn.running_var    loaded from backbone.fast.res_nl1.res_0.shortcut.bn.running_var    of shape (32,)
2022-04-26 15:47:32,045 alphaction.utils.model_serialization INFO: backbone.fast.res_nl1.res_0.shortcut.bn.weight         loaded from backbone.fast.res_nl1.res_0.shortcut.bn.weight         of shape (32,)
2022-04-26 15:47:32,045 alphaction.utils.model_serialization INFO: backbone.fast.res_nl1.res_0.shortcut.conv.weight       loaded from backbone.fast.res_nl1.res_0.shortcut.conv.weight       of shape (32, 8, 1, 1, 1)
2022-04-26 15:47:32,045 alphaction.utils.model_serialization INFO: backbone.fast.res_nl1.res_1.btnk.conv1.bn.bias         loaded from backbone.fast.res_nl1.res_1.btnk.conv1.bn.bias         of shape (8,)
2022-04-26 15:47:32,045 alphaction.utils.model_serialization INFO: backbone.fast.res_nl1.res_1.btnk.conv1.bn.running_mean loaded from backbone.fast.res_nl1.res_1.btnk.conv1.bn.running_mean of shape (8,)
2022-04-26 15:47:32,045 alphaction.utils.model_serialization INFO: backbone.fast.res_nl1.res_1.btnk.conv1.bn.running_var  loaded from backbone.fast.res_nl1.res_1.btnk.conv1.bn.running_var  of shape (8,)
2022-04-26 15:47:32,045 alphaction.utils.model_serialization INFO: backbone.fast.res_nl1.res_1.btnk.conv1.bn.weight       loaded from backbone.fast.res_nl1.res_1.btnk.conv1.bn.weight       of shape (8,)
2022-04-26 15:47:32,045 alphaction.utils.model_serialization INFO: backbone.fast.res_nl1.res_1.btnk.conv1.conv.weight     loaded from backbone.fast.res_nl1.res_1.btnk.conv1.conv.weight     of shape (8, 32, 3, 1, 1)
2022-04-26 15:47:32,045 alphaction.utils.model_serialization INFO: backbone.fast.res_nl1.res_1.btnk.conv2.bn.bias         loaded from backbone.fast.res_nl1.res_1.btnk.conv2.bn.bias         of shape (8,)
2022-04-26 15:47:32,045 alphaction.utils.model_serialization INFO: backbone.fast.res_nl1.res_1.btnk.conv2.bn.running_mean loaded from backbone.fast.res_nl1.res_1.btnk.conv2.bn.running_mean of shape (8,)
2022-04-26 15:47:32,045 alphaction.utils.model_serialization INFO: backbone.fast.res_nl1.res_1.btnk.conv2.bn.running_var  loaded from backbone.fast.res_nl1.res_1.btnk.conv2.bn.running_var  of shape (8,)
2022-04-26 15:47:32,045 alphaction.utils.model_serialization INFO: backbone.fast.res_nl1.res_1.btnk.conv2.bn.weight       loaded from backbone.fast.res_nl1.res_1.btnk.conv2.bn.weight       of shape (8,)
2022-04-26 15:47:32,045 alphaction.utils.model_serialization INFO: backbone.fast.res_nl1.res_1.btnk.conv2.conv.weight     loaded from backbone.fast.res_nl1.res_1.btnk.conv2.conv.weight     of shape (8, 8, 1, 3, 3)
2022-04-26 15:47:32,045 alphaction.utils.model_serialization INFO: backbone.fast.res_nl1.res_1.btnk.conv3.bn.bias         loaded from backbone.fast.res_nl1.res_1.btnk.conv3.bn.bias         of shape (32,)
2022-04-26 15:47:32,045 alphaction.utils.model_serialization INFO: backbone.fast.res_nl1.res_1.btnk.conv3.bn.running_mean loaded from backbone.fast.res_nl1.res_1.btnk.conv3.bn.running_mean of shape (32,)
2022-04-26 15:47:32,045 alphaction.utils.model_serialization INFO: backbone.fast.res_nl1.res_1.btnk.conv3.bn.running_var  loaded from backbone.fast.res_nl1.res_1.btnk.conv3.bn.running_var  of shape (32,)
2022-04-26 15:47:32,045 alphaction.utils.model_serialization INFO: backbone.fast.res_nl1.res_1.btnk.conv3.bn.weight       loaded from backbone.fast.res_nl1.res_1.btnk.conv3.bn.weight       of shape (32,)
2022-04-26 15:47:32,045 alphaction.utils.model_serialization INFO: backbone.fast.res_nl1.res_1.btnk.conv3.conv.weight     loaded from backbone.fast.res_nl1.res_1.btnk.conv3.conv.weight     of shape (32, 8, 1, 1, 1)
2022-04-26 15:47:32,045 alphaction.utils.model_serialization INFO: backbone.fast.res_nl1.res_2.btnk.conv1.bn.bias         loaded from backbone.fast.res_nl1.res_2.btnk.conv1.bn.bias         of shape (8,)
2022-04-26 15:47:32,045 alphaction.utils.model_serialization INFO: backbone.fast.res_nl1.res_2.btnk.conv1.bn.running_mean loaded from backbone.fast.res_nl1.res_2.btnk.conv1.bn.running_mean of shape (8,)
2022-04-26 15:47:32,045 alphaction.utils.model_serialization INFO: backbone.fast.res_nl1.res_2.btnk.conv1.bn.running_var  loaded from backbone.fast.res_nl1.res_2.btnk.conv1.bn.running_var  of shape (8,)
2022-04-26 15:47:32,046 alphaction.utils.model_serialization INFO: backbone.fast.res_nl1.res_2.btnk.conv1.bn.weight       loaded from backbone.fast.res_nl1.res_2.btnk.conv1.bn.weight       of shape (8,)
2022-04-26 15:47:32,046 alphaction.utils.model_serialization INFO: backbone.fast.res_nl1.res_2.btnk.conv1.conv.weight     loaded from backbone.fast.res_nl1.res_2.btnk.conv1.conv.weight     of shape (8, 32, 3, 1, 1)
2022-04-26 15:47:32,046 alphaction.utils.model_serialization INFO: backbone.fast.res_nl1.res_2.btnk.conv2.bn.bias         loaded from backbone.fast.res_nl1.res_2.btnk.conv2.bn.bias         of shape (8,)
2022-04-26 15:47:32,046 alphaction.utils.model_serialization INFO: backbone.fast.res_nl1.res_2.btnk.conv2.bn.running_mean loaded from backbone.fast.res_nl1.res_2.btnk.conv2.bn.running_mean of shape (8,)
2022-04-26 15:47:32,046 alphaction.utils.model_serialization INFO: backbone.fast.res_nl1.res_2.btnk.conv2.bn.running_var  loaded from backbone.fast.res_nl1.res_2.btnk.conv2.bn.running_var  of shape (8,)
2022-04-26 15:47:32,046 alphaction.utils.model_serialization INFO: backbone.fast.res_nl1.res_2.btnk.conv2.bn.weight       loaded from backbone.fast.res_nl1.res_2.btnk.conv2.bn.weight       of shape (8,)
2022-04-26 15:47:32,046 alphaction.utils.model_serialization INFO: backbone.fast.res_nl1.res_2.btnk.conv2.conv.weight     loaded from backbone.fast.res_nl1.res_2.btnk.conv2.conv.weight     of shape (8, 8, 1, 3, 3)
2022-04-26 15:47:32,046 alphaction.utils.model_serialization INFO: backbone.fast.res_nl1.res_2.btnk.conv3.bn.bias         loaded from backbone.fast.res_nl1.res_2.btnk.conv3.bn.bias         of shape (32,)
2022-04-26 15:47:32,046 alphaction.utils.model_serialization INFO: backbone.fast.res_nl1.res_2.btnk.conv3.bn.running_mean loaded from backbone.fast.res_nl1.res_2.btnk.conv3.bn.running_mean of shape (32,)
2022-04-26 15:47:32,046 alphaction.utils.model_serialization INFO: backbone.fast.res_nl1.res_2.btnk.conv3.bn.running_var  loaded from backbone.fast.res_nl1.res_2.btnk.conv3.bn.running_var  of shape (32,)
2022-04-26 15:47:32,046 alphaction.utils.model_serialization INFO: backbone.fast.res_nl1.res_2.btnk.conv3.bn.weight       loaded from backbone.fast.res_nl1.res_2.btnk.conv3.bn.weight       of shape (32,)
2022-04-26 15:47:32,046 alphaction.utils.model_serialization INFO: backbone.fast.res_nl1.res_2.btnk.conv3.conv.weight     loaded from backbone.fast.res_nl1.res_2.btnk.conv3.conv.weight     of shape (32, 8, 1, 1, 1)
2022-04-26 15:47:32,046 alphaction.utils.model_serialization INFO: backbone.fast.res_nl2.res_0.btnk.conv1.bn.bias         loaded from backbone.fast.res_nl2.res_0.btnk.conv1.bn.bias         of shape (16,)
2022-04-26 15:47:32,046 alphaction.utils.model_serialization INFO: backbone.fast.res_nl2.res_0.btnk.conv1.bn.running_mean loaded from backbone.fast.res_nl2.res_0.btnk.conv1.bn.running_mean of shape (16,)
2022-04-26 15:47:32,046 alphaction.utils.model_serialization INFO: backbone.fast.res_nl2.res_0.btnk.conv1.bn.running_var  loaded from backbone.fast.res_nl2.res_0.btnk.conv1.bn.running_var  of shape (16,)
2022-04-26 15:47:32,046 alphaction.utils.model_serialization INFO: backbone.fast.res_nl2.res_0.btnk.conv1.bn.weight       loaded from backbone.fast.res_nl2.res_0.btnk.conv1.bn.weight       of shape (16,)
2022-04-26 15:47:32,046 alphaction.utils.model_serialization INFO: backbone.fast.res_nl2.res_0.btnk.conv1.conv.weight     loaded from backbone.fast.res_nl2.res_0.btnk.conv1.conv.weight     of shape (16, 32, 3, 1, 1)
2022-04-26 15:47:32,046 alphaction.utils.model_serialization INFO: backbone.fast.res_nl2.res_0.btnk.conv2.bn.bias         loaded from backbone.fast.res_nl2.res_0.btnk.conv2.bn.bias         of shape (16,)
2022-04-26 15:47:32,046 alphaction.utils.model_serialization INFO: backbone.fast.res_nl2.res_0.btnk.conv2.bn.running_mean loaded from backbone.fast.res_nl2.res_0.btnk.conv2.bn.running_mean of shape (16,)
2022-04-26 15:47:32,046 alphaction.utils.model_serialization INFO: backbone.fast.res_nl2.res_0.btnk.conv2.bn.running_var  loaded from backbone.fast.res_nl2.res_0.btnk.conv2.bn.running_var  of shape (16,)
2022-04-26 15:47:32,046 alphaction.utils.model_serialization INFO: backbone.fast.res_nl2.res_0.btnk.conv2.bn.weight       loaded from backbone.fast.res_nl2.res_0.btnk.conv2.bn.weight       of shape (16,)
2022-04-26 15:47:32,046 alphaction.utils.model_serialization INFO: backbone.fast.res_nl2.res_0.btnk.conv2.conv.weight     loaded from backbone.fast.res_nl2.res_0.btnk.conv2.conv.weight     of shape (16, 16, 1, 3, 3)
2022-04-26 15:47:32,046 alphaction.utils.model_serialization INFO: backbone.fast.res_nl2.res_0.btnk.conv3.bn.bias         loaded from backbone.fast.res_nl2.res_0.btnk.conv3.bn.bias         of shape (64,)
2022-04-26 15:47:32,046 alphaction.utils.model_serialization INFO: backbone.fast.res_nl2.res_0.btnk.conv3.bn.running_mean loaded from backbone.fast.res_nl2.res_0.btnk.conv3.bn.running_mean of shape (64,)
2022-04-26 15:47:32,047 alphaction.utils.model_serialization INFO: backbone.fast.res_nl2.res_0.btnk.conv3.bn.running_var  loaded from backbone.fast.res_nl2.res_0.btnk.conv3.bn.running_var  of shape (64,)
2022-04-26 15:47:32,047 alphaction.utils.model_serialization INFO: backbone.fast.res_nl2.res_0.btnk.conv3.bn.weight       loaded from backbone.fast.res_nl2.res_0.btnk.conv3.bn.weight       of shape (64,)
2022-04-26 15:47:32,047 alphaction.utils.model_serialization INFO: backbone.fast.res_nl2.res_0.btnk.conv3.conv.weight     loaded from backbone.fast.res_nl2.res_0.btnk.conv3.conv.weight     of shape (64, 16, 1, 1, 1)
2022-04-26 15:47:32,047 alphaction.utils.model_serialization INFO: backbone.fast.res_nl2.res_0.shortcut.bn.bias           loaded from backbone.fast.res_nl2.res_0.shortcut.bn.bias           of shape (64,)
2022-04-26 15:47:32,047 alphaction.utils.model_serialization INFO: backbone.fast.res_nl2.res_0.shortcut.bn.running_mean   loaded from backbone.fast.res_nl2.res_0.shortcut.bn.running_mean   of shape (64,)
2022-04-26 15:47:32,047 alphaction.utils.model_serialization INFO: backbone.fast.res_nl2.res_0.shortcut.bn.running_var    loaded from backbone.fast.res_nl2.res_0.shortcut.bn.running_var    of shape (64,)
2022-04-26 15:47:32,047 alphaction.utils.model_serialization INFO: backbone.fast.res_nl2.res_0.shortcut.bn.weight         loaded from backbone.fast.res_nl2.res_0.shortcut.bn.weight         of shape (64,)
2022-04-26 15:47:32,047 alphaction.utils.model_serialization INFO: backbone.fast.res_nl2.res_0.shortcut.conv.weight       loaded from backbone.fast.res_nl2.res_0.shortcut.conv.weight       of shape (64, 32, 1, 1, 1)
2022-04-26 15:47:32,047 alphaction.utils.model_serialization INFO: backbone.fast.res_nl2.res_1.btnk.conv1.bn.bias         loaded from backbone.fast.res_nl2.res_1.btnk.conv1.bn.bias         of shape (16,)
2022-04-26 15:47:32,047 alphaction.utils.model_serialization INFO: backbone.fast.res_nl2.res_1.btnk.conv1.bn.running_mean loaded from backbone.fast.res_nl2.res_1.btnk.conv1.bn.running_mean of shape (16,)
2022-04-26 15:47:32,047 alphaction.utils.model_serialization INFO: backbone.fast.res_nl2.res_1.btnk.conv1.bn.running_var  loaded from backbone.fast.res_nl2.res_1.btnk.conv1.bn.running_var  of shape (16,)
2022-04-26 15:47:32,047 alphaction.utils.model_serialization INFO: backbone.fast.res_nl2.res_1.btnk.conv1.bn.weight       loaded from backbone.fast.res_nl2.res_1.btnk.conv1.bn.weight       of shape (16,)
2022-04-26 15:47:32,047 alphaction.utils.model_serialization INFO: backbone.fast.res_nl2.res_1.btnk.conv1.conv.weight     loaded from backbone.fast.res_nl2.res_1.btnk.conv1.conv.weight     of shape (16, 64, 3, 1, 1)
2022-04-26 15:47:32,047 alphaction.utils.model_serialization INFO: backbone.fast.res_nl2.res_1.btnk.conv2.bn.bias         loaded from backbone.fast.res_nl2.res_1.btnk.conv2.bn.bias         of shape (16,)
2022-04-26 15:47:32,047 alphaction.utils.model_serialization INFO: backbone.fast.res_nl2.res_1.btnk.conv2.bn.running_mean loaded from backbone.fast.res_nl2.res_1.btnk.conv2.bn.running_mean of shape (16,)
2022-04-26 15:47:32,047 alphaction.utils.model_serialization INFO: backbone.fast.res_nl2.res_1.btnk.conv2.bn.running_var  loaded from backbone.fast.res_nl2.res_1.btnk.conv2.bn.running_var  of shape (16,)
2022-04-26 15:47:32,047 alphaction.utils.model_serialization INFO: backbone.fast.res_nl2.res_1.btnk.conv2.bn.weight       loaded from backbone.fast.res_nl2.res_1.btnk.conv2.bn.weight       of shape (16,)
2022-04-26 15:47:32,047 alphaction.utils.model_serialization INFO: backbone.fast.res_nl2.res_1.btnk.conv2.conv.weight     loaded from backbone.fast.res_nl2.res_1.btnk.conv2.conv.weight     of shape (16, 16, 1, 3, 3)
2022-04-26 15:47:32,047 alphaction.utils.model_serialization INFO: backbone.fast.res_nl2.res_1.btnk.conv3.bn.bias         loaded from backbone.fast.res_nl2.res_1.btnk.conv3.bn.bias         of shape (64,)
2022-04-26 15:47:32,047 alphaction.utils.model_serialization INFO: backbone.fast.res_nl2.res_1.btnk.conv3.bn.running_mean loaded from backbone.fast.res_nl2.res_1.btnk.conv3.bn.running_mean of shape (64,)
2022-04-26 15:47:32,047 alphaction.utils.model_serialization INFO: backbone.fast.res_nl2.res_1.btnk.conv3.bn.running_var  loaded from backbone.fast.res_nl2.res_1.btnk.conv3.bn.running_var  of shape (64,)
2022-04-26 15:47:32,047 alphaction.utils.model_serialization INFO: backbone.fast.res_nl2.res_1.btnk.conv3.bn.weight       loaded from backbone.fast.res_nl2.res_1.btnk.conv3.bn.weight       of shape (64,)
2022-04-26 15:47:32,047 alphaction.utils.model_serialization INFO: backbone.fast.res_nl2.res_1.btnk.conv3.conv.weight     loaded from backbone.fast.res_nl2.res_1.btnk.conv3.conv.weight     of shape (64, 16, 1, 1, 1)
2022-04-26 15:47:32,047 alphaction.utils.model_serialization INFO: backbone.fast.res_nl2.res_2.btnk.conv1.bn.bias         loaded from backbone.fast.res_nl2.res_2.btnk.conv1.bn.bias         of shape (16,)
2022-04-26 15:47:32,048 alphaction.utils.model_serialization INFO: backbone.fast.res_nl2.res_2.btnk.conv1.bn.running_mean loaded from backbone.fast.res_nl2.res_2.btnk.conv1.bn.running_mean of shape (16,)
2022-04-26 15:47:32,048 alphaction.utils.model_serialization INFO: backbone.fast.res_nl2.res_2.btnk.conv1.bn.running_var  loaded from backbone.fast.res_nl2.res_2.btnk.conv1.bn.running_var  of shape (16,)
2022-04-26 15:47:32,048 alphaction.utils.model_serialization INFO: backbone.fast.res_nl2.res_2.btnk.conv1.bn.weight       loaded from backbone.fast.res_nl2.res_2.btnk.conv1.bn.weight       of shape (16,)
2022-04-26 15:47:32,048 alphaction.utils.model_serialization INFO: backbone.fast.res_nl2.res_2.btnk.conv1.conv.weight     loaded from backbone.fast.res_nl2.res_2.btnk.conv1.conv.weight     of shape (16, 64, 3, 1, 1)
2022-04-26 15:47:32,048 alphaction.utils.model_serialization INFO: backbone.fast.res_nl2.res_2.btnk.conv2.bn.bias         loaded from backbone.fast.res_nl2.res_2.btnk.conv2.bn.bias         of shape (16,)
2022-04-26 15:47:32,048 alphaction.utils.model_serialization INFO: backbone.fast.res_nl2.res_2.btnk.conv2.bn.running_mean loaded from backbone.fast.res_nl2.res_2.btnk.conv2.bn.running_mean of shape (16,)
2022-04-26 15:47:32,048 alphaction.utils.model_serialization INFO: backbone.fast.res_nl2.res_2.btnk.conv2.bn.running_var  loaded from backbone.fast.res_nl2.res_2.btnk.conv2.bn.running_var  of shape (16,)
2022-04-26 15:47:32,048 alphaction.utils.model_serialization INFO: backbone.fast.res_nl2.res_2.btnk.conv2.bn.weight       loaded from backbone.fast.res_nl2.res_2.btnk.conv2.bn.weight       of shape (16,)
2022-04-26 15:47:32,048 alphaction.utils.model_serialization INFO: backbone.fast.res_nl2.res_2.btnk.conv2.conv.weight     loaded from backbone.fast.res_nl2.res_2.btnk.conv2.conv.weight     of shape (16, 16, 1, 3, 3)
2022-04-26 15:47:32,048 alphaction.utils.model_serialization INFO: backbone.fast.res_nl2.res_2.btnk.conv3.bn.bias         loaded from backbone.fast.res_nl2.res_2.btnk.conv3.bn.bias         of shape (64,)
2022-04-26 15:47:32,048 alphaction.utils.model_serialization INFO: backbone.fast.res_nl2.res_2.btnk.conv3.bn.running_mean loaded from backbone.fast.res_nl2.res_2.btnk.conv3.bn.running_mean of shape (64,)
2022-04-26 15:47:32,048 alphaction.utils.model_serialization INFO: backbone.fast.res_nl2.res_2.btnk.conv3.bn.running_var  loaded from backbone.fast.res_nl2.res_2.btnk.conv3.bn.running_var  of shape (64,)
2022-04-26 15:47:32,048 alphaction.utils.model_serialization INFO: backbone.fast.res_nl2.res_2.btnk.conv3.bn.weight       loaded from backbone.fast.res_nl2.res_2.btnk.conv3.bn.weight       of shape (64,)
2022-04-26 15:47:32,048 alphaction.utils.model_serialization INFO: backbone.fast.res_nl2.res_2.btnk.conv3.conv.weight     loaded from backbone.fast.res_nl2.res_2.btnk.conv3.conv.weight     of shape (64, 16, 1, 1, 1)
2022-04-26 15:47:32,048 alphaction.utils.model_serialization INFO: backbone.fast.res_nl2.res_3.btnk.conv1.bn.bias         loaded from backbone.fast.res_nl2.res_3.btnk.conv1.bn.bias         of shape (16,)
2022-04-26 15:47:32,048 alphaction.utils.model_serialization INFO: backbone.fast.res_nl2.res_3.btnk.conv1.bn.running_mean loaded from backbone.fast.res_nl2.res_3.btnk.conv1.bn.running_mean of shape (16,)
2022-04-26 15:47:32,048 alphaction.utils.model_serialization INFO: backbone.fast.res_nl2.res_3.btnk.conv1.bn.running_var  loaded from backbone.fast.res_nl2.res_3.btnk.conv1.bn.running_var  of shape (16,)
2022-04-26 15:47:32,048 alphaction.utils.model_serialization INFO: backbone.fast.res_nl2.res_3.btnk.conv1.bn.weight       loaded from backbone.fast.res_nl2.res_3.btnk.conv1.bn.weight       of shape (16,)
2022-04-26 15:47:32,048 alphaction.utils.model_serialization INFO: backbone.fast.res_nl2.res_3.btnk.conv1.conv.weight     loaded from backbone.fast.res_nl2.res_3.btnk.conv1.conv.weight     of shape (16, 64, 3, 1, 1)
2022-04-26 15:47:32,048 alphaction.utils.model_serialization INFO: backbone.fast.res_nl2.res_3.btnk.conv2.bn.bias         loaded from backbone.fast.res_nl2.res_3.btnk.conv2.bn.bias         of shape (16,)
2022-04-26 15:47:32,048 alphaction.utils.model_serialization INFO: backbone.fast.res_nl2.res_3.btnk.conv2.bn.running_mean loaded from backbone.fast.res_nl2.res_3.btnk.conv2.bn.running_mean of shape (16,)
2022-04-26 15:47:32,048 alphaction.utils.model_serialization INFO: backbone.fast.res_nl2.res_3.btnk.conv2.bn.running_var  loaded from backbone.fast.res_nl2.res_3.btnk.conv2.bn.running_var  of shape (16,)
2022-04-26 15:47:32,048 alphaction.utils.model_serialization INFO: backbone.fast.res_nl2.res_3.btnk.conv2.bn.weight       loaded from backbone.fast.res_nl2.res_3.btnk.conv2.bn.weight       of shape (16,)
2022-04-26 15:47:32,048 alphaction.utils.model_serialization INFO: backbone.fast.res_nl2.res_3.btnk.conv2.conv.weight     loaded from backbone.fast.res_nl2.res_3.btnk.conv2.conv.weight     of shape (16, 16, 1, 3, 3)
2022-04-26 15:47:32,049 alphaction.utils.model_serialization INFO: backbone.fast.res_nl2.res_3.btnk.conv3.bn.bias         loaded from backbone.fast.res_nl2.res_3.btnk.conv3.bn.bias         of shape (64,)
2022-04-26 15:47:32,049 alphaction.utils.model_serialization INFO: backbone.fast.res_nl2.res_3.btnk.conv3.bn.running_mean loaded from backbone.fast.res_nl2.res_3.btnk.conv3.bn.running_mean of shape (64,)
2022-04-26 15:47:32,049 alphaction.utils.model_serialization INFO: backbone.fast.res_nl2.res_3.btnk.conv3.bn.running_var  loaded from backbone.fast.res_nl2.res_3.btnk.conv3.bn.running_var  of shape (64,)
2022-04-26 15:47:32,049 alphaction.utils.model_serialization INFO: backbone.fast.res_nl2.res_3.btnk.conv3.bn.weight       loaded from backbone.fast.res_nl2.res_3.btnk.conv3.bn.weight       of shape (64,)
2022-04-26 15:47:32,049 alphaction.utils.model_serialization INFO: backbone.fast.res_nl2.res_3.btnk.conv3.conv.weight     loaded from backbone.fast.res_nl2.res_3.btnk.conv3.conv.weight     of shape (64, 16, 1, 1, 1)
2022-04-26 15:47:32,049 alphaction.utils.model_serialization INFO: backbone.fast.res_nl3.res_0.btnk.conv1.bn.bias         loaded from backbone.fast.res_nl3.res_0.btnk.conv1.bn.bias         of shape (32,)
2022-04-26 15:47:32,049 alphaction.utils.model_serialization INFO: backbone.fast.res_nl3.res_0.btnk.conv1.bn.running_mean loaded from backbone.fast.res_nl3.res_0.btnk.conv1.bn.running_mean of shape (32,)
2022-04-26 15:47:32,049 alphaction.utils.model_serialization INFO: backbone.fast.res_nl3.res_0.btnk.conv1.bn.running_var  loaded from backbone.fast.res_nl3.res_0.btnk.conv1.bn.running_var  of shape (32,)
2022-04-26 15:47:32,049 alphaction.utils.model_serialization INFO: backbone.fast.res_nl3.res_0.btnk.conv1.bn.weight       loaded from backbone.fast.res_nl3.res_0.btnk.conv1.bn.weight       of shape (32,)
2022-04-26 15:47:32,049 alphaction.utils.model_serialization INFO: backbone.fast.res_nl3.res_0.btnk.conv1.conv.weight     loaded from backbone.fast.res_nl3.res_0.btnk.conv1.conv.weight     of shape (32, 64, 3, 1, 1)
2022-04-26 15:47:32,049 alphaction.utils.model_serialization INFO: backbone.fast.res_nl3.res_0.btnk.conv2.bn.bias         loaded from backbone.fast.res_nl3.res_0.btnk.conv2.bn.bias         of shape (32,)
2022-04-26 15:47:32,049 alphaction.utils.model_serialization INFO: backbone.fast.res_nl3.res_0.btnk.conv2.bn.running_mean loaded from backbone.fast.res_nl3.res_0.btnk.conv2.bn.running_mean of shape (32,)
2022-04-26 15:47:32,049 alphaction.utils.model_serialization INFO: backbone.fast.res_nl3.res_0.btnk.conv2.bn.running_var  loaded from backbone.fast.res_nl3.res_0.btnk.conv2.bn.running_var  of shape (32,)
2022-04-26 15:47:32,049 alphaction.utils.model_serialization INFO: backbone.fast.res_nl3.res_0.btnk.conv2.bn.weight       loaded from backbone.fast.res_nl3.res_0.btnk.conv2.bn.weight       of shape (32,)
2022-04-26 15:47:32,049 alphaction.utils.model_serialization INFO: backbone.fast.res_nl3.res_0.btnk.conv2.conv.weight     loaded from backbone.fast.res_nl3.res_0.btnk.conv2.conv.weight     of shape (32, 32, 1, 3, 3)
2022-04-26 15:47:32,049 alphaction.utils.model_serialization INFO: backbone.fast.res_nl3.res_0.btnk.conv3.bn.bias         loaded from backbone.fast.res_nl3.res_0.btnk.conv3.bn.bias         of shape (128,)
2022-04-26 15:47:32,049 alphaction.utils.model_serialization INFO: backbone.fast.res_nl3.res_0.btnk.conv3.bn.running_mean loaded from backbone.fast.res_nl3.res_0.btnk.conv3.bn.running_mean of shape (128,)
2022-04-26 15:47:32,049 alphaction.utils.model_serialization INFO: backbone.fast.res_nl3.res_0.btnk.conv3.bn.running_var  loaded from backbone.fast.res_nl3.res_0.btnk.conv3.bn.running_var  of shape (128,)
2022-04-26 15:47:32,049 alphaction.utils.model_serialization INFO: backbone.fast.res_nl3.res_0.btnk.conv3.bn.weight       loaded from backbone.fast.res_nl3.res_0.btnk.conv3.bn.weight       of shape (128,)
2022-04-26 15:47:32,049 alphaction.utils.model_serialization INFO: backbone.fast.res_nl3.res_0.btnk.conv3.conv.weight     loaded from backbone.fast.res_nl3.res_0.btnk.conv3.conv.weight     of shape (128, 32, 1, 1, 1)
2022-04-26 15:47:32,049 alphaction.utils.model_serialization INFO: backbone.fast.res_nl3.res_0.shortcut.bn.bias           loaded from backbone.fast.res_nl3.res_0.shortcut.bn.bias           of shape (128,)
2022-04-26 15:47:32,049 alphaction.utils.model_serialization INFO: backbone.fast.res_nl3.res_0.shortcut.bn.running_mean   loaded from backbone.fast.res_nl3.res_0.shortcut.bn.running_mean   of shape (128,)
2022-04-26 15:47:32,049 alphaction.utils.model_serialization INFO: backbone.fast.res_nl3.res_0.shortcut.bn.running_var    loaded from backbone.fast.res_nl3.res_0.shortcut.bn.running_var    of shape (128,)
2022-04-26 15:47:32,049 alphaction.utils.model_serialization INFO: backbone.fast.res_nl3.res_0.shortcut.bn.weight         loaded from backbone.fast.res_nl3.res_0.shortcut.bn.weight         of shape (128,)
2022-04-26 15:47:32,050 alphaction.utils.model_serialization INFO: backbone.fast.res_nl3.res_0.shortcut.conv.weight       loaded from backbone.fast.res_nl3.res_0.shortcut.conv.weight       of shape (128, 64, 1, 1, 1)
2022-04-26 15:47:32,050 alphaction.utils.model_serialization INFO: backbone.fast.res_nl3.res_1.btnk.conv1.bn.bias         loaded from backbone.fast.res_nl3.res_1.btnk.conv1.bn.bias         of shape (32,)
2022-04-26 15:47:32,050 alphaction.utils.model_serialization INFO: backbone.fast.res_nl3.res_1.btnk.conv1.bn.running_mean loaded from backbone.fast.res_nl3.res_1.btnk.conv1.bn.running_mean of shape (32,)
2022-04-26 15:47:32,050 alphaction.utils.model_serialization INFO: backbone.fast.res_nl3.res_1.btnk.conv1.bn.running_var  loaded from backbone.fast.res_nl3.res_1.btnk.conv1.bn.running_var  of shape (32,)
2022-04-26 15:47:32,050 alphaction.utils.model_serialization INFO: backbone.fast.res_nl3.res_1.btnk.conv1.bn.weight       loaded from backbone.fast.res_nl3.res_1.btnk.conv1.bn.weight       of shape (32,)
2022-04-26 15:47:32,050 alphaction.utils.model_serialization INFO: backbone.fast.res_nl3.res_1.btnk.conv1.conv.weight     loaded from backbone.fast.res_nl3.res_1.btnk.conv1.conv.weight     of shape (32, 128, 3, 1, 1)
2022-04-26 15:47:32,050 alphaction.utils.model_serialization INFO: backbone.fast.res_nl3.res_1.btnk.conv2.bn.bias         loaded from backbone.fast.res_nl3.res_1.btnk.conv2.bn.bias         of shape (32,)
2022-04-26 15:47:32,050 alphaction.utils.model_serialization INFO: backbone.fast.res_nl3.res_1.btnk.conv2.bn.running_mean loaded from backbone.fast.res_nl3.res_1.btnk.conv2.bn.running_mean of shape (32,)
2022-04-26 15:47:32,050 alphaction.utils.model_serialization INFO: backbone.fast.res_nl3.res_1.btnk.conv2.bn.running_var  loaded from backbone.fast.res_nl3.res_1.btnk.conv2.bn.running_var  of shape (32,)
2022-04-26 15:47:32,050 alphaction.utils.model_serialization INFO: backbone.fast.res_nl3.res_1.btnk.conv2.bn.weight       loaded from backbone.fast.res_nl3.res_1.btnk.conv2.bn.weight       of shape (32,)
2022-04-26 15:47:32,050 alphaction.utils.model_serialization INFO: backbone.fast.res_nl3.res_1.btnk.conv2.conv.weight     loaded from backbone.fast.res_nl3.res_1.btnk.conv2.conv.weight     of shape (32, 32, 1, 3, 3)
2022-04-26 15:47:32,050 alphaction.utils.model_serialization INFO: backbone.fast.res_nl3.res_1.btnk.conv3.bn.bias         loaded from backbone.fast.res_nl3.res_1.btnk.conv3.bn.bias         of shape (128,)
2022-04-26 15:47:32,050 alphaction.utils.model_serialization INFO: backbone.fast.res_nl3.res_1.btnk.conv3.bn.running_mean loaded from backbone.fast.res_nl3.res_1.btnk.conv3.bn.running_mean of shape (128,)
2022-04-26 15:47:32,050 alphaction.utils.model_serialization INFO: backbone.fast.res_nl3.res_1.btnk.conv3.bn.running_var  loaded from backbone.fast.res_nl3.res_1.btnk.conv3.bn.running_var  of shape (128,)
2022-04-26 15:47:32,050 alphaction.utils.model_serialization INFO: backbone.fast.res_nl3.res_1.btnk.conv3.bn.weight       loaded from backbone.fast.res_nl3.res_1.btnk.conv3.bn.weight       of shape (128,)
2022-04-26 15:47:32,050 alphaction.utils.model_serialization INFO: backbone.fast.res_nl3.res_1.btnk.conv3.conv.weight     loaded from backbone.fast.res_nl3.res_1.btnk.conv3.conv.weight     of shape (128, 32, 1, 1, 1)
2022-04-26 15:47:32,050 alphaction.utils.model_serialization INFO: backbone.fast.res_nl3.res_2.btnk.conv1.bn.bias         loaded from backbone.fast.res_nl3.res_2.btnk.conv1.bn.bias         of shape (32,)
2022-04-26 15:47:32,050 alphaction.utils.model_serialization INFO: backbone.fast.res_nl3.res_2.btnk.conv1.bn.running_mean loaded from backbone.fast.res_nl3.res_2.btnk.conv1.bn.running_mean of shape (32,)
2022-04-26 15:47:32,050 alphaction.utils.model_serialization INFO: backbone.fast.res_nl3.res_2.btnk.conv1.bn.running_var  loaded from backbone.fast.res_nl3.res_2.btnk.conv1.bn.running_var  of shape (32,)
2022-04-26 15:47:32,050 alphaction.utils.model_serialization INFO: backbone.fast.res_nl3.res_2.btnk.conv1.bn.weight       loaded from backbone.fast.res_nl3.res_2.btnk.conv1.bn.weight       of shape (32,)
2022-04-26 15:47:32,050 alphaction.utils.model_serialization INFO: backbone.fast.res_nl3.res_2.btnk.conv1.conv.weight     loaded from backbone.fast.res_nl3.res_2.btnk.conv1.conv.weight     of shape (32, 128, 3, 1, 1)
2022-04-26 15:47:32,050 alphaction.utils.model_serialization INFO: backbone.fast.res_nl3.res_2.btnk.conv2.bn.bias         loaded from backbone.fast.res_nl3.res_2.btnk.conv2.bn.bias         of shape (32,)
2022-04-26 15:47:32,050 alphaction.utils.model_serialization INFO: backbone.fast.res_nl3.res_2.btnk.conv2.bn.running_mean loaded from backbone.fast.res_nl3.res_2.btnk.conv2.bn.running_mean of shape (32,)
2022-04-26 15:47:32,051 alphaction.utils.model_serialization INFO: backbone.fast.res_nl3.res_2.btnk.conv2.bn.running_var  loaded from backbone.fast.res_nl3.res_2.btnk.conv2.bn.running_var  of shape (32,)
2022-04-26 15:47:32,051 alphaction.utils.model_serialization INFO: backbone.fast.res_nl3.res_2.btnk.conv2.bn.weight       loaded from backbone.fast.res_nl3.res_2.btnk.conv2.bn.weight       of shape (32,)
2022-04-26 15:47:32,051 alphaction.utils.model_serialization INFO: backbone.fast.res_nl3.res_2.btnk.conv2.conv.weight     loaded from backbone.fast.res_nl3.res_2.btnk.conv2.conv.weight     of shape (32, 32, 1, 3, 3)
2022-04-26 15:47:32,051 alphaction.utils.model_serialization INFO: backbone.fast.res_nl3.res_2.btnk.conv3.bn.bias         loaded from backbone.fast.res_nl3.res_2.btnk.conv3.bn.bias         of shape (128,)
2022-04-26 15:47:32,051 alphaction.utils.model_serialization INFO: backbone.fast.res_nl3.res_2.btnk.conv3.bn.running_mean loaded from backbone.fast.res_nl3.res_2.btnk.conv3.bn.running_mean of shape (128,)
2022-04-26 15:47:32,051 alphaction.utils.model_serialization INFO: backbone.fast.res_nl3.res_2.btnk.conv3.bn.running_var  loaded from backbone.fast.res_nl3.res_2.btnk.conv3.bn.running_var  of shape (128,)
2022-04-26 15:47:32,051 alphaction.utils.model_serialization INFO: backbone.fast.res_nl3.res_2.btnk.conv3.bn.weight       loaded from backbone.fast.res_nl3.res_2.btnk.conv3.bn.weight       of shape (128,)
2022-04-26 15:47:32,051 alphaction.utils.model_serialization INFO: backbone.fast.res_nl3.res_2.btnk.conv3.conv.weight     loaded from backbone.fast.res_nl3.res_2.btnk.conv3.conv.weight     of shape (128, 32, 1, 1, 1)
2022-04-26 15:47:32,051 alphaction.utils.model_serialization INFO: backbone.fast.res_nl3.res_3.btnk.conv1.bn.bias         loaded from backbone.fast.res_nl3.res_3.btnk.conv1.bn.bias         of shape (32,)
2022-04-26 15:47:32,051 alphaction.utils.model_serialization INFO: backbone.fast.res_nl3.res_3.btnk.conv1.bn.running_mean loaded from backbone.fast.res_nl3.res_3.btnk.conv1.bn.running_mean of shape (32,)
2022-04-26 15:47:32,051 alphaction.utils.model_serialization INFO: backbone.fast.res_nl3.res_3.btnk.conv1.bn.running_var  loaded from backbone.fast.res_nl3.res_3.btnk.conv1.bn.running_var  of shape (32,)
2022-04-26 15:47:32,051 alphaction.utils.model_serialization INFO: backbone.fast.res_nl3.res_3.btnk.conv1.bn.weight       loaded from backbone.fast.res_nl3.res_3.btnk.conv1.bn.weight       of shape (32,)
2022-04-26 15:47:32,051 alphaction.utils.model_serialization INFO: backbone.fast.res_nl3.res_3.btnk.conv1.conv.weight     loaded from backbone.fast.res_nl3.res_3.btnk.conv1.conv.weight     of shape (32, 128, 3, 1, 1)
2022-04-26 15:47:32,051 alphaction.utils.model_serialization INFO: backbone.fast.res_nl3.res_3.btnk.conv2.bn.bias         loaded from backbone.fast.res_nl3.res_3.btnk.conv2.bn.bias         of shape (32,)
2022-04-26 15:47:32,051 alphaction.utils.model_serialization INFO: backbone.fast.res_nl3.res_3.btnk.conv2.bn.running_mean loaded from backbone.fast.res_nl3.res_3.btnk.conv2.bn.running_mean of shape (32,)
2022-04-26 15:47:32,051 alphaction.utils.model_serialization INFO: backbone.fast.res_nl3.res_3.btnk.conv2.bn.running_var  loaded from backbone.fast.res_nl3.res_3.btnk.conv2.bn.running_var  of shape (32,)
2022-04-26 15:47:32,051 alphaction.utils.model_serialization INFO: backbone.fast.res_nl3.res_3.btnk.conv2.bn.weight       loaded from backbone.fast.res_nl3.res_3.btnk.conv2.bn.weight       of shape (32,)
2022-04-26 15:47:32,051 alphaction.utils.model_serialization INFO: backbone.fast.res_nl3.res_3.btnk.conv2.conv.weight     loaded from backbone.fast.res_nl3.res_3.btnk.conv2.conv.weight     of shape (32, 32, 1, 3, 3)
2022-04-26 15:47:32,051 alphaction.utils.model_serialization INFO: backbone.fast.res_nl3.res_3.btnk.conv3.bn.bias         loaded from backbone.fast.res_nl3.res_3.btnk.conv3.bn.bias         of shape (128,)
2022-04-26 15:47:32,051 alphaction.utils.model_serialization INFO: backbone.fast.res_nl3.res_3.btnk.conv3.bn.running_mean loaded from backbone.fast.res_nl3.res_3.btnk.conv3.bn.running_mean of shape (128,)
2022-04-26 15:47:32,051 alphaction.utils.model_serialization INFO: backbone.fast.res_nl3.res_3.btnk.conv3.bn.running_var  loaded from backbone.fast.res_nl3.res_3.btnk.conv3.bn.running_var  of shape (128,)
2022-04-26 15:47:32,051 alphaction.utils.model_serialization INFO: backbone.fast.res_nl3.res_3.btnk.conv3.bn.weight       loaded from backbone.fast.res_nl3.res_3.btnk.conv3.bn.weight       of shape (128,)
2022-04-26 15:47:32,051 alphaction.utils.model_serialization INFO: backbone.fast.res_nl3.res_3.btnk.conv3.conv.weight     loaded from backbone.fast.res_nl3.res_3.btnk.conv3.conv.weight     of shape (128, 32, 1, 1, 1)
2022-04-26 15:47:32,051 alphaction.utils.model_serialization INFO: backbone.fast.res_nl3.res_4.btnk.conv1.bn.bias         loaded from backbone.fast.res_nl3.res_4.btnk.conv1.bn.bias         of shape (32,)
2022-04-26 15:47:32,052 alphaction.utils.model_serialization INFO: backbone.fast.res_nl3.res_4.btnk.conv1.bn.running_mean loaded from backbone.fast.res_nl3.res_4.btnk.conv1.bn.running_mean of shape (32,)
2022-04-26 15:47:32,052 alphaction.utils.model_serialization INFO: backbone.fast.res_nl3.res_4.btnk.conv1.bn.running_var  loaded from backbone.fast.res_nl3.res_4.btnk.conv1.bn.running_var  of shape (32,)
2022-04-26 15:47:32,052 alphaction.utils.model_serialization INFO: backbone.fast.res_nl3.res_4.btnk.conv1.bn.weight       loaded from backbone.fast.res_nl3.res_4.btnk.conv1.bn.weight       of shape (32,)
2022-04-26 15:47:32,052 alphaction.utils.model_serialization INFO: backbone.fast.res_nl3.res_4.btnk.conv1.conv.weight     loaded from backbone.fast.res_nl3.res_4.btnk.conv1.conv.weight     of shape (32, 128, 3, 1, 1)
2022-04-26 15:47:32,052 alphaction.utils.model_serialization INFO: backbone.fast.res_nl3.res_4.btnk.conv2.bn.bias         loaded from backbone.fast.res_nl3.res_4.btnk.conv2.bn.bias         of shape (32,)
2022-04-26 15:47:32,052 alphaction.utils.model_serialization INFO: backbone.fast.res_nl3.res_4.btnk.conv2.bn.running_mean loaded from backbone.fast.res_nl3.res_4.btnk.conv2.bn.running_mean of shape (32,)
2022-04-26 15:47:32,052 alphaction.utils.model_serialization INFO: backbone.fast.res_nl3.res_4.btnk.conv2.bn.running_var  loaded from backbone.fast.res_nl3.res_4.btnk.conv2.bn.running_var  of shape (32,)
2022-04-26 15:47:32,052 alphaction.utils.model_serialization INFO: backbone.fast.res_nl3.res_4.btnk.conv2.bn.weight       loaded from backbone.fast.res_nl3.res_4.btnk.conv2.bn.weight       of shape (32,)
2022-04-26 15:47:32,052 alphaction.utils.model_serialization INFO: backbone.fast.res_nl3.res_4.btnk.conv2.conv.weight     loaded from backbone.fast.res_nl3.res_4.btnk.conv2.conv.weight     of shape (32, 32, 1, 3, 3)
2022-04-26 15:47:32,052 alphaction.utils.model_serialization INFO: backbone.fast.res_nl3.res_4.btnk.conv3.bn.bias         loaded from backbone.fast.res_nl3.res_4.btnk.conv3.bn.bias         of shape (128,)
2022-04-26 15:47:32,052 alphaction.utils.model_serialization INFO: backbone.fast.res_nl3.res_4.btnk.conv3.bn.running_mean loaded from backbone.fast.res_nl3.res_4.btnk.conv3.bn.running_mean of shape (128,)
2022-04-26 15:47:32,052 alphaction.utils.model_serialization INFO: backbone.fast.res_nl3.res_4.btnk.conv3.bn.running_var  loaded from backbone.fast.res_nl3.res_4.btnk.conv3.bn.running_var  of shape (128,)
2022-04-26 15:47:32,052 alphaction.utils.model_serialization INFO: backbone.fast.res_nl3.res_4.btnk.conv3.bn.weight       loaded from backbone.fast.res_nl3.res_4.btnk.conv3.bn.weight       of shape (128,)
2022-04-26 15:47:32,052 alphaction.utils.model_serialization INFO: backbone.fast.res_nl3.res_4.btnk.conv3.conv.weight     loaded from backbone.fast.res_nl3.res_4.btnk.conv3.conv.weight     of shape (128, 32, 1, 1, 1)
2022-04-26 15:47:32,052 alphaction.utils.model_serialization INFO: backbone.fast.res_nl3.res_5.btnk.conv1.bn.bias         loaded from backbone.fast.res_nl3.res_5.btnk.conv1.bn.bias         of shape (32,)
2022-04-26 15:47:32,052 alphaction.utils.model_serialization INFO: backbone.fast.res_nl3.res_5.btnk.conv1.bn.running_mean loaded from backbone.fast.res_nl3.res_5.btnk.conv1.bn.running_mean of shape (32,)
2022-04-26 15:47:32,052 alphaction.utils.model_serialization INFO: backbone.fast.res_nl3.res_5.btnk.conv1.bn.running_var  loaded from backbone.fast.res_nl3.res_5.btnk.conv1.bn.running_var  of shape (32,)
2022-04-26 15:47:32,052 alphaction.utils.model_serialization INFO: backbone.fast.res_nl3.res_5.btnk.conv1.bn.weight       loaded from backbone.fast.res_nl3.res_5.btnk.conv1.bn.weight       of shape (32,)
2022-04-26 15:47:32,052 alphaction.utils.model_serialization INFO: backbone.fast.res_nl3.res_5.btnk.conv1.conv.weight     loaded from backbone.fast.res_nl3.res_5.btnk.conv1.conv.weight     of shape (32, 128, 3, 1, 1)
2022-04-26 15:47:32,052 alphaction.utils.model_serialization INFO: backbone.fast.res_nl3.res_5.btnk.conv2.bn.bias         loaded from backbone.fast.res_nl3.res_5.btnk.conv2.bn.bias         of shape (32,)
2022-04-26 15:47:32,052 alphaction.utils.model_serialization INFO: backbone.fast.res_nl3.res_5.btnk.conv2.bn.running_mean loaded from backbone.fast.res_nl3.res_5.btnk.conv2.bn.running_mean of shape (32,)
2022-04-26 15:47:32,052 alphaction.utils.model_serialization INFO: backbone.fast.res_nl3.res_5.btnk.conv2.bn.running_var  loaded from backbone.fast.res_nl3.res_5.btnk.conv2.bn.running_var  of shape (32,)
2022-04-26 15:47:32,052 alphaction.utils.model_serialization INFO: backbone.fast.res_nl3.res_5.btnk.conv2.bn.weight       loaded from backbone.fast.res_nl3.res_5.btnk.conv2.bn.weight       of shape (32,)
2022-04-26 15:47:32,052 alphaction.utils.model_serialization INFO: backbone.fast.res_nl3.res_5.btnk.conv2.conv.weight     loaded from backbone.fast.res_nl3.res_5.btnk.conv2.conv.weight     of shape (32, 32, 1, 3, 3)
2022-04-26 15:47:32,053 alphaction.utils.model_serialization INFO: backbone.fast.res_nl3.res_5.btnk.conv3.bn.bias         loaded from backbone.fast.res_nl3.res_5.btnk.conv3.bn.bias         of shape (128,)
2022-04-26 15:47:32,053 alphaction.utils.model_serialization INFO: backbone.fast.res_nl3.res_5.btnk.conv3.bn.running_mean loaded from backbone.fast.res_nl3.res_5.btnk.conv3.bn.running_mean of shape (128,)
2022-04-26 15:47:32,053 alphaction.utils.model_serialization INFO: backbone.fast.res_nl3.res_5.btnk.conv3.bn.running_var  loaded from backbone.fast.res_nl3.res_5.btnk.conv3.bn.running_var  of shape (128,)
2022-04-26 15:47:32,053 alphaction.utils.model_serialization INFO: backbone.fast.res_nl3.res_5.btnk.conv3.bn.weight       loaded from backbone.fast.res_nl3.res_5.btnk.conv3.bn.weight       of shape (128,)
2022-04-26 15:47:32,053 alphaction.utils.model_serialization INFO: backbone.fast.res_nl3.res_5.btnk.conv3.conv.weight     loaded from backbone.fast.res_nl3.res_5.btnk.conv3.conv.weight     of shape (128, 32, 1, 1, 1)
2022-04-26 15:47:32,053 alphaction.utils.model_serialization INFO: backbone.fast.res_nl4.res_0.btnk.conv1.bn.bias         loaded from backbone.fast.res_nl4.res_0.btnk.conv1.bn.bias         of shape (64,)
2022-04-26 15:47:32,053 alphaction.utils.model_serialization INFO: backbone.fast.res_nl4.res_0.btnk.conv1.bn.running_mean loaded from backbone.fast.res_nl4.res_0.btnk.conv1.bn.running_mean of shape (64,)
2022-04-26 15:47:32,053 alphaction.utils.model_serialization INFO: backbone.fast.res_nl4.res_0.btnk.conv1.bn.running_var  loaded from backbone.fast.res_nl4.res_0.btnk.conv1.bn.running_var  of shape (64,)
2022-04-26 15:47:32,053 alphaction.utils.model_serialization INFO: backbone.fast.res_nl4.res_0.btnk.conv1.bn.weight       loaded from backbone.fast.res_nl4.res_0.btnk.conv1.bn.weight       of shape (64,)
2022-04-26 15:47:32,053 alphaction.utils.model_serialization INFO: backbone.fast.res_nl4.res_0.btnk.conv1.conv.weight     loaded from backbone.fast.res_nl4.res_0.btnk.conv1.conv.weight     of shape (64, 128, 3, 1, 1)
2022-04-26 15:47:32,053 alphaction.utils.model_serialization INFO: backbone.fast.res_nl4.res_0.btnk.conv2.bn.bias         loaded from backbone.fast.res_nl4.res_0.btnk.conv2.bn.bias         of shape (64,)
2022-04-26 15:47:32,053 alphaction.utils.model_serialization INFO: backbone.fast.res_nl4.res_0.btnk.conv2.bn.running_mean loaded from backbone.fast.res_nl4.res_0.btnk.conv2.bn.running_mean of shape (64,)
2022-04-26 15:47:32,053 alphaction.utils.model_serialization INFO: backbone.fast.res_nl4.res_0.btnk.conv2.bn.running_var  loaded from backbone.fast.res_nl4.res_0.btnk.conv2.bn.running_var  of shape (64,)
2022-04-26 15:47:32,053 alphaction.utils.model_serialization INFO: backbone.fast.res_nl4.res_0.btnk.conv2.bn.weight       loaded from backbone.fast.res_nl4.res_0.btnk.conv2.bn.weight       of shape (64,)
2022-04-26 15:47:32,053 alphaction.utils.model_serialization INFO: backbone.fast.res_nl4.res_0.btnk.conv2.conv.weight     loaded from backbone.fast.res_nl4.res_0.btnk.conv2.conv.weight     of shape (64, 64, 1, 3, 3)
2022-04-26 15:47:32,053 alphaction.utils.model_serialization INFO: backbone.fast.res_nl4.res_0.btnk.conv3.bn.bias         loaded from backbone.fast.res_nl4.res_0.btnk.conv3.bn.bias         of shape (256,)
2022-04-26 15:47:32,053 alphaction.utils.model_serialization INFO: backbone.fast.res_nl4.res_0.btnk.conv3.bn.running_mean loaded from backbone.fast.res_nl4.res_0.btnk.conv3.bn.running_mean of shape (256,)
2022-04-26 15:47:32,053 alphaction.utils.model_serialization INFO: backbone.fast.res_nl4.res_0.btnk.conv3.bn.running_var  loaded from backbone.fast.res_nl4.res_0.btnk.conv3.bn.running_var  of shape (256,)
2022-04-26 15:47:32,053 alphaction.utils.model_serialization INFO: backbone.fast.res_nl4.res_0.btnk.conv3.bn.weight       loaded from backbone.fast.res_nl4.res_0.btnk.conv3.bn.weight       of shape (256,)
2022-04-26 15:47:32,053 alphaction.utils.model_serialization INFO: backbone.fast.res_nl4.res_0.btnk.conv3.conv.weight     loaded from backbone.fast.res_nl4.res_0.btnk.conv3.conv.weight     of shape (256, 64, 1, 1, 1)
2022-04-26 15:47:32,053 alphaction.utils.model_serialization INFO: backbone.fast.res_nl4.res_0.shortcut.bn.bias           loaded from backbone.fast.res_nl4.res_0.shortcut.bn.bias           of shape (256,)
2022-04-26 15:47:32,053 alphaction.utils.model_serialization INFO: backbone.fast.res_nl4.res_0.shortcut.bn.running_mean   loaded from backbone.fast.res_nl4.res_0.shortcut.bn.running_mean   of shape (256,)
2022-04-26 15:47:32,053 alphaction.utils.model_serialization INFO: backbone.fast.res_nl4.res_0.shortcut.bn.running_var    loaded from backbone.fast.res_nl4.res_0.shortcut.bn.running_var    of shape (256,)
2022-04-26 15:47:32,053 alphaction.utils.model_serialization INFO: backbone.fast.res_nl4.res_0.shortcut.bn.weight         loaded from backbone.fast.res_nl4.res_0.shortcut.bn.weight         of shape (256,)
2022-04-26 15:47:32,054 alphaction.utils.model_serialization INFO: backbone.fast.res_nl4.res_0.shortcut.conv.weight       loaded from backbone.fast.res_nl4.res_0.shortcut.conv.weight       of shape (256, 128, 1, 1, 1)
2022-04-26 15:47:32,054 alphaction.utils.model_serialization INFO: backbone.fast.res_nl4.res_1.btnk.conv1.bn.bias         loaded from backbone.fast.res_nl4.res_1.btnk.conv1.bn.bias         of shape (64,)
2022-04-26 15:47:32,054 alphaction.utils.model_serialization INFO: backbone.fast.res_nl4.res_1.btnk.conv1.bn.running_mean loaded from backbone.fast.res_nl4.res_1.btnk.conv1.bn.running_mean of shape (64,)
2022-04-26 15:47:32,054 alphaction.utils.model_serialization INFO: backbone.fast.res_nl4.res_1.btnk.conv1.bn.running_var  loaded from backbone.fast.res_nl4.res_1.btnk.conv1.bn.running_var  of shape (64,)
2022-04-26 15:47:32,054 alphaction.utils.model_serialization INFO: backbone.fast.res_nl4.res_1.btnk.conv1.bn.weight       loaded from backbone.fast.res_nl4.res_1.btnk.conv1.bn.weight       of shape (64,)
2022-04-26 15:47:32,054 alphaction.utils.model_serialization INFO: backbone.fast.res_nl4.res_1.btnk.conv1.conv.weight     loaded from backbone.fast.res_nl4.res_1.btnk.conv1.conv.weight     of shape (64, 256, 3, 1, 1)
2022-04-26 15:47:32,054 alphaction.utils.model_serialization INFO: backbone.fast.res_nl4.res_1.btnk.conv2.bn.bias         loaded from backbone.fast.res_nl4.res_1.btnk.conv2.bn.bias         of shape (64,)
2022-04-26 15:47:32,054 alphaction.utils.model_serialization INFO: backbone.fast.res_nl4.res_1.btnk.conv2.bn.running_mean loaded from backbone.fast.res_nl4.res_1.btnk.conv2.bn.running_mean of shape (64,)
2022-04-26 15:47:32,054 alphaction.utils.model_serialization INFO: backbone.fast.res_nl4.res_1.btnk.conv2.bn.running_var  loaded from backbone.fast.res_nl4.res_1.btnk.conv2.bn.running_var  of shape (64,)
2022-04-26 15:47:32,054 alphaction.utils.model_serialization INFO: backbone.fast.res_nl4.res_1.btnk.conv2.bn.weight       loaded from backbone.fast.res_nl4.res_1.btnk.conv2.bn.weight       of shape (64,)
2022-04-26 15:47:32,054 alphaction.utils.model_serialization INFO: backbone.fast.res_nl4.res_1.btnk.conv2.conv.weight     loaded from backbone.fast.res_nl4.res_1.btnk.conv2.conv.weight     of shape (64, 64, 1, 3, 3)
2022-04-26 15:47:32,054 alphaction.utils.model_serialization INFO: backbone.fast.res_nl4.res_1.btnk.conv3.bn.bias         loaded from backbone.fast.res_nl4.res_1.btnk.conv3.bn.bias         of shape (256,)
2022-04-26 15:47:32,054 alphaction.utils.model_serialization INFO: backbone.fast.res_nl4.res_1.btnk.conv3.bn.running_mean loaded from backbone.fast.res_nl4.res_1.btnk.conv3.bn.running_mean of shape (256,)
2022-04-26 15:47:32,054 alphaction.utils.model_serialization INFO: backbone.fast.res_nl4.res_1.btnk.conv3.bn.running_var  loaded from backbone.fast.res_nl4.res_1.btnk.conv3.bn.running_var  of shape (256,)
2022-04-26 15:47:32,054 alphaction.utils.model_serialization INFO: backbone.fast.res_nl4.res_1.btnk.conv3.bn.weight       loaded from backbone.fast.res_nl4.res_1.btnk.conv3.bn.weight       of shape (256,)
2022-04-26 15:47:32,054 alphaction.utils.model_serialization INFO: backbone.fast.res_nl4.res_1.btnk.conv3.conv.weight     loaded from backbone.fast.res_nl4.res_1.btnk.conv3.conv.weight     of shape (256, 64, 1, 1, 1)
2022-04-26 15:47:32,054 alphaction.utils.model_serialization INFO: backbone.fast.res_nl4.res_2.btnk.conv1.bn.bias         loaded from backbone.fast.res_nl4.res_2.btnk.conv1.bn.bias         of shape (64,)
2022-04-26 15:47:32,054 alphaction.utils.model_serialization INFO: backbone.fast.res_nl4.res_2.btnk.conv1.bn.running_mean loaded from backbone.fast.res_nl4.res_2.btnk.conv1.bn.running_mean of shape (64,)
2022-04-26 15:47:32,054 alphaction.utils.model_serialization INFO: backbone.fast.res_nl4.res_2.btnk.conv1.bn.running_var  loaded from backbone.fast.res_nl4.res_2.btnk.conv1.bn.running_var  of shape (64,)
2022-04-26 15:47:32,054 alphaction.utils.model_serialization INFO: backbone.fast.res_nl4.res_2.btnk.conv1.bn.weight       loaded from backbone.fast.res_nl4.res_2.btnk.conv1.bn.weight       of shape (64,)
2022-04-26 15:47:32,054 alphaction.utils.model_serialization INFO: backbone.fast.res_nl4.res_2.btnk.conv1.conv.weight     loaded from backbone.fast.res_nl4.res_2.btnk.conv1.conv.weight     of shape (64, 256, 3, 1, 1)
2022-04-26 15:47:32,054 alphaction.utils.model_serialization INFO: backbone.fast.res_nl4.res_2.btnk.conv2.bn.bias         loaded from backbone.fast.res_nl4.res_2.btnk.conv2.bn.bias         of shape (64,)
2022-04-26 15:47:32,054 alphaction.utils.model_serialization INFO: backbone.fast.res_nl4.res_2.btnk.conv2.bn.running_mean loaded from backbone.fast.res_nl4.res_2.btnk.conv2.bn.running_mean of shape (64,)
2022-04-26 15:47:32,054 alphaction.utils.model_serialization INFO: backbone.fast.res_nl4.res_2.btnk.conv2.bn.running_var  loaded from backbone.fast.res_nl4.res_2.btnk.conv2.bn.running_var  of shape (64,)
2022-04-26 15:47:32,054 alphaction.utils.model_serialization INFO: backbone.fast.res_nl4.res_2.btnk.conv2.bn.weight       loaded from backbone.fast.res_nl4.res_2.btnk.conv2.bn.weight       of shape (64,)
2022-04-26 15:47:32,055 alphaction.utils.model_serialization INFO: backbone.fast.res_nl4.res_2.btnk.conv2.conv.weight     loaded from backbone.fast.res_nl4.res_2.btnk.conv2.conv.weight     of shape (64, 64, 1, 3, 3)
2022-04-26 15:47:32,055 alphaction.utils.model_serialization INFO: backbone.fast.res_nl4.res_2.btnk.conv3.bn.bias         loaded from backbone.fast.res_nl4.res_2.btnk.conv3.bn.bias         of shape (256,)
2022-04-26 15:47:32,055 alphaction.utils.model_serialization INFO: backbone.fast.res_nl4.res_2.btnk.conv3.bn.running_mean loaded from backbone.fast.res_nl4.res_2.btnk.conv3.bn.running_mean of shape (256,)
2022-04-26 15:47:32,055 alphaction.utils.model_serialization INFO: backbone.fast.res_nl4.res_2.btnk.conv3.bn.running_var  loaded from backbone.fast.res_nl4.res_2.btnk.conv3.bn.running_var  of shape (256,)
2022-04-26 15:47:32,055 alphaction.utils.model_serialization INFO: backbone.fast.res_nl4.res_2.btnk.conv3.bn.weight       loaded from backbone.fast.res_nl4.res_2.btnk.conv3.bn.weight       of shape (256,)
2022-04-26 15:47:32,055 alphaction.utils.model_serialization INFO: backbone.fast.res_nl4.res_2.btnk.conv3.conv.weight     loaded from backbone.fast.res_nl4.res_2.btnk.conv3.conv.weight     of shape (256, 64, 1, 1, 1)
2022-04-26 15:47:32,055 alphaction.utils.model_serialization INFO: backbone.slow.bn1.bias                                 loaded from backbone.slow.bn1.bias                                 of shape (64,)
2022-04-26 15:47:32,055 alphaction.utils.model_serialization INFO: backbone.slow.bn1.running_mean                         loaded from backbone.slow.bn1.running_mean                         of shape (64,)
2022-04-26 15:47:32,055 alphaction.utils.model_serialization INFO: backbone.slow.bn1.running_var                          loaded from backbone.slow.bn1.running_var                          of shape (64,)
2022-04-26 15:47:32,055 alphaction.utils.model_serialization INFO: backbone.slow.bn1.weight                               loaded from backbone.slow.bn1.weight                               of shape (64,)
2022-04-26 15:47:32,055 alphaction.utils.model_serialization INFO: backbone.slow.conv1.weight                             loaded from backbone.slow.conv1.weight                             of shape (64, 3, 1, 7, 7)
2022-04-26 15:47:32,055 alphaction.utils.model_serialization INFO: backbone.slow.res_nl1.res_0.btnk.conv1.bn.bias         loaded from backbone.slow.res_nl1.res_0.btnk.conv1.bn.bias         of shape (64,)
2022-04-26 15:47:32,055 alphaction.utils.model_serialization INFO: backbone.slow.res_nl1.res_0.btnk.conv1.bn.running_mean loaded from backbone.slow.res_nl1.res_0.btnk.conv1.bn.running_mean of shape (64,)
2022-04-26 15:47:32,055 alphaction.utils.model_serialization INFO: backbone.slow.res_nl1.res_0.btnk.conv1.bn.running_var  loaded from backbone.slow.res_nl1.res_0.btnk.conv1.bn.running_var  of shape (64,)
2022-04-26 15:47:32,055 alphaction.utils.model_serialization INFO: backbone.slow.res_nl1.res_0.btnk.conv1.bn.weight       loaded from backbone.slow.res_nl1.res_0.btnk.conv1.bn.weight       of shape (64,)
2022-04-26 15:47:32,055 alphaction.utils.model_serialization INFO: backbone.slow.res_nl1.res_0.btnk.conv1.conv.weight     loaded from backbone.slow.res_nl1.res_0.btnk.conv1.conv.weight     of shape (64, 80, 1, 1, 1)
2022-04-26 15:47:32,055 alphaction.utils.model_serialization INFO: backbone.slow.res_nl1.res_0.btnk.conv2.bn.bias         loaded from backbone.slow.res_nl1.res_0.btnk.conv2.bn.bias         of shape (64,)
2022-04-26 15:47:32,055 alphaction.utils.model_serialization INFO: backbone.slow.res_nl1.res_0.btnk.conv2.bn.running_mean loaded from backbone.slow.res_nl1.res_0.btnk.conv2.bn.running_mean of shape (64,)
2022-04-26 15:47:32,055 alphaction.utils.model_serialization INFO: backbone.slow.res_nl1.res_0.btnk.conv2.bn.running_var  loaded from backbone.slow.res_nl1.res_0.btnk.conv2.bn.running_var  of shape (64,)
2022-04-26 15:47:32,055 alphaction.utils.model_serialization INFO: backbone.slow.res_nl1.res_0.btnk.conv2.bn.weight       loaded from backbone.slow.res_nl1.res_0.btnk.conv2.bn.weight       of shape (64,)
2022-04-26 15:47:32,055 alphaction.utils.model_serialization INFO: backbone.slow.res_nl1.res_0.btnk.conv2.conv.weight     loaded from backbone.slow.res_nl1.res_0.btnk.conv2.conv.weight     of shape (64, 64, 1, 3, 3)
2022-04-26 15:47:32,055 alphaction.utils.model_serialization INFO: backbone.slow.res_nl1.res_0.btnk.conv3.bn.bias         loaded from backbone.slow.res_nl1.res_0.btnk.conv3.bn.bias         of shape (256,)
2022-04-26 15:47:32,055 alphaction.utils.model_serialization INFO: backbone.slow.res_nl1.res_0.btnk.conv3.bn.running_mean loaded from backbone.slow.res_nl1.res_0.btnk.conv3.bn.running_mean of shape (256,)
2022-04-26 15:47:32,055 alphaction.utils.model_serialization INFO: backbone.slow.res_nl1.res_0.btnk.conv3.bn.running_var  loaded from backbone.slow.res_nl1.res_0.btnk.conv3.bn.running_var  of shape (256,)
2022-04-26 15:47:32,055 alphaction.utils.model_serialization INFO: backbone.slow.res_nl1.res_0.btnk.conv3.bn.weight       loaded from backbone.slow.res_nl1.res_0.btnk.conv3.bn.weight       of shape (256,)
2022-04-26 15:47:32,055 alphaction.utils.model_serialization INFO: backbone.slow.res_nl1.res_0.btnk.conv3.conv.weight     loaded from backbone.slow.res_nl1.res_0.btnk.conv3.conv.weight     of shape (256, 64, 1, 1, 1)
2022-04-26 15:47:32,055 alphaction.utils.model_serialization INFO: backbone.slow.res_nl1.res_0.shortcut.bn.bias           loaded from backbone.slow.res_nl1.res_0.shortcut.bn.bias           of shape (256,)
2022-04-26 15:47:32,055 alphaction.utils.model_serialization INFO: backbone.slow.res_nl1.res_0.shortcut.bn.running_mean   loaded from backbone.slow.res_nl1.res_0.shortcut.bn.running_mean   of shape (256,)
2022-04-26 15:47:32,055 alphaction.utils.model_serialization INFO: backbone.slow.res_nl1.res_0.shortcut.bn.running_var    loaded from backbone.slow.res_nl1.res_0.shortcut.bn.running_var    of shape (256,)
2022-04-26 15:47:32,056 alphaction.utils.model_serialization INFO: backbone.slow.res_nl1.res_0.shortcut.bn.weight         loaded from backbone.slow.res_nl1.res_0.shortcut.bn.weight         of shape (256,)
2022-04-26 15:47:32,056 alphaction.utils.model_serialization INFO: backbone.slow.res_nl1.res_0.shortcut.conv.weight       loaded from backbone.slow.res_nl1.res_0.shortcut.conv.weight       of shape (256, 80, 1, 1, 1)
2022-04-26 15:47:32,056 alphaction.utils.model_serialization INFO: backbone.slow.res_nl1.res_1.btnk.conv1.bn.bias         loaded from backbone.slow.res_nl1.res_1.btnk.conv1.bn.bias         of shape (64,)
2022-04-26 15:47:32,056 alphaction.utils.model_serialization INFO: backbone.slow.res_nl1.res_1.btnk.conv1.bn.running_mean loaded from backbone.slow.res_nl1.res_1.btnk.conv1.bn.running_mean of shape (64,)
2022-04-26 15:47:32,056 alphaction.utils.model_serialization INFO: backbone.slow.res_nl1.res_1.btnk.conv1.bn.running_var  loaded from backbone.slow.res_nl1.res_1.btnk.conv1.bn.running_var  of shape (64,)
2022-04-26 15:47:32,056 alphaction.utils.model_serialization INFO: backbone.slow.res_nl1.res_1.btnk.conv1.bn.weight       loaded from backbone.slow.res_nl1.res_1.btnk.conv1.bn.weight       of shape (64,)
2022-04-26 15:47:32,056 alphaction.utils.model_serialization INFO: backbone.slow.res_nl1.res_1.btnk.conv1.conv.weight     loaded from backbone.slow.res_nl1.res_1.btnk.conv1.conv.weight     of shape (64, 256, 1, 1, 1)
2022-04-26 15:47:32,056 alphaction.utils.model_serialization INFO: backbone.slow.res_nl1.res_1.btnk.conv2.bn.bias         loaded from backbone.slow.res_nl1.res_1.btnk.conv2.bn.bias         of shape (64,)
2022-04-26 15:47:32,056 alphaction.utils.model_serialization INFO: backbone.slow.res_nl1.res_1.btnk.conv2.bn.running_mean loaded from backbone.slow.res_nl1.res_1.btnk.conv2.bn.running_mean of shape (64,)
2022-04-26 15:47:32,056 alphaction.utils.model_serialization INFO: backbone.slow.res_nl1.res_1.btnk.conv2.bn.running_var  loaded from backbone.slow.res_nl1.res_1.btnk.conv2.bn.running_var  of shape (64,)
2022-04-26 15:47:32,056 alphaction.utils.model_serialization INFO: backbone.slow.res_nl1.res_1.btnk.conv2.bn.weight       loaded from backbone.slow.res_nl1.res_1.btnk.conv2.bn.weight       of shape (64,)
2022-04-26 15:47:32,056 alphaction.utils.model_serialization INFO: backbone.slow.res_nl1.res_1.btnk.conv2.conv.weight     loaded from backbone.slow.res_nl1.res_1.btnk.conv2.conv.weight     of shape (64, 64, 1, 3, 3)
2022-04-26 15:47:32,056 alphaction.utils.model_serialization INFO: backbone.slow.res_nl1.res_1.btnk.conv3.bn.bias         loaded from backbone.slow.res_nl1.res_1.btnk.conv3.bn.bias         of shape (256,)
2022-04-26 15:47:32,056 alphaction.utils.model_serialization INFO: backbone.slow.res_nl1.res_1.btnk.conv3.bn.running_mean loaded from backbone.slow.res_nl1.res_1.btnk.conv3.bn.running_mean of shape (256,)
2022-04-26 15:47:32,056 alphaction.utils.model_serialization INFO: backbone.slow.res_nl1.res_1.btnk.conv3.bn.running_var  loaded from backbone.slow.res_nl1.res_1.btnk.conv3.bn.running_var  of shape (256,)
2022-04-26 15:47:32,056 alphaction.utils.model_serialization INFO: backbone.slow.res_nl1.res_1.btnk.conv3.bn.weight       loaded from backbone.slow.res_nl1.res_1.btnk.conv3.bn.weight       of shape (256,)
2022-04-26 15:47:32,056 alphaction.utils.model_serialization INFO: backbone.slow.res_nl1.res_1.btnk.conv3.conv.weight     loaded from backbone.slow.res_nl1.res_1.btnk.conv3.conv.weight     of shape (256, 64, 1, 1, 1)
2022-04-26 15:47:32,056 alphaction.utils.model_serialization INFO: backbone.slow.res_nl1.res_2.btnk.conv1.bn.bias         loaded from backbone.slow.res_nl1.res_2.btnk.conv1.bn.bias         of shape (64,)
2022-04-26 15:47:32,056 alphaction.utils.model_serialization INFO: backbone.slow.res_nl1.res_2.btnk.conv1.bn.running_mean loaded from backbone.slow.res_nl1.res_2.btnk.conv1.bn.running_mean of shape (64,)
2022-04-26 15:47:32,056 alphaction.utils.model_serialization INFO: backbone.slow.res_nl1.res_2.btnk.conv1.bn.running_var  loaded from backbone.slow.res_nl1.res_2.btnk.conv1.bn.running_var  of shape (64,)
2022-04-26 15:47:32,056 alphaction.utils.model_serialization INFO: backbone.slow.res_nl1.res_2.btnk.conv1.bn.weight       loaded from backbone.slow.res_nl1.res_2.btnk.conv1.bn.weight       of shape (64,)
2022-04-26 15:47:32,056 alphaction.utils.model_serialization INFO: backbone.slow.res_nl1.res_2.btnk.conv1.conv.weight     loaded from backbone.slow.res_nl1.res_2.btnk.conv1.conv.weight     of shape (64, 256, 1, 1, 1)
2022-04-26 15:47:32,056 alphaction.utils.model_serialization INFO: backbone.slow.res_nl1.res_2.btnk.conv2.bn.bias         loaded from backbone.slow.res_nl1.res_2.btnk.conv2.bn.bias         of shape (64,)
2022-04-26 15:47:32,056 alphaction.utils.model_serialization INFO: backbone.slow.res_nl1.res_2.btnk.conv2.bn.running_mean loaded from backbone.slow.res_nl1.res_2.btnk.conv2.bn.running_mean of shape (64,)
2022-04-26 15:47:32,056 alphaction.utils.model_serialization INFO: backbone.slow.res_nl1.res_2.btnk.conv2.bn.running_var  loaded from backbone.slow.res_nl1.res_2.btnk.conv2.bn.running_var  of shape (64,)
2022-04-26 15:47:32,056 alphaction.utils.model_serialization INFO: backbone.slow.res_nl1.res_2.btnk.conv2.bn.weight       loaded from backbone.slow.res_nl1.res_2.btnk.conv2.bn.weight       of shape (64,)
2022-04-26 15:47:32,056 alphaction.utils.model_serialization INFO: backbone.slow.res_nl1.res_2.btnk.conv2.conv.weight     loaded from backbone.slow.res_nl1.res_2.btnk.conv2.conv.weight     of shape (64, 64, 1, 3, 3)
2022-04-26 15:47:32,056 alphaction.utils.model_serialization INFO: backbone.slow.res_nl1.res_2.btnk.conv3.bn.bias         loaded from backbone.slow.res_nl1.res_2.btnk.conv3.bn.bias         of shape (256,)
2022-04-26 15:47:32,056 alphaction.utils.model_serialization INFO: backbone.slow.res_nl1.res_2.btnk.conv3.bn.running_mean loaded from backbone.slow.res_nl1.res_2.btnk.conv3.bn.running_mean of shape (256,)
2022-04-26 15:47:32,056 alphaction.utils.model_serialization INFO: backbone.slow.res_nl1.res_2.btnk.conv3.bn.running_var  loaded from backbone.slow.res_nl1.res_2.btnk.conv3.bn.running_var  of shape (256,)
2022-04-26 15:47:32,057 alphaction.utils.model_serialization INFO: backbone.slow.res_nl1.res_2.btnk.conv3.bn.weight       loaded from backbone.slow.res_nl1.res_2.btnk.conv3.bn.weight       of shape (256,)
2022-04-26 15:47:32,057 alphaction.utils.model_serialization INFO: backbone.slow.res_nl1.res_2.btnk.conv3.conv.weight     loaded from backbone.slow.res_nl1.res_2.btnk.conv3.conv.weight     of shape (256, 64, 1, 1, 1)
2022-04-26 15:47:32,057 alphaction.utils.model_serialization INFO: backbone.slow.res_nl2.res_0.btnk.conv1.bn.bias         loaded from backbone.slow.res_nl2.res_0.btnk.conv1.bn.bias         of shape (128,)
2022-04-26 15:47:32,057 alphaction.utils.model_serialization INFO: backbone.slow.res_nl2.res_0.btnk.conv1.bn.running_mean loaded from backbone.slow.res_nl2.res_0.btnk.conv1.bn.running_mean of shape (128,)
2022-04-26 15:47:32,057 alphaction.utils.model_serialization INFO: backbone.slow.res_nl2.res_0.btnk.conv1.bn.running_var  loaded from backbone.slow.res_nl2.res_0.btnk.conv1.bn.running_var  of shape (128,)
2022-04-26 15:47:32,057 alphaction.utils.model_serialization INFO: backbone.slow.res_nl2.res_0.btnk.conv1.bn.weight       loaded from backbone.slow.res_nl2.res_0.btnk.conv1.bn.weight       of shape (128,)
2022-04-26 15:47:32,057 alphaction.utils.model_serialization INFO: backbone.slow.res_nl2.res_0.btnk.conv1.conv.weight     loaded from backbone.slow.res_nl2.res_0.btnk.conv1.conv.weight     of shape (128, 320, 1, 1, 1)
2022-04-26 15:47:32,057 alphaction.utils.model_serialization INFO: backbone.slow.res_nl2.res_0.btnk.conv2.bn.bias         loaded from backbone.slow.res_nl2.res_0.btnk.conv2.bn.bias         of shape (128,)
2022-04-26 15:47:32,057 alphaction.utils.model_serialization INFO: backbone.slow.res_nl2.res_0.btnk.conv2.bn.running_mean loaded from backbone.slow.res_nl2.res_0.btnk.conv2.bn.running_mean of shape (128,)
2022-04-26 15:47:32,057 alphaction.utils.model_serialization INFO: backbone.slow.res_nl2.res_0.btnk.conv2.bn.running_var  loaded from backbone.slow.res_nl2.res_0.btnk.conv2.bn.running_var  of shape (128,)
2022-04-26 15:47:32,057 alphaction.utils.model_serialization INFO: backbone.slow.res_nl2.res_0.btnk.conv2.bn.weight       loaded from backbone.slow.res_nl2.res_0.btnk.conv2.bn.weight       of shape (128,)
2022-04-26 15:47:32,057 alphaction.utils.model_serialization INFO: backbone.slow.res_nl2.res_0.btnk.conv2.conv.weight     loaded from backbone.slow.res_nl2.res_0.btnk.conv2.conv.weight     of shape (128, 128, 1, 3, 3)
2022-04-26 15:47:32,057 alphaction.utils.model_serialization INFO: backbone.slow.res_nl2.res_0.btnk.conv3.bn.bias         loaded from backbone.slow.res_nl2.res_0.btnk.conv3.bn.bias         of shape (512,)
2022-04-26 15:47:32,057 alphaction.utils.model_serialization INFO: backbone.slow.res_nl2.res_0.btnk.conv3.bn.running_mean loaded from backbone.slow.res_nl2.res_0.btnk.conv3.bn.running_mean of shape (512,)
2022-04-26 15:47:32,057 alphaction.utils.model_serialization INFO: backbone.slow.res_nl2.res_0.btnk.conv3.bn.running_var  loaded from backbone.slow.res_nl2.res_0.btnk.conv3.bn.running_var  of shape (512,)
2022-04-26 15:47:32,057 alphaction.utils.model_serialization INFO: backbone.slow.res_nl2.res_0.btnk.conv3.bn.weight       loaded from backbone.slow.res_nl2.res_0.btnk.conv3.bn.weight       of shape (512,)
2022-04-26 15:47:32,057 alphaction.utils.model_serialization INFO: backbone.slow.res_nl2.res_0.btnk.conv3.conv.weight     loaded from backbone.slow.res_nl2.res_0.btnk.conv3.conv.weight     of shape (512, 128, 1, 1, 1)
2022-04-26 15:47:32,057 alphaction.utils.model_serialization INFO: backbone.slow.res_nl2.res_0.shortcut.bn.bias           loaded from backbone.slow.res_nl2.res_0.shortcut.bn.bias           of shape (512,)
2022-04-26 15:47:32,057 alphaction.utils.model_serialization INFO: backbone.slow.res_nl2.res_0.shortcut.bn.running_mean   loaded from backbone.slow.res_nl2.res_0.shortcut.bn.running_mean   of shape (512,)
2022-04-26 15:47:32,057 alphaction.utils.model_serialization INFO: backbone.slow.res_nl2.res_0.shortcut.bn.running_var    loaded from backbone.slow.res_nl2.res_0.shortcut.bn.running_var    of shape (512,)
2022-04-26 15:47:32,057 alphaction.utils.model_serialization INFO: backbone.slow.res_nl2.res_0.shortcut.bn.weight         loaded from backbone.slow.res_nl2.res_0.shortcut.bn.weight         of shape (512,)
2022-04-26 15:47:32,058 alphaction.utils.model_serialization INFO: backbone.slow.res_nl2.res_0.shortcut.conv.weight       loaded from backbone.slow.res_nl2.res_0.shortcut.conv.weight       of shape (512, 320, 1, 1, 1)
2022-04-26 15:47:32,058 alphaction.utils.model_serialization INFO: backbone.slow.res_nl2.res_1.btnk.conv1.bn.bias         loaded from backbone.slow.res_nl2.res_1.btnk.conv1.bn.bias         of shape (128,)
2022-04-26 15:47:32,058 alphaction.utils.model_serialization INFO: backbone.slow.res_nl2.res_1.btnk.conv1.bn.running_mean loaded from backbone.slow.res_nl2.res_1.btnk.conv1.bn.running_mean of shape (128,)
2022-04-26 15:47:32,058 alphaction.utils.model_serialization INFO: backbone.slow.res_nl2.res_1.btnk.conv1.bn.running_var  loaded from backbone.slow.res_nl2.res_1.btnk.conv1.bn.running_var  of shape (128,)
2022-04-26 15:47:32,058 alphaction.utils.model_serialization INFO: backbone.slow.res_nl2.res_1.btnk.conv1.bn.weight       loaded from backbone.slow.res_nl2.res_1.btnk.conv1.bn.weight       of shape (128,)
2022-04-26 15:47:32,058 alphaction.utils.model_serialization INFO: backbone.slow.res_nl2.res_1.btnk.conv1.conv.weight     loaded from backbone.slow.res_nl2.res_1.btnk.conv1.conv.weight     of shape (128, 512, 1, 1, 1)
2022-04-26 15:47:32,058 alphaction.utils.model_serialization INFO: backbone.slow.res_nl2.res_1.btnk.conv2.bn.bias         loaded from backbone.slow.res_nl2.res_1.btnk.conv2.bn.bias         of shape (128,)
2022-04-26 15:47:32,058 alphaction.utils.model_serialization INFO: backbone.slow.res_nl2.res_1.btnk.conv2.bn.running_mean loaded from backbone.slow.res_nl2.res_1.btnk.conv2.bn.running_mean of shape (128,)
2022-04-26 15:47:32,058 alphaction.utils.model_serialization INFO: backbone.slow.res_nl2.res_1.btnk.conv2.bn.running_var  loaded from backbone.slow.res_nl2.res_1.btnk.conv2.bn.running_var  of shape (128,)
2022-04-26 15:47:32,058 alphaction.utils.model_serialization INFO: backbone.slow.res_nl2.res_1.btnk.conv2.bn.weight       loaded from backbone.slow.res_nl2.res_1.btnk.conv2.bn.weight       of shape (128,)
2022-04-26 15:47:32,058 alphaction.utils.model_serialization INFO: backbone.slow.res_nl2.res_1.btnk.conv2.conv.weight     loaded from backbone.slow.res_nl2.res_1.btnk.conv2.conv.weight     of shape (128, 128, 1, 3, 3)
2022-04-26 15:47:32,058 alphaction.utils.model_serialization INFO: backbone.slow.res_nl2.res_1.btnk.conv3.bn.bias         loaded from backbone.slow.res_nl2.res_1.btnk.conv3.bn.bias         of shape (512,)
2022-04-26 15:47:32,058 alphaction.utils.model_serialization INFO: backbone.slow.res_nl2.res_1.btnk.conv3.bn.running_mean loaded from backbone.slow.res_nl2.res_1.btnk.conv3.bn.running_mean of shape (512,)
2022-04-26 15:47:32,058 alphaction.utils.model_serialization INFO: backbone.slow.res_nl2.res_1.btnk.conv3.bn.running_var  loaded from backbone.slow.res_nl2.res_1.btnk.conv3.bn.running_var  of shape (512,)
2022-04-26 15:47:32,058 alphaction.utils.model_serialization INFO: backbone.slow.res_nl2.res_1.btnk.conv3.bn.weight       loaded from backbone.slow.res_nl2.res_1.btnk.conv3.bn.weight       of shape (512,)
2022-04-26 15:47:32,058 alphaction.utils.model_serialization INFO: backbone.slow.res_nl2.res_1.btnk.conv3.conv.weight     loaded from backbone.slow.res_nl2.res_1.btnk.conv3.conv.weight     of shape (512, 128, 1, 1, 1)
2022-04-26 15:47:32,058 alphaction.utils.model_serialization INFO: backbone.slow.res_nl2.res_2.btnk.conv1.bn.bias         loaded from backbone.slow.res_nl2.res_2.btnk.conv1.bn.bias         of shape (128,)
2022-04-26 15:47:32,058 alphaction.utils.model_serialization INFO: backbone.slow.res_nl2.res_2.btnk.conv1.bn.running_mean loaded from backbone.slow.res_nl2.res_2.btnk.conv1.bn.running_mean of shape (128,)
2022-04-26 15:47:32,058 alphaction.utils.model_serialization INFO: backbone.slow.res_nl2.res_2.btnk.conv1.bn.running_var  loaded from backbone.slow.res_nl2.res_2.btnk.conv1.bn.running_var  of shape (128,)
2022-04-26 15:47:32,058 alphaction.utils.model_serialization INFO: backbone.slow.res_nl2.res_2.btnk.conv1.bn.weight       loaded from backbone.slow.res_nl2.res_2.btnk.conv1.bn.weight       of shape (128,)
2022-04-26 15:47:32,058 alphaction.utils.model_serialization INFO: backbone.slow.res_nl2.res_2.btnk.conv1.conv.weight     loaded from backbone.slow.res_nl2.res_2.btnk.conv1.conv.weight     of shape (128, 512, 1, 1, 1)
2022-04-26 15:47:32,058 alphaction.utils.model_serialization INFO: backbone.slow.res_nl2.res_2.btnk.conv2.bn.bias         loaded from backbone.slow.res_nl2.res_2.btnk.conv2.bn.bias         of shape (128,)
2022-04-26 15:47:32,058 alphaction.utils.model_serialization INFO: backbone.slow.res_nl2.res_2.btnk.conv2.bn.running_mean loaded from backbone.slow.res_nl2.res_2.btnk.conv2.bn.running_mean of shape (128,)
2022-04-26 15:47:32,058 alphaction.utils.model_serialization INFO: backbone.slow.res_nl2.res_2.btnk.conv2.bn.running_var  loaded from backbone.slow.res_nl2.res_2.btnk.conv2.bn.running_var  of shape (128,)
2022-04-26 15:47:32,058 alphaction.utils.model_serialization INFO: backbone.slow.res_nl2.res_2.btnk.conv2.bn.weight       loaded from backbone.slow.res_nl2.res_2.btnk.conv2.bn.weight       of shape (128,)
2022-04-26 15:47:32,058 alphaction.utils.model_serialization INFO: backbone.slow.res_nl2.res_2.btnk.conv2.conv.weight     loaded from backbone.slow.res_nl2.res_2.btnk.conv2.conv.weight     of shape (128, 128, 1, 3, 3)
2022-04-26 15:47:32,058 alphaction.utils.model_serialization INFO: backbone.slow.res_nl2.res_2.btnk.conv3.bn.bias         loaded from backbone.slow.res_nl2.res_2.btnk.conv3.bn.bias         of shape (512,)
2022-04-26 15:47:32,059 alphaction.utils.model_serialization INFO: backbone.slow.res_nl2.res_2.btnk.conv3.bn.running_mean loaded from backbone.slow.res_nl2.res_2.btnk.conv3.bn.running_mean of shape (512,)
2022-04-26 15:47:32,059 alphaction.utils.model_serialization INFO: backbone.slow.res_nl2.res_2.btnk.conv3.bn.running_var  loaded from backbone.slow.res_nl2.res_2.btnk.conv3.bn.running_var  of shape (512,)
2022-04-26 15:47:32,059 alphaction.utils.model_serialization INFO: backbone.slow.res_nl2.res_2.btnk.conv3.bn.weight       loaded from backbone.slow.res_nl2.res_2.btnk.conv3.bn.weight       of shape (512,)
2022-04-26 15:47:32,059 alphaction.utils.model_serialization INFO: backbone.slow.res_nl2.res_2.btnk.conv3.conv.weight     loaded from backbone.slow.res_nl2.res_2.btnk.conv3.conv.weight     of shape (512, 128, 1, 1, 1)
2022-04-26 15:47:32,059 alphaction.utils.model_serialization INFO: backbone.slow.res_nl2.res_3.btnk.conv1.bn.bias         loaded from backbone.slow.res_nl2.res_3.btnk.conv1.bn.bias         of shape (128,)
2022-04-26 15:47:32,059 alphaction.utils.model_serialization INFO: backbone.slow.res_nl2.res_3.btnk.conv1.bn.running_mean loaded from backbone.slow.res_nl2.res_3.btnk.conv1.bn.running_mean of shape (128,)
2022-04-26 15:47:32,059 alphaction.utils.model_serialization INFO: backbone.slow.res_nl2.res_3.btnk.conv1.bn.running_var  loaded from backbone.slow.res_nl2.res_3.btnk.conv1.bn.running_var  of shape (128,)
2022-04-26 15:47:32,059 alphaction.utils.model_serialization INFO: backbone.slow.res_nl2.res_3.btnk.conv1.bn.weight       loaded from backbone.slow.res_nl2.res_3.btnk.conv1.bn.weight       of shape (128,)
2022-04-26 15:47:32,059 alphaction.utils.model_serialization INFO: backbone.slow.res_nl2.res_3.btnk.conv1.conv.weight     loaded from backbone.slow.res_nl2.res_3.btnk.conv1.conv.weight     of shape (128, 512, 1, 1, 1)
2022-04-26 15:47:32,059 alphaction.utils.model_serialization INFO: backbone.slow.res_nl2.res_3.btnk.conv2.bn.bias         loaded from backbone.slow.res_nl2.res_3.btnk.conv2.bn.bias         of shape (128,)
2022-04-26 15:47:32,059 alphaction.utils.model_serialization INFO: backbone.slow.res_nl2.res_3.btnk.conv2.bn.running_mean loaded from backbone.slow.res_nl2.res_3.btnk.conv2.bn.running_mean of shape (128,)
2022-04-26 15:47:32,059 alphaction.utils.model_serialization INFO: backbone.slow.res_nl2.res_3.btnk.conv2.bn.running_var  loaded from backbone.slow.res_nl2.res_3.btnk.conv2.bn.running_var  of shape (128,)
2022-04-26 15:47:32,059 alphaction.utils.model_serialization INFO: backbone.slow.res_nl2.res_3.btnk.conv2.bn.weight       loaded from backbone.slow.res_nl2.res_3.btnk.conv2.bn.weight       of shape (128,)
2022-04-26 15:47:32,059 alphaction.utils.model_serialization INFO: backbone.slow.res_nl2.res_3.btnk.conv2.conv.weight     loaded from backbone.slow.res_nl2.res_3.btnk.conv2.conv.weight     of shape (128, 128, 1, 3, 3)
2022-04-26 15:47:32,059 alphaction.utils.model_serialization INFO: backbone.slow.res_nl2.res_3.btnk.conv3.bn.bias         loaded from backbone.slow.res_nl2.res_3.btnk.conv3.bn.bias         of shape (512,)
2022-04-26 15:47:32,059 alphaction.utils.model_serialization INFO: backbone.slow.res_nl2.res_3.btnk.conv3.bn.running_mean loaded from backbone.slow.res_nl2.res_3.btnk.conv3.bn.running_mean of shape (512,)
2022-04-26 15:47:32,059 alphaction.utils.model_serialization INFO: backbone.slow.res_nl2.res_3.btnk.conv3.bn.running_var  loaded from backbone.slow.res_nl2.res_3.btnk.conv3.bn.running_var  of shape (512,)
2022-04-26 15:47:32,059 alphaction.utils.model_serialization INFO: backbone.slow.res_nl2.res_3.btnk.conv3.bn.weight       loaded from backbone.slow.res_nl2.res_3.btnk.conv3.bn.weight       of shape (512,)
2022-04-26 15:47:32,059 alphaction.utils.model_serialization INFO: backbone.slow.res_nl2.res_3.btnk.conv3.conv.weight     loaded from backbone.slow.res_nl2.res_3.btnk.conv3.conv.weight     of shape (512, 128, 1, 1, 1)
2022-04-26 15:47:32,059 alphaction.utils.model_serialization INFO: backbone.slow.res_nl3.res_0.btnk.conv1.bn.bias         loaded from backbone.slow.res_nl3.res_0.btnk.conv1.bn.bias         of shape (256,)
2022-04-26 15:47:32,059 alphaction.utils.model_serialization INFO: backbone.slow.res_nl3.res_0.btnk.conv1.bn.running_mean loaded from backbone.slow.res_nl3.res_0.btnk.conv1.bn.running_mean of shape (256,)
2022-04-26 15:47:32,059 alphaction.utils.model_serialization INFO: backbone.slow.res_nl3.res_0.btnk.conv1.bn.running_var  loaded from backbone.slow.res_nl3.res_0.btnk.conv1.bn.running_var  of shape (256,)
2022-04-26 15:47:32,059 alphaction.utils.model_serialization INFO: backbone.slow.res_nl3.res_0.btnk.conv1.bn.weight       loaded from backbone.slow.res_nl3.res_0.btnk.conv1.bn.weight       of shape (256,)
2022-04-26 15:47:32,059 alphaction.utils.model_serialization INFO: backbone.slow.res_nl3.res_0.btnk.conv1.conv.weight     loaded from backbone.slow.res_nl3.res_0.btnk.conv1.conv.weight     of shape (256, 640, 3, 1, 1)
2022-04-26 15:47:32,059 alphaction.utils.model_serialization INFO: backbone.slow.res_nl3.res_0.btnk.conv2.bn.bias         loaded from backbone.slow.res_nl3.res_0.btnk.conv2.bn.bias         of shape (256,)
2022-04-26 15:47:32,059 alphaction.utils.model_serialization INFO: backbone.slow.res_nl3.res_0.btnk.conv2.bn.running_mean loaded from backbone.slow.res_nl3.res_0.btnk.conv2.bn.running_mean of shape (256,)
2022-04-26 15:47:32,059 alphaction.utils.model_serialization INFO: backbone.slow.res_nl3.res_0.btnk.conv2.bn.running_var  loaded from backbone.slow.res_nl3.res_0.btnk.conv2.bn.running_var  of shape (256,)
2022-04-26 15:47:32,059 alphaction.utils.model_serialization INFO: backbone.slow.res_nl3.res_0.btnk.conv2.bn.weight       loaded from backbone.slow.res_nl3.res_0.btnk.conv2.bn.weight       of shape (256,)
2022-04-26 15:47:32,059 alphaction.utils.model_serialization INFO: backbone.slow.res_nl3.res_0.btnk.conv2.conv.weight     loaded from backbone.slow.res_nl3.res_0.btnk.conv2.conv.weight     of shape (256, 256, 1, 3, 3)
2022-04-26 15:47:32,060 alphaction.utils.model_serialization INFO: backbone.slow.res_nl3.res_0.btnk.conv3.bn.bias         loaded from backbone.slow.res_nl3.res_0.btnk.conv3.bn.bias         of shape (1024,)
2022-04-26 15:47:32,060 alphaction.utils.model_serialization INFO: backbone.slow.res_nl3.res_0.btnk.conv3.bn.running_mean loaded from backbone.slow.res_nl3.res_0.btnk.conv3.bn.running_mean of shape (1024,)
2022-04-26 15:47:32,060 alphaction.utils.model_serialization INFO: backbone.slow.res_nl3.res_0.btnk.conv3.bn.running_var  loaded from backbone.slow.res_nl3.res_0.btnk.conv3.bn.running_var  of shape (1024,)
2022-04-26 15:47:32,060 alphaction.utils.model_serialization INFO: backbone.slow.res_nl3.res_0.btnk.conv3.bn.weight       loaded from backbone.slow.res_nl3.res_0.btnk.conv3.bn.weight       of shape (1024,)
2022-04-26 15:47:32,060 alphaction.utils.model_serialization INFO: backbone.slow.res_nl3.res_0.btnk.conv3.conv.weight     loaded from backbone.slow.res_nl3.res_0.btnk.conv3.conv.weight     of shape (1024, 256, 1, 1, 1)
2022-04-26 15:47:32,060 alphaction.utils.model_serialization INFO: backbone.slow.res_nl3.res_0.shortcut.bn.bias           loaded from backbone.slow.res_nl3.res_0.shortcut.bn.bias           of shape (1024,)
2022-04-26 15:47:32,060 alphaction.utils.model_serialization INFO: backbone.slow.res_nl3.res_0.shortcut.bn.running_mean   loaded from backbone.slow.res_nl3.res_0.shortcut.bn.running_mean   of shape (1024,)
2022-04-26 15:47:32,060 alphaction.utils.model_serialization INFO: backbone.slow.res_nl3.res_0.shortcut.bn.running_var    loaded from backbone.slow.res_nl3.res_0.shortcut.bn.running_var    of shape (1024,)
2022-04-26 15:47:32,060 alphaction.utils.model_serialization INFO: backbone.slow.res_nl3.res_0.shortcut.bn.weight         loaded from backbone.slow.res_nl3.res_0.shortcut.bn.weight         of shape (1024,)
2022-04-26 15:47:32,060 alphaction.utils.model_serialization INFO: backbone.slow.res_nl3.res_0.shortcut.conv.weight       loaded from backbone.slow.res_nl3.res_0.shortcut.conv.weight       of shape (1024, 640, 1, 1, 1)
2022-04-26 15:47:32,060 alphaction.utils.model_serialization INFO: backbone.slow.res_nl3.res_1.btnk.conv1.bn.bias         loaded from backbone.slow.res_nl3.res_1.btnk.conv1.bn.bias         of shape (256,)
2022-04-26 15:47:32,060 alphaction.utils.model_serialization INFO: backbone.slow.res_nl3.res_1.btnk.conv1.bn.running_mean loaded from backbone.slow.res_nl3.res_1.btnk.conv1.bn.running_mean of shape (256,)
2022-04-26 15:47:32,060 alphaction.utils.model_serialization INFO: backbone.slow.res_nl3.res_1.btnk.conv1.bn.running_var  loaded from backbone.slow.res_nl3.res_1.btnk.conv1.bn.running_var  of shape (256,)
2022-04-26 15:47:32,060 alphaction.utils.model_serialization INFO: backbone.slow.res_nl3.res_1.btnk.conv1.bn.weight       loaded from backbone.slow.res_nl3.res_1.btnk.conv1.bn.weight       of shape (256,)
2022-04-26 15:47:32,060 alphaction.utils.model_serialization INFO: backbone.slow.res_nl3.res_1.btnk.conv1.conv.weight     loaded from backbone.slow.res_nl3.res_1.btnk.conv1.conv.weight     of shape (256, 1024, 3, 1, 1)
2022-04-26 15:47:32,060 alphaction.utils.model_serialization INFO: backbone.slow.res_nl3.res_1.btnk.conv2.bn.bias         loaded from backbone.slow.res_nl3.res_1.btnk.conv2.bn.bias         of shape (256,)
2022-04-26 15:47:32,060 alphaction.utils.model_serialization INFO: backbone.slow.res_nl3.res_1.btnk.conv2.bn.running_mean loaded from backbone.slow.res_nl3.res_1.btnk.conv2.bn.running_mean of shape (256,)
2022-04-26 15:47:32,060 alphaction.utils.model_serialization INFO: backbone.slow.res_nl3.res_1.btnk.conv2.bn.running_var  loaded from backbone.slow.res_nl3.res_1.btnk.conv2.bn.running_var  of shape (256,)
2022-04-26 15:47:32,060 alphaction.utils.model_serialization INFO: backbone.slow.res_nl3.res_1.btnk.conv2.bn.weight       loaded from backbone.slow.res_nl3.res_1.btnk.conv2.bn.weight       of shape (256,)
2022-04-26 15:47:32,060 alphaction.utils.model_serialization INFO: backbone.slow.res_nl3.res_1.btnk.conv2.conv.weight     loaded from backbone.slow.res_nl3.res_1.btnk.conv2.conv.weight     of shape (256, 256, 1, 3, 3)
2022-04-26 15:47:32,060 alphaction.utils.model_serialization INFO: backbone.slow.res_nl3.res_1.btnk.conv3.bn.bias         loaded from backbone.slow.res_nl3.res_1.btnk.conv3.bn.bias         of shape (1024,)
2022-04-26 15:47:32,060 alphaction.utils.model_serialization INFO: backbone.slow.res_nl3.res_1.btnk.conv3.bn.running_mean loaded from backbone.slow.res_nl3.res_1.btnk.conv3.bn.running_mean of shape (1024,)
2022-04-26 15:47:32,060 alphaction.utils.model_serialization INFO: backbone.slow.res_nl3.res_1.btnk.conv3.bn.running_var  loaded from backbone.slow.res_nl3.res_1.btnk.conv3.bn.running_var  of shape (1024,)
2022-04-26 15:47:32,060 alphaction.utils.model_serialization INFO: backbone.slow.res_nl3.res_1.btnk.conv3.bn.weight       loaded from backbone.slow.res_nl3.res_1.btnk.conv3.bn.weight       of shape (1024,)
2022-04-26 15:47:32,060 alphaction.utils.model_serialization INFO: backbone.slow.res_nl3.res_1.btnk.conv3.conv.weight     loaded from backbone.slow.res_nl3.res_1.btnk.conv3.conv.weight     of shape (1024, 256, 1, 1, 1)
2022-04-26 15:47:32,060 alphaction.utils.model_serialization INFO: backbone.slow.res_nl3.res_2.btnk.conv1.bn.bias         loaded from backbone.slow.res_nl3.res_2.btnk.conv1.bn.bias         of shape (256,)
2022-04-26 15:47:32,060 alphaction.utils.model_serialization INFO: backbone.slow.res_nl3.res_2.btnk.conv1.bn.running_mean loaded from backbone.slow.res_nl3.res_2.btnk.conv1.bn.running_mean of shape (256,)
2022-04-26 15:47:32,060 alphaction.utils.model_serialization INFO: backbone.slow.res_nl3.res_2.btnk.conv1.bn.running_var  loaded from backbone.slow.res_nl3.res_2.btnk.conv1.bn.running_var  of shape (256,)
2022-04-26 15:47:32,060 alphaction.utils.model_serialization INFO: backbone.slow.res_nl3.res_2.btnk.conv1.bn.weight       loaded from backbone.slow.res_nl3.res_2.btnk.conv1.bn.weight       of shape (256,)
2022-04-26 15:47:32,061 alphaction.utils.model_serialization INFO: backbone.slow.res_nl3.res_2.btnk.conv1.conv.weight     loaded from backbone.slow.res_nl3.res_2.btnk.conv1.conv.weight     of shape (256, 1024, 3, 1, 1)
2022-04-26 15:47:32,061 alphaction.utils.model_serialization INFO: backbone.slow.res_nl3.res_2.btnk.conv2.bn.bias         loaded from backbone.slow.res_nl3.res_2.btnk.conv2.bn.bias         of shape (256,)
2022-04-26 15:47:32,061 alphaction.utils.model_serialization INFO: backbone.slow.res_nl3.res_2.btnk.conv2.bn.running_mean loaded from backbone.slow.res_nl3.res_2.btnk.conv2.bn.running_mean of shape (256,)
2022-04-26 15:47:32,061 alphaction.utils.model_serialization INFO: backbone.slow.res_nl3.res_2.btnk.conv2.bn.running_var  loaded from backbone.slow.res_nl3.res_2.btnk.conv2.bn.running_var  of shape (256,)
2022-04-26 15:47:32,061 alphaction.utils.model_serialization INFO: backbone.slow.res_nl3.res_2.btnk.conv2.bn.weight       loaded from backbone.slow.res_nl3.res_2.btnk.conv2.bn.weight       of shape (256,)
2022-04-26 15:47:32,061 alphaction.utils.model_serialization INFO: backbone.slow.res_nl3.res_2.btnk.conv2.conv.weight     loaded from backbone.slow.res_nl3.res_2.btnk.conv2.conv.weight     of shape (256, 256, 1, 3, 3)
2022-04-26 15:47:32,061 alphaction.utils.model_serialization INFO: backbone.slow.res_nl3.res_2.btnk.conv3.bn.bias         loaded from backbone.slow.res_nl3.res_2.btnk.conv3.bn.bias         of shape (1024,)
2022-04-26 15:47:32,061 alphaction.utils.model_serialization INFO: backbone.slow.res_nl3.res_2.btnk.conv3.bn.running_mean loaded from backbone.slow.res_nl3.res_2.btnk.conv3.bn.running_mean of shape (1024,)
2022-04-26 15:47:32,061 alphaction.utils.model_serialization INFO: backbone.slow.res_nl3.res_2.btnk.conv3.bn.running_var  loaded from backbone.slow.res_nl3.res_2.btnk.conv3.bn.running_var  of shape (1024,)
2022-04-26 15:47:32,061 alphaction.utils.model_serialization INFO: backbone.slow.res_nl3.res_2.btnk.conv3.bn.weight       loaded from backbone.slow.res_nl3.res_2.btnk.conv3.bn.weight       of shape (1024,)
2022-04-26 15:47:32,061 alphaction.utils.model_serialization INFO: backbone.slow.res_nl3.res_2.btnk.conv3.conv.weight     loaded from backbone.slow.res_nl3.res_2.btnk.conv3.conv.weight     of shape (1024, 256, 1, 1, 1)
2022-04-26 15:47:32,061 alphaction.utils.model_serialization INFO: backbone.slow.res_nl3.res_3.btnk.conv1.bn.bias         loaded from backbone.slow.res_nl3.res_3.btnk.conv1.bn.bias         of shape (256,)
2022-04-26 15:47:32,061 alphaction.utils.model_serialization INFO: backbone.slow.res_nl3.res_3.btnk.conv1.bn.running_mean loaded from backbone.slow.res_nl3.res_3.btnk.conv1.bn.running_mean of shape (256,)
2022-04-26 15:47:32,061 alphaction.utils.model_serialization INFO: backbone.slow.res_nl3.res_3.btnk.conv1.bn.running_var  loaded from backbone.slow.res_nl3.res_3.btnk.conv1.bn.running_var  of shape (256,)
2022-04-26 15:47:32,061 alphaction.utils.model_serialization INFO: backbone.slow.res_nl3.res_3.btnk.conv1.bn.weight       loaded from backbone.slow.res_nl3.res_3.btnk.conv1.bn.weight       of shape (256,)
2022-04-26 15:47:32,061 alphaction.utils.model_serialization INFO: backbone.slow.res_nl3.res_3.btnk.conv1.conv.weight     loaded from backbone.slow.res_nl3.res_3.btnk.conv1.conv.weight     of shape (256, 1024, 3, 1, 1)
2022-04-26 15:47:32,061 alphaction.utils.model_serialization INFO: backbone.slow.res_nl3.res_3.btnk.conv2.bn.bias         loaded from backbone.slow.res_nl3.res_3.btnk.conv2.bn.bias         of shape (256,)
2022-04-26 15:47:32,061 alphaction.utils.model_serialization INFO: backbone.slow.res_nl3.res_3.btnk.conv2.bn.running_mean loaded from backbone.slow.res_nl3.res_3.btnk.conv2.bn.running_mean of shape (256,)
2022-04-26 15:47:32,061 alphaction.utils.model_serialization INFO: backbone.slow.res_nl3.res_3.btnk.conv2.bn.running_var  loaded from backbone.slow.res_nl3.res_3.btnk.conv2.bn.running_var  of shape (256,)
2022-04-26 15:47:32,061 alphaction.utils.model_serialization INFO: backbone.slow.res_nl3.res_3.btnk.conv2.bn.weight       loaded from backbone.slow.res_nl3.res_3.btnk.conv2.bn.weight       of shape (256,)
2022-04-26 15:47:32,061 alphaction.utils.model_serialization INFO: backbone.slow.res_nl3.res_3.btnk.conv2.conv.weight     loaded from backbone.slow.res_nl3.res_3.btnk.conv2.conv.weight     of shape (256, 256, 1, 3, 3)
2022-04-26 15:47:32,061 alphaction.utils.model_serialization INFO: backbone.slow.res_nl3.res_3.btnk.conv3.bn.bias         loaded from backbone.slow.res_nl3.res_3.btnk.conv3.bn.bias         of shape (1024,)
2022-04-26 15:47:32,061 alphaction.utils.model_serialization INFO: backbone.slow.res_nl3.res_3.btnk.conv3.bn.running_mean loaded from backbone.slow.res_nl3.res_3.btnk.conv3.bn.running_mean of shape (1024,)
2022-04-26 15:47:32,061 alphaction.utils.model_serialization INFO: backbone.slow.res_nl3.res_3.btnk.conv3.bn.running_var  loaded from backbone.slow.res_nl3.res_3.btnk.conv3.bn.running_var  of shape (1024,)
2022-04-26 15:47:32,061 alphaction.utils.model_serialization INFO: backbone.slow.res_nl3.res_3.btnk.conv3.bn.weight       loaded from backbone.slow.res_nl3.res_3.btnk.conv3.bn.weight       of shape (1024,)
2022-04-26 15:47:32,061 alphaction.utils.model_serialization INFO: backbone.slow.res_nl3.res_3.btnk.conv3.conv.weight     loaded from backbone.slow.res_nl3.res_3.btnk.conv3.conv.weight     of shape (1024, 256, 1, 1, 1)
2022-04-26 15:47:32,061 alphaction.utils.model_serialization INFO: backbone.slow.res_nl3.res_4.btnk.conv1.bn.bias         loaded from backbone.slow.res_nl3.res_4.btnk.conv1.bn.bias         of shape (256,)
2022-04-26 15:47:32,061 alphaction.utils.model_serialization INFO: backbone.slow.res_nl3.res_4.btnk.conv1.bn.running_mean loaded from backbone.slow.res_nl3.res_4.btnk.conv1.bn.running_mean of shape (256,)
2022-04-26 15:47:32,061 alphaction.utils.model_serialization INFO: backbone.slow.res_nl3.res_4.btnk.conv1.bn.running_var  loaded from backbone.slow.res_nl3.res_4.btnk.conv1.bn.running_var  of shape (256,)
2022-04-26 15:47:32,061 alphaction.utils.model_serialization INFO: backbone.slow.res_nl3.res_4.btnk.conv1.bn.weight       loaded from backbone.slow.res_nl3.res_4.btnk.conv1.bn.weight       of shape (256,)
2022-04-26 15:47:32,062 alphaction.utils.model_serialization INFO: backbone.slow.res_nl3.res_4.btnk.conv1.conv.weight     loaded from backbone.slow.res_nl3.res_4.btnk.conv1.conv.weight     of shape (256, 1024, 3, 1, 1)
2022-04-26 15:47:32,062 alphaction.utils.model_serialization INFO: backbone.slow.res_nl3.res_4.btnk.conv2.bn.bias         loaded from backbone.slow.res_nl3.res_4.btnk.conv2.bn.bias         of shape (256,)
2022-04-26 15:47:32,062 alphaction.utils.model_serialization INFO: backbone.slow.res_nl3.res_4.btnk.conv2.bn.running_mean loaded from backbone.slow.res_nl3.res_4.btnk.conv2.bn.running_mean of shape (256,)
2022-04-26 15:47:32,062 alphaction.utils.model_serialization INFO: backbone.slow.res_nl3.res_4.btnk.conv2.bn.running_var  loaded from backbone.slow.res_nl3.res_4.btnk.conv2.bn.running_var  of shape (256,)
2022-04-26 15:47:32,062 alphaction.utils.model_serialization INFO: backbone.slow.res_nl3.res_4.btnk.conv2.bn.weight       loaded from backbone.slow.res_nl3.res_4.btnk.conv2.bn.weight       of shape (256,)
2022-04-26 15:47:32,062 alphaction.utils.model_serialization INFO: backbone.slow.res_nl3.res_4.btnk.conv2.conv.weight     loaded from backbone.slow.res_nl3.res_4.btnk.conv2.conv.weight     of shape (256, 256, 1, 3, 3)
2022-04-26 15:47:32,062 alphaction.utils.model_serialization INFO: backbone.slow.res_nl3.res_4.btnk.conv3.bn.bias         loaded from backbone.slow.res_nl3.res_4.btnk.conv3.bn.bias         of shape (1024,)
2022-04-26 15:47:32,062 alphaction.utils.model_serialization INFO: backbone.slow.res_nl3.res_4.btnk.conv3.bn.running_mean loaded from backbone.slow.res_nl3.res_4.btnk.conv3.bn.running_mean of shape (1024,)
2022-04-26 15:47:32,062 alphaction.utils.model_serialization INFO: backbone.slow.res_nl3.res_4.btnk.conv3.bn.running_var  loaded from backbone.slow.res_nl3.res_4.btnk.conv3.bn.running_var  of shape (1024,)
2022-04-26 15:47:32,062 alphaction.utils.model_serialization INFO: backbone.slow.res_nl3.res_4.btnk.conv3.bn.weight       loaded from backbone.slow.res_nl3.res_4.btnk.conv3.bn.weight       of shape (1024,)
2022-04-26 15:47:32,062 alphaction.utils.model_serialization INFO: backbone.slow.res_nl3.res_4.btnk.conv3.conv.weight     loaded from backbone.slow.res_nl3.res_4.btnk.conv3.conv.weight     of shape (1024, 256, 1, 1, 1)
2022-04-26 15:47:32,062 alphaction.utils.model_serialization INFO: backbone.slow.res_nl3.res_5.btnk.conv1.bn.bias         loaded from backbone.slow.res_nl3.res_5.btnk.conv1.bn.bias         of shape (256,)
2022-04-26 15:47:32,062 alphaction.utils.model_serialization INFO: backbone.slow.res_nl3.res_5.btnk.conv1.bn.running_mean loaded from backbone.slow.res_nl3.res_5.btnk.conv1.bn.running_mean of shape (256,)
2022-04-26 15:47:32,062 alphaction.utils.model_serialization INFO: backbone.slow.res_nl3.res_5.btnk.conv1.bn.running_var  loaded from backbone.slow.res_nl3.res_5.btnk.conv1.bn.running_var  of shape (256,)
2022-04-26 15:47:32,062 alphaction.utils.model_serialization INFO: backbone.slow.res_nl3.res_5.btnk.conv1.bn.weight       loaded from backbone.slow.res_nl3.res_5.btnk.conv1.bn.weight       of shape (256,)
2022-04-26 15:47:32,062 alphaction.utils.model_serialization INFO: backbone.slow.res_nl3.res_5.btnk.conv1.conv.weight     loaded from backbone.slow.res_nl3.res_5.btnk.conv1.conv.weight     of shape (256, 1024, 3, 1, 1)
2022-04-26 15:47:32,062 alphaction.utils.model_serialization INFO: backbone.slow.res_nl3.res_5.btnk.conv2.bn.bias         loaded from backbone.slow.res_nl3.res_5.btnk.conv2.bn.bias         of shape (256,)
2022-04-26 15:47:32,062 alphaction.utils.model_serialization INFO: backbone.slow.res_nl3.res_5.btnk.conv2.bn.running_mean loaded from backbone.slow.res_nl3.res_5.btnk.conv2.bn.running_mean of shape (256,)
2022-04-26 15:47:32,062 alphaction.utils.model_serialization INFO: backbone.slow.res_nl3.res_5.btnk.conv2.bn.running_var  loaded from backbone.slow.res_nl3.res_5.btnk.conv2.bn.running_var  of shape (256,)
2022-04-26 15:47:32,062 alphaction.utils.model_serialization INFO: backbone.slow.res_nl3.res_5.btnk.conv2.bn.weight       loaded from backbone.slow.res_nl3.res_5.btnk.conv2.bn.weight       of shape (256,)
2022-04-26 15:47:32,062 alphaction.utils.model_serialization INFO: backbone.slow.res_nl3.res_5.btnk.conv2.conv.weight     loaded from backbone.slow.res_nl3.res_5.btnk.conv2.conv.weight     of shape (256, 256, 1, 3, 3)
2022-04-26 15:47:32,062 alphaction.utils.model_serialization INFO: backbone.slow.res_nl3.res_5.btnk.conv3.bn.bias         loaded from backbone.slow.res_nl3.res_5.btnk.conv3.bn.bias         of shape (1024,)
2022-04-26 15:47:32,062 alphaction.utils.model_serialization INFO: backbone.slow.res_nl3.res_5.btnk.conv3.bn.running_mean loaded from backbone.slow.res_nl3.res_5.btnk.conv3.bn.running_mean of shape (1024,)
2022-04-26 15:47:32,062 alphaction.utils.model_serialization INFO: backbone.slow.res_nl3.res_5.btnk.conv3.bn.running_var  loaded from backbone.slow.res_nl3.res_5.btnk.conv3.bn.running_var  of shape (1024,)
2022-04-26 15:47:32,062 alphaction.utils.model_serialization INFO: backbone.slow.res_nl3.res_5.btnk.conv3.bn.weight       loaded from backbone.slow.res_nl3.res_5.btnk.conv3.bn.weight       of shape (1024,)
2022-04-26 15:47:32,062 alphaction.utils.model_serialization INFO: backbone.slow.res_nl3.res_5.btnk.conv3.conv.weight     loaded from backbone.slow.res_nl3.res_5.btnk.conv3.conv.weight     of shape (1024, 256, 1, 1, 1)
2022-04-26 15:47:32,062 alphaction.utils.model_serialization INFO: backbone.slow.res_nl4.res_0.btnk.conv1.bn.bias         loaded from backbone.slow.res_nl4.res_0.btnk.conv1.bn.bias         of shape (512,)
2022-04-26 15:47:32,062 alphaction.utils.model_serialization INFO: backbone.slow.res_nl4.res_0.btnk.conv1.bn.running_mean loaded from backbone.slow.res_nl4.res_0.btnk.conv1.bn.running_mean of shape (512,)
2022-04-26 15:47:32,063 alphaction.utils.model_serialization INFO: backbone.slow.res_nl4.res_0.btnk.conv1.bn.running_var  loaded from backbone.slow.res_nl4.res_0.btnk.conv1.bn.running_var  of shape (512,)
2022-04-26 15:47:32,063 alphaction.utils.model_serialization INFO: backbone.slow.res_nl4.res_0.btnk.conv1.bn.weight       loaded from backbone.slow.res_nl4.res_0.btnk.conv1.bn.weight       of shape (512,)
2022-04-26 15:47:32,063 alphaction.utils.model_serialization INFO: backbone.slow.res_nl4.res_0.btnk.conv1.conv.weight     loaded from backbone.slow.res_nl4.res_0.btnk.conv1.conv.weight     of shape (512, 1280, 3, 1, 1)
2022-04-26 15:47:32,063 alphaction.utils.model_serialization INFO: backbone.slow.res_nl4.res_0.btnk.conv2.bn.bias         loaded from backbone.slow.res_nl4.res_0.btnk.conv2.bn.bias         of shape (512,)
2022-04-26 15:47:32,063 alphaction.utils.model_serialization INFO: backbone.slow.res_nl4.res_0.btnk.conv2.bn.running_mean loaded from backbone.slow.res_nl4.res_0.btnk.conv2.bn.running_mean of shape (512,)
2022-04-26 15:47:32,063 alphaction.utils.model_serialization INFO: backbone.slow.res_nl4.res_0.btnk.conv2.bn.running_var  loaded from backbone.slow.res_nl4.res_0.btnk.conv2.bn.running_var  of shape (512,)
2022-04-26 15:47:32,063 alphaction.utils.model_serialization INFO: backbone.slow.res_nl4.res_0.btnk.conv2.bn.weight       loaded from backbone.slow.res_nl4.res_0.btnk.conv2.bn.weight       of shape (512,)
2022-04-26 15:47:32,063 alphaction.utils.model_serialization INFO: backbone.slow.res_nl4.res_0.btnk.conv2.conv.weight     loaded from backbone.slow.res_nl4.res_0.btnk.conv2.conv.weight     of shape (512, 512, 1, 3, 3)
2022-04-26 15:47:32,063 alphaction.utils.model_serialization INFO: backbone.slow.res_nl4.res_0.btnk.conv3.bn.bias         loaded from backbone.slow.res_nl4.res_0.btnk.conv3.bn.bias         of shape (2048,)
2022-04-26 15:47:32,063 alphaction.utils.model_serialization INFO: backbone.slow.res_nl4.res_0.btnk.conv3.bn.running_mean loaded from backbone.slow.res_nl4.res_0.btnk.conv3.bn.running_mean of shape (2048,)
2022-04-26 15:47:32,063 alphaction.utils.model_serialization INFO: backbone.slow.res_nl4.res_0.btnk.conv3.bn.running_var  loaded from backbone.slow.res_nl4.res_0.btnk.conv3.bn.running_var  of shape (2048,)
2022-04-26 15:47:32,063 alphaction.utils.model_serialization INFO: backbone.slow.res_nl4.res_0.btnk.conv3.bn.weight       loaded from backbone.slow.res_nl4.res_0.btnk.conv3.bn.weight       of shape (2048,)
2022-04-26 15:47:32,063 alphaction.utils.model_serialization INFO: backbone.slow.res_nl4.res_0.btnk.conv3.conv.weight     loaded from backbone.slow.res_nl4.res_0.btnk.conv3.conv.weight     of shape (2048, 512, 1, 1, 1)
2022-04-26 15:47:32,063 alphaction.utils.model_serialization INFO: backbone.slow.res_nl4.res_0.shortcut.bn.bias           loaded from backbone.slow.res_nl4.res_0.shortcut.bn.bias           of shape (2048,)
2022-04-26 15:47:32,063 alphaction.utils.model_serialization INFO: backbone.slow.res_nl4.res_0.shortcut.bn.running_mean   loaded from backbone.slow.res_nl4.res_0.shortcut.bn.running_mean   of shape (2048,)
2022-04-26 15:47:32,063 alphaction.utils.model_serialization INFO: backbone.slow.res_nl4.res_0.shortcut.bn.running_var    loaded from backbone.slow.res_nl4.res_0.shortcut.bn.running_var    of shape (2048,)
2022-04-26 15:47:32,063 alphaction.utils.model_serialization INFO: backbone.slow.res_nl4.res_0.shortcut.bn.weight         loaded from backbone.slow.res_nl4.res_0.shortcut.bn.weight         of shape (2048,)
2022-04-26 15:47:32,063 alphaction.utils.model_serialization INFO: backbone.slow.res_nl4.res_0.shortcut.conv.weight       loaded from backbone.slow.res_nl4.res_0.shortcut.conv.weight       of shape (2048, 1280, 1, 1, 1)
2022-04-26 15:47:32,063 alphaction.utils.model_serialization INFO: backbone.slow.res_nl4.res_1.btnk.conv1.bn.bias         loaded from backbone.slow.res_nl4.res_1.btnk.conv1.bn.bias         of shape (512,)
2022-04-26 15:47:32,063 alphaction.utils.model_serialization INFO: backbone.slow.res_nl4.res_1.btnk.conv1.bn.running_mean loaded from backbone.slow.res_nl4.res_1.btnk.conv1.bn.running_mean of shape (512,)
2022-04-26 15:47:32,063 alphaction.utils.model_serialization INFO: backbone.slow.res_nl4.res_1.btnk.conv1.bn.running_var  loaded from backbone.slow.res_nl4.res_1.btnk.conv1.bn.running_var  of shape (512,)
2022-04-26 15:47:32,063 alphaction.utils.model_serialization INFO: backbone.slow.res_nl4.res_1.btnk.conv1.bn.weight       loaded from backbone.slow.res_nl4.res_1.btnk.conv1.bn.weight       of shape (512,)
2022-04-26 15:47:32,063 alphaction.utils.model_serialization INFO: backbone.slow.res_nl4.res_1.btnk.conv1.conv.weight     loaded from backbone.slow.res_nl4.res_1.btnk.conv1.conv.weight     of shape (512, 2048, 3, 1, 1)
2022-04-26 15:47:32,063 alphaction.utils.model_serialization INFO: backbone.slow.res_nl4.res_1.btnk.conv2.bn.bias         loaded from backbone.slow.res_nl4.res_1.btnk.conv2.bn.bias         of shape (512,)
2022-04-26 15:47:32,063 alphaction.utils.model_serialization INFO: backbone.slow.res_nl4.res_1.btnk.conv2.bn.running_mean loaded from backbone.slow.res_nl4.res_1.btnk.conv2.bn.running_mean of shape (512,)
2022-04-26 15:47:32,063 alphaction.utils.model_serialization INFO: backbone.slow.res_nl4.res_1.btnk.conv2.bn.running_var  loaded from backbone.slow.res_nl4.res_1.btnk.conv2.bn.running_var  of shape (512,)
2022-04-26 15:47:32,063 alphaction.utils.model_serialization INFO: backbone.slow.res_nl4.res_1.btnk.conv2.bn.weight       loaded from backbone.slow.res_nl4.res_1.btnk.conv2.bn.weight       of shape (512,)
2022-04-26 15:47:32,063 alphaction.utils.model_serialization INFO: backbone.slow.res_nl4.res_1.btnk.conv2.conv.weight     loaded from backbone.slow.res_nl4.res_1.btnk.conv2.conv.weight     of shape (512, 512, 1, 3, 3)
2022-04-26 15:47:32,063 alphaction.utils.model_serialization INFO: backbone.slow.res_nl4.res_1.btnk.conv3.bn.bias         loaded from backbone.slow.res_nl4.res_1.btnk.conv3.bn.bias         of shape (2048,)
2022-04-26 15:47:32,064 alphaction.utils.model_serialization INFO: backbone.slow.res_nl4.res_1.btnk.conv3.bn.running_mean loaded from backbone.slow.res_nl4.res_1.btnk.conv3.bn.running_mean of shape (2048,)
2022-04-26 15:47:32,064 alphaction.utils.model_serialization INFO: backbone.slow.res_nl4.res_1.btnk.conv3.bn.running_var  loaded from backbone.slow.res_nl4.res_1.btnk.conv3.bn.running_var  of shape (2048,)
2022-04-26 15:47:32,064 alphaction.utils.model_serialization INFO: backbone.slow.res_nl4.res_1.btnk.conv3.bn.weight       loaded from backbone.slow.res_nl4.res_1.btnk.conv3.bn.weight       of shape (2048,)
2022-04-26 15:47:32,064 alphaction.utils.model_serialization INFO: backbone.slow.res_nl4.res_1.btnk.conv3.conv.weight     loaded from backbone.slow.res_nl4.res_1.btnk.conv3.conv.weight     of shape (2048, 512, 1, 1, 1)
2022-04-26 15:47:32,064 alphaction.utils.model_serialization INFO: backbone.slow.res_nl4.res_2.btnk.conv1.bn.bias         loaded from backbone.slow.res_nl4.res_2.btnk.conv1.bn.bias         of shape (512,)
2022-04-26 15:47:32,064 alphaction.utils.model_serialization INFO: backbone.slow.res_nl4.res_2.btnk.conv1.bn.running_mean loaded from backbone.slow.res_nl4.res_2.btnk.conv1.bn.running_mean of shape (512,)
2022-04-26 15:47:32,064 alphaction.utils.model_serialization INFO: backbone.slow.res_nl4.res_2.btnk.conv1.bn.running_var  loaded from backbone.slow.res_nl4.res_2.btnk.conv1.bn.running_var  of shape (512,)
2022-04-26 15:47:32,064 alphaction.utils.model_serialization INFO: backbone.slow.res_nl4.res_2.btnk.conv1.bn.weight       loaded from backbone.slow.res_nl4.res_2.btnk.conv1.bn.weight       of shape (512,)
2022-04-26 15:47:32,064 alphaction.utils.model_serialization INFO: backbone.slow.res_nl4.res_2.btnk.conv1.conv.weight     loaded from backbone.slow.res_nl4.res_2.btnk.conv1.conv.weight     of shape (512, 2048, 3, 1, 1)
2022-04-26 15:47:32,064 alphaction.utils.model_serialization INFO: backbone.slow.res_nl4.res_2.btnk.conv2.bn.bias         loaded from backbone.slow.res_nl4.res_2.btnk.conv2.bn.bias         of shape (512,)
2022-04-26 15:47:32,064 alphaction.utils.model_serialization INFO: backbone.slow.res_nl4.res_2.btnk.conv2.bn.running_mean loaded from backbone.slow.res_nl4.res_2.btnk.conv2.bn.running_mean of shape (512,)
2022-04-26 15:47:32,064 alphaction.utils.model_serialization INFO: backbone.slow.res_nl4.res_2.btnk.conv2.bn.running_var  loaded from backbone.slow.res_nl4.res_2.btnk.conv2.bn.running_var  of shape (512,)
2022-04-26 15:47:32,064 alphaction.utils.model_serialization INFO: backbone.slow.res_nl4.res_2.btnk.conv2.bn.weight       loaded from backbone.slow.res_nl4.res_2.btnk.conv2.bn.weight       of shape (512,)
2022-04-26 15:47:32,064 alphaction.utils.model_serialization INFO: backbone.slow.res_nl4.res_2.btnk.conv2.conv.weight     loaded from backbone.slow.res_nl4.res_2.btnk.conv2.conv.weight     of shape (512, 512, 1, 3, 3)
2022-04-26 15:47:32,064 alphaction.utils.model_serialization INFO: backbone.slow.res_nl4.res_2.btnk.conv3.bn.bias         loaded from backbone.slow.res_nl4.res_2.btnk.conv3.bn.bias         of shape (2048,)
2022-04-26 15:47:32,064 alphaction.utils.model_serialization INFO: backbone.slow.res_nl4.res_2.btnk.conv3.bn.running_mean loaded from backbone.slow.res_nl4.res_2.btnk.conv3.bn.running_mean of shape (2048,)
2022-04-26 15:47:32,064 alphaction.utils.model_serialization INFO: backbone.slow.res_nl4.res_2.btnk.conv3.bn.running_var  loaded from backbone.slow.res_nl4.res_2.btnk.conv3.bn.running_var  of shape (2048,)
2022-04-26 15:47:32,064 alphaction.utils.model_serialization INFO: backbone.slow.res_nl4.res_2.btnk.conv3.bn.weight       loaded from backbone.slow.res_nl4.res_2.btnk.conv3.bn.weight       of shape (2048,)
2022-04-26 15:47:32,064 alphaction.utils.model_serialization INFO: backbone.slow.res_nl4.res_2.btnk.conv3.conv.weight     loaded from backbone.slow.res_nl4.res_2.btnk.conv3.conv.weight     of shape (2048, 512, 1, 1, 1)
2022-04-26 15:47:32,064 alphaction.utils.model_serialization INFO: roi_heads.action.feature_extractor.fc1.bias will not be loaded.
2022-04-26 15:47:32,064 alphaction.utils.model_serialization INFO: roi_heads.action.feature_extractor.fc1.weight will not be loaded.
2022-04-26 15:47:32,064 alphaction.utils.model_serialization INFO: roi_heads.action.feature_extractor.fc2.bias will not be loaded.
2022-04-26 15:47:32,064 alphaction.utils.model_serialization INFO: roi_heads.action.feature_extractor.fc2.weight will not be loaded.
2022-04-26 15:47:32,064 alphaction.utils.model_serialization INFO: roi_heads.action.predictor.cls_score.bias will not be loaded.
2022-04-26 15:47:32,064 alphaction.utils.model_serialization INFO: roi_heads.action.predictor.cls_score.weight will not be loaded.
2022-04-26 15:47:32,155 alphaction.trainer INFO: Start training
2022-04-26 15:47:43,353 alphaction.trainer INFO: eta: 5 days, 16:49:51  iter: 20  loss_pose_action: 2.0039 (1.9933)  loss_object_interaction: 0.0213 (0.0535)  loss_person_interaction: 0.0235 (0.0557)  total_loss: 3.8337 (5.9606)  accuracy_pose_action: 0.0000 (0.2458)  accuracy_object_interaction: 1.0000 (0.6000)  accuracy_person_interaction: 1.0000 (0.6500)  time: 0.4748 (0.5598)  data: 0.0114 (0.0906)  lr: 0.000032  max mem: 2403
2022-04-26 15:47:52,852 alphaction.trainer INFO: eta: 5 days, 6:27:53  iter: 40  loss_pose_action: 1.6747 (1.9332)  loss_object_interaction: 0.0003 (0.0272)  loss_person_interaction: 0.0002 (0.0282)  total_loss: 2.1891 (4.1337)  accuracy_pose_action: 0.3333 (0.2688)  accuracy_object_interaction: 1.0000 (0.8000)  accuracy_person_interaction: 1.0000 (0.8250)  time: 0.4749 (0.5174)  data: 0.0116 (0.0512)  lr: 0.000033  max mem: 2403
2022-04-26 15:48:02,410 alphaction.trainer INFO: eta: 5 days, 3:14:34  iter: 60  loss_pose_action: 1.6926 (1.9197)  loss_object_interaction: 0.0008 (0.0185)  loss_person_interaction: 0.0008 (0.0192)  total_loss: 2.1242 (3.5361)  accuracy_pose_action: 0.3333 (0.2792)  accuracy_object_interaction: 1.0000 (0.8667)  accuracy_person_interaction: 1.0000 (0.8833)  time: 0.4777 (0.5042)  data: 0.0115 (0.0381)  lr: 0.000034  max mem: 2403
2022-04-26 15:48:12,018 alphaction.trainer INFO: eta: 5 days, 1:47:06  iter: 80  loss_pose_action: 1.3098 (1.7745)  loss_object_interaction: 0.0008 (0.0143)  loss_person_interaction: 0.0009 (0.0148)  total_loss: 1.6846 (3.0805)  accuracy_pose_action: 0.3333 (0.2927)  accuracy_object_interaction: 1.0000 (0.9000)  accuracy_person_interaction: 1.0000 (0.9125)  time: 0.4805 (0.4983)  data: 0.0118 (0.0315)  lr: 0.000035  max mem: 2403
2022-04-26 15:48:21,701 alphaction.trainer INFO: eta: 5 days, 1:05:40  iter: 100  loss_pose_action: 1.4279 (1.7373)  loss_object_interaction: 0.0010 (0.0117)  loss_person_interaction: 0.0014 (0.0121)  total_loss: 1.8379 (2.8620)  accuracy_pose_action: 0.0000 (0.2792)  accuracy_object_interaction: 1.0000 (0.9200)  accuracy_person_interaction: 1.0000 (0.9300)  time: 0.4831 (0.4954)  data: 0.0117 (0.0276)  lr: 0.000036  max mem: 2403
2022-04-26 15:48:21,704 alphaction.utils.checkpoint INFO: Saving checkpoint to data/output/resnet50_4x16f_baseline_robalo/model_0000100.pth
2022-04-26 15:48:22,538 alphaction.inference INFO: Start evaluation on lfv_robalo_val_ava_video dataset(135 videos).
2022-04-26 15:48:37,154 alphaction.inference INFO: Total inference time: 0:00:14.615158 (0.10826042669790763 s / video per device, on 1 devices)
2022-04-26 15:48:37,154 alphaction.inference INFO: performing ava evaluation.
2022-04-26 15:48:37,154 alphaction.inference INFO: Preparing results for AVA format
2022-04-26 15:48:37,172 alphaction.inference INFO: Evaluating predictions
2022-04-26 15:48:37,224 alphaction.inference INFO: ==> 0.0516396 seconds to write file /tmp/tmp9miawriz
2022-04-26 15:48:37,225 alphaction.inference INFO: CATEGORIES (12):
[ {'id': 1, 'name': 'cut (an object)'},
  {'id': 2, 'name': 'holding for (a person)'},
  {'id': 3, 'name': 'handover to (a person)'},
  {'id': 4, 'name': 'squeeze (an object)'},
  {'id': 5, 'name': 'sprinkle (an object)'},
  {'id': 6, 'name': 'transfer (an object)'},
  {'id': 7, 'name': 'pour (an object)'},
  {'id': 8, 'name': 'heat (an object)'},
  {'id': 9, 'name': 'stir (an object)'},
  {'id': 10, 'name': 'wrap (an object)'},
  {'id': 11, 'name': 'roll (an object)'},
  {'id': 12, 'name': 'dip (an object)'}]
2022-04-26 15:48:37,225 alphaction.inference INFO: ==> 0.000459194 seconds to read file data/lfv_robalo/annotations/lfv_robalo_val.csv
2022-04-26 15:48:37,243 alphaction.inference INFO: ==> 0.0175259 seconds to convert groundtruth
2022-04-26 15:48:37,263 alphaction.inference INFO: ==> 0.0198226 seconds to read file /tmp/tmp9miawriz
2022-04-26 15:48:37,600 alphaction.inference INFO: ==> 0.337363 seconds to convert detections
2022-04-26 15:48:37,601 alphaction.inference INFO: The following classes have no ground truth examples: [ 2  3 10 11 12]
2022-04-26 15:48:37,604 alphaction.inference INFO: ==> 0.00328279 seconds to run_evaluator
2022-04-26 15:48:37,605 alphaction.inference INFO: { 'PascalBoxes_PerformanceByCategory/AP@0.5IOU/cut (an object)': 0.4903148440922194,
  'PascalBoxes_PerformanceByCategory/AP@0.5IOU/dip (an object)': nan,
  'PascalBoxes_PerformanceByCategory/AP@0.5IOU/handover to (a person)': nan,
  'PascalBoxes_PerformanceByCategory/AP@0.5IOU/heat (an object)': 0.726614707866648,
  'PascalBoxes_PerformanceByCategory/AP@0.5IOU/holding for (a person)': nan,
  'PascalBoxes_PerformanceByCategory/AP@0.5IOU/pour (an object)': 0.029850746268656716,
  'PascalBoxes_PerformanceByCategory/AP@0.5IOU/roll (an object)': nan,
  'PascalBoxes_PerformanceByCategory/AP@0.5IOU/sprinkle (an object)': 0.023529411764705882,
  'PascalBoxes_PerformanceByCategory/AP@0.5IOU/squeeze (an object)': 0.19893190921228304,
  'PascalBoxes_PerformanceByCategory/AP@0.5IOU/stir (an object)': 0.31114109432642467,
  'PascalBoxes_PerformanceByCategory/AP@0.5IOU/transfer (an object)': 0.3729687740811451,
  'PascalBoxes_PerformanceByCategory/AP@0.5IOU/wrap (an object)': nan,
  'PascalBoxes_Precision/mAP@0.5IOU': 0.30762164108744033}
2022-04-26 15:48:47,385 alphaction.trainer INFO: eta: 5 days, 0:49:33  iter: 120  loss_pose_action: 1.3495 (1.6921)  loss_object_interaction: 0.0005 (0.0098)  loss_person_interaction: 0.0006 (0.0103)  total_loss: 1.6699 (2.6863)  accuracy_pose_action: 0.3333 (0.2854)  accuracy_object_interaction: 1.0000 (0.9333)  accuracy_person_interaction: 1.0000 (0.9417)  time: 0.4883 (0.4944)  data: 0.0118 (0.0250)  lr: 0.000037  max mem: 2403
2022-04-26 15:48:57,384 alphaction.trainer INFO: eta: 5 days, 1:01:08  iter: 140  loss_pose_action: 1.0037 (1.6311)  loss_object_interaction: 0.0005 (0.0085)  loss_person_interaction: 0.0007 (0.0089)  total_loss: 1.2148 (2.5270)  accuracy_pose_action: 0.5000 (0.3077)  accuracy_object_interaction: 1.0000 (0.9429)  accuracy_person_interaction: 1.0000 (0.9500)  time: 0.4986 (0.4952)  data: 0.0117 (0.0231)  lr: 0.000038  max mem: 2403
2022-04-26 15:49:07,494 alphaction.trainer INFO: eta: 5 days, 1:19:55  iter: 160  loss_pose_action: 1.0687 (1.5769)  loss_object_interaction: 0.0005 (0.0076)  loss_person_interaction: 0.0005 (0.0079)  total_loss: 1.3544 (2.3975)  accuracy_pose_action: 0.3333 (0.3151)  accuracy_object_interaction: 1.0000 (0.9500)  accuracy_person_interaction: 1.0000 (0.9563)  time: 0.5078 (0.4964)  data: 0.0121 (0.0218)  lr: 0.000039  max mem: 2403
2022-04-26 15:49:17,610 alphaction.trainer INFO: eta: 5 days, 1:35:00  iter: 180  loss_pose_action: 0.5548 (1.5403)  loss_object_interaction: 0.0002 (0.0068)  loss_person_interaction: 0.0003 (0.0071)  total_loss: 0.7293 (2.3004)  accuracy_pose_action: 0.5000 (0.3375)  accuracy_object_interaction: 1.0000 (0.9556)  accuracy_person_interaction: 1.0000 (0.9611)  time: 0.5083 (0.4975)  data: 0.0123 (0.0208)  lr: 0.000040  max mem: 2403
2022-04-26 15:49:27,786 alphaction.trainer INFO: eta: 5 days, 1:51:27  iter: 200  loss_pose_action: 1.1241 (1.5261)  loss_object_interaction: 0.0007 (0.0062)  loss_person_interaction: 0.0009 (0.0065)  total_loss: 1.4031 (2.2450)  accuracy_pose_action: 0.3333 (0.3442)  accuracy_object_interaction: 1.0000 (0.9600)  accuracy_person_interaction: 1.0000 (0.9650)  time: 0.5120 (0.4986)  data: 0.0119 (0.0200)  lr: 0.000041  max mem: 2403
2022-04-26 15:49:27,790 alphaction.utils.checkpoint INFO: Saving checkpoint to data/output/resnet50_4x16f_baseline_robalo/model_0000200.pth
2022-04-26 15:49:28,048 alphaction.inference INFO: Start evaluation on lfv_robalo_val_ava_video dataset(135 videos).
2022-04-26 15:49:42,948 alphaction.inference INFO: Total inference time: 0:00:14.899449 (0.11036628793787073 s / video per device, on 1 devices)
2022-04-26 15:49:42,948 alphaction.inference INFO: performing ava evaluation.
2022-04-26 15:49:42,948 alphaction.inference INFO: Preparing results for AVA format
2022-04-26 15:49:42,965 alphaction.inference INFO: Evaluating predictions
2022-04-26 15:49:43,016 alphaction.inference INFO: ==> 0.0508492 seconds to write file /tmp/tmpafxi73ah
2022-04-26 15:49:43,016 alphaction.inference INFO: CATEGORIES (12):
[ {'id': 1, 'name': 'cut (an object)'},
  {'id': 2, 'name': 'holding for (a person)'},
  {'id': 3, 'name': 'handover to (a person)'},
  {'id': 4, 'name': 'squeeze (an object)'},
  {'id': 5, 'name': 'sprinkle (an object)'},
  {'id': 6, 'name': 'transfer (an object)'},
  {'id': 7, 'name': 'pour (an object)'},
  {'id': 8, 'name': 'heat (an object)'},
  {'id': 9, 'name': 'stir (an object)'},
  {'id': 10, 'name': 'wrap (an object)'},
  {'id': 11, 'name': 'roll (an object)'},
  {'id': 12, 'name': 'dip (an object)'}]
2022-04-26 15:49:43,017 alphaction.inference INFO: ==> 0.000474215 seconds to read file data/lfv_robalo/annotations/lfv_robalo_val.csv
2022-04-26 15:49:43,035 alphaction.inference INFO: ==> 0.0180123 seconds to convert groundtruth
2022-04-26 15:49:43,055 alphaction.inference INFO: ==> 0.0195653 seconds to read file /tmp/tmpafxi73ah
2022-04-26 15:49:43,388 alphaction.inference INFO: ==> 0.333417 seconds to convert detections
2022-04-26 15:49:43,388 alphaction.inference INFO: The following classes have no ground truth examples: [ 2  3 10 11 12]
2022-04-26 15:49:43,391 alphaction.inference INFO: ==> 0.00269914 seconds to run_evaluator
2022-04-26 15:49:43,392 alphaction.inference INFO: { 'PascalBoxes_PerformanceByCategory/AP@0.5IOU/cut (an object)': 0.6322222384877931,
  'PascalBoxes_PerformanceByCategory/AP@0.5IOU/dip (an object)': nan,
  'PascalBoxes_PerformanceByCategory/AP@0.5IOU/handover to (a person)': nan,
  'PascalBoxes_PerformanceByCategory/AP@0.5IOU/heat (an object)': 0.6715932618405198,
  'PascalBoxes_PerformanceByCategory/AP@0.5IOU/holding for (a person)': nan,
  'PascalBoxes_PerformanceByCategory/AP@0.5IOU/pour (an object)': 0.03305785123966942,
  'PascalBoxes_PerformanceByCategory/AP@0.5IOU/roll (an object)': nan,
  'PascalBoxes_PerformanceByCategory/AP@0.5IOU/sprinkle (an object)': 0.02631578947368421,
  'PascalBoxes_PerformanceByCategory/AP@0.5IOU/squeeze (an object)': 0.1917379855167873,
  'PascalBoxes_PerformanceByCategory/AP@0.5IOU/stir (an object)': 0.3553529803529803,
  'PascalBoxes_PerformanceByCategory/AP@0.5IOU/transfer (an object)': 0.41158266099539104,
  'PascalBoxes_PerformanceByCategory/AP@0.5IOU/wrap (an object)': nan,
  'PascalBoxes_Precision/mAP@0.5IOU': 0.3316946811295464}
2022-04-26 15:49:53,353 alphaction.trainer INFO: eta: 5 days, 1:50:25  iter: 220  loss_pose_action: 1.1462 (1.4791)  loss_object_interaction: 0.0004 (0.0057)  loss_person_interaction: 0.0003 (0.0060)  total_loss: 1.3834 (2.1549)  accuracy_pose_action: 0.5000 (0.3598)  accuracy_object_interaction: 1.0000 (0.9636)  accuracy_person_interaction: 1.0000 (0.9682)  time: 0.4957 (0.4986)  data: 0.0122 (0.0193)  lr: 0.000042  max mem: 2403
2022-04-26 15:50:03,489 alphaction.trainer INFO: eta: 5 days, 2:00:16  iter: 240  loss_pose_action: 1.3202 (1.4757)  loss_object_interaction: 0.0005 (0.0053)  loss_person_interaction: 0.0005 (0.0056)  total_loss: 1.6151 (2.1241)  accuracy_pose_action: 0.2500 (0.3531)  accuracy_object_interaction: 1.0000 (0.9667)  accuracy_person_interaction: 1.0000 (0.9708)  time: 0.5099 (0.4992)  data: 0.0120 (0.0187)  lr: 0.000042  max mem: 2403
2022-04-26 15:50:13,727 alphaction.trainer INFO: eta: 5 days, 2:14:26  iter: 260  loss_pose_action: 0.8737 (1.4369)  loss_object_interaction: 0.0004 (0.0049)  loss_person_interaction: 0.0004 (0.0052)  total_loss: 1.0863 (2.0532)  accuracy_pose_action: 0.5000 (0.3635)  accuracy_object_interaction: 1.0000 (0.9692)  accuracy_person_interaction: 1.0000 (0.9731)  time: 0.5128 (0.5002)  data: 0.0125 (0.0183)  lr: 0.000043  max mem: 2403
2022-04-26 15:50:23,924 alphaction.trainer INFO: eta: 5 days, 2:24:18  iter: 280  loss_pose_action: 0.5550 (1.3980)  loss_object_interaction: 0.0003 (0.0046)  loss_person_interaction: 0.0003 (0.0048)  total_loss: 0.6925 (1.9856)  accuracy_pose_action: 0.5000 (0.3792)  accuracy_object_interaction: 1.0000 (0.9714)  accuracy_person_interaction: 1.0000 (0.9750)  time: 0.5141 (0.5009)  data: 0.0121 (0.0179)  lr: 0.000044  max mem: 2403
2022-04-26 15:50:34,075 alphaction.trainer INFO: eta: 5 days, 2:30:38  iter: 300  loss_pose_action: 0.9144 (1.3840)  loss_object_interaction: 0.0005 (0.0044)  loss_person_interaction: 0.0005 (0.0046)  total_loss: 1.1226 (1.9518)  accuracy_pose_action: 0.5000 (0.3883)  accuracy_object_interaction: 1.0000 (0.9733)  accuracy_person_interaction: 1.0000 (0.9767)  time: 0.5098 (0.5014)  data: 0.0121 (0.0175)  lr: 0.000045  max mem: 2403
2022-04-26 15:50:34,078 alphaction.utils.checkpoint INFO: Saving checkpoint to data/output/resnet50_4x16f_baseline_robalo/model_0000300.pth
2022-04-26 15:50:34,335 alphaction.inference INFO: Start evaluation on lfv_robalo_val_ava_video dataset(135 videos).
2022-04-26 15:50:49,370 alphaction.inference INFO: Total inference time: 0:00:15.034368 (0.11136568740562157 s / video per device, on 1 devices)
2022-04-26 15:50:49,370 alphaction.inference INFO: performing ava evaluation.
2022-04-26 15:50:49,370 alphaction.inference INFO: Preparing results for AVA format
2022-04-26 15:50:49,387 alphaction.inference INFO: Evaluating predictions
2022-04-26 15:50:49,439 alphaction.inference INFO: ==> 0.0517526 seconds to write file /tmp/tmpexuvoz7g
2022-04-26 15:50:49,440 alphaction.inference INFO: CATEGORIES (12):
[ {'id': 1, 'name': 'cut (an object)'},
  {'id': 2, 'name': 'holding for (a person)'},
  {'id': 3, 'name': 'handover to (a person)'},
  {'id': 4, 'name': 'squeeze (an object)'},
  {'id': 5, 'name': 'sprinkle (an object)'},
  {'id': 6, 'name': 'transfer (an object)'},
  {'id': 7, 'name': 'pour (an object)'},
  {'id': 8, 'name': 'heat (an object)'},
  {'id': 9, 'name': 'stir (an object)'},
  {'id': 10, 'name': 'wrap (an object)'},
  {'id': 11, 'name': 'roll (an object)'},
  {'id': 12, 'name': 'dip (an object)'}]
2022-04-26 15:50:49,440 alphaction.inference INFO: ==> 0.000424385 seconds to read file data/lfv_robalo/annotations/lfv_robalo_val.csv
2022-04-26 15:50:49,458 alphaction.inference INFO: ==> 0.0179687 seconds to convert groundtruth
2022-04-26 15:50:49,478 alphaction.inference INFO: ==> 0.0198853 seconds to read file /tmp/tmpexuvoz7g
2022-04-26 15:50:49,819 alphaction.inference INFO: ==> 0.340405 seconds to convert detections
2022-04-26 15:50:49,819 alphaction.inference INFO: The following classes have no ground truth examples: [ 2  3 10 11 12]
2022-04-26 15:50:49,822 alphaction.inference INFO: ==> 0.00272036 seconds to run_evaluator
2022-04-26 15:50:49,823 alphaction.inference INFO: { 'PascalBoxes_PerformanceByCategory/AP@0.5IOU/cut (an object)': 0.8406827567256219,
  'PascalBoxes_PerformanceByCategory/AP@0.5IOU/dip (an object)': nan,
  'PascalBoxes_PerformanceByCategory/AP@0.5IOU/handover to (a person)': nan,
  'PascalBoxes_PerformanceByCategory/AP@0.5IOU/heat (an object)': 0.7004721122234665,
  'PascalBoxes_PerformanceByCategory/AP@0.5IOU/holding for (a person)': nan,
  'PascalBoxes_PerformanceByCategory/AP@0.5IOU/pour (an object)': 0.06518065268065268,
  'PascalBoxes_PerformanceByCategory/AP@0.5IOU/roll (an object)': nan,
  'PascalBoxes_PerformanceByCategory/AP@0.5IOU/sprinkle (an object)': 0.029116045245077504,
  'PascalBoxes_PerformanceByCategory/AP@0.5IOU/squeeze (an object)': 0.09342057433660486,
  'PascalBoxes_PerformanceByCategory/AP@0.5IOU/stir (an object)': 0.5219252374969253,
  'PascalBoxes_PerformanceByCategory/AP@0.5IOU/transfer (an object)': 0.4289940205151885,
  'PascalBoxes_PerformanceByCategory/AP@0.5IOU/wrap (an object)': nan,
  'PascalBoxes_Precision/mAP@0.5IOU': 0.3828273427462196}
2022-04-26 15:50:59,912 alphaction.trainer INFO: eta: 5 days, 2:33:15  iter: 320  loss_pose_action: 0.5442 (1.3472)  loss_object_interaction: 0.0002 (0.0041)  loss_person_interaction: 0.0002 (0.0043)  total_loss: 0.6715 (1.8909)  accuracy_pose_action: 0.6667 (0.4018)  accuracy_object_interaction: 1.0000 (0.9750)  accuracy_person_interaction: 1.0000 (0.9781)  time: 0.5060 (0.5015)  data: 0.0122 (0.0172)  lr: 0.000046  max mem: 2403
2022-04-26 15:51:10,049 alphaction.trainer INFO: eta: 5 days, 2:37:40  iter: 340  loss_pose_action: 0.7134 (1.3261)  loss_object_interaction: 0.0002 (0.0039)  loss_person_interaction: 0.0002 (0.0041)  total_loss: 0.8718 (1.8506)  accuracy_pose_action: 0.5000 (0.4100)  accuracy_object_interaction: 1.0000 (0.9765)  accuracy_person_interaction: 1.0000 (0.9794)  time: 0.5097 (0.5019)  data: 0.0123 (0.0169)  lr: 0.000047  max mem: 2403
2022-04-26 15:51:20,235 alphaction.trainer INFO: eta: 5 days, 2:43:32  iter: 360  loss_pose_action: 1.0752 (1.3173)  loss_object_interaction: 0.0003 (0.0037)  loss_person_interaction: 0.0003 (0.0039)  total_loss: 1.2935 (1.8270)  accuracy_pose_action: 0.5000 (0.4144)  accuracy_object_interaction: 1.0000 (0.9778)  accuracy_person_interaction: 1.0000 (0.9806)  time: 0.5103 (0.5023)  data: 0.0120 (0.0167)  lr: 0.000048  max mem: 2403
2022-04-26 15:51:30,420 alphaction.trainer INFO: eta: 5 days, 2:48:47  iter: 380  loss_pose_action: 0.7150 (1.2977)  loss_object_interaction: 0.0002 (0.0035)  loss_person_interaction: 0.0002 (0.0037)  total_loss: 0.8808 (1.7916)  accuracy_pose_action: 0.5000 (0.4184)  accuracy_object_interaction: 1.0000 (0.9789)  accuracy_person_interaction: 1.0000 (0.9816)  time: 0.5122 (0.5026)  data: 0.0124 (0.0165)  lr: 0.000049  max mem: 2403
2022-04-26 15:51:40,665 alphaction.trainer INFO: eta: 5 days, 2:55:38  iter: 400  loss_pose_action: 0.8211 (1.2837)  loss_object_interaction: 0.0004 (0.0034)  loss_person_interaction: 0.0004 (0.0035)  total_loss: 0.9949 (1.7647)  accuracy_pose_action: 0.5000 (0.4219)  accuracy_object_interaction: 1.0000 (0.9800)  accuracy_person_interaction: 1.0000 (0.9825)  time: 0.5131 (0.5031)  data: 0.0126 (0.0163)  lr: 0.000050  max mem: 2403
2022-04-26 15:51:40,668 alphaction.utils.checkpoint INFO: Saving checkpoint to data/output/resnet50_4x16f_baseline_robalo/model_0000400.pth
2022-04-26 15:51:40,937 alphaction.inference INFO: Start evaluation on lfv_robalo_val_ava_video dataset(135 videos).
2022-04-26 15:51:55,612 alphaction.inference INFO: Total inference time: 0:00:14.674881 (0.10870282385084364 s / video per device, on 1 devices)
2022-04-26 15:51:55,612 alphaction.inference INFO: performing ava evaluation.
2022-04-26 15:51:55,612 alphaction.inference INFO: Preparing results for AVA format
2022-04-26 15:51:55,630 alphaction.inference INFO: Evaluating predictions
2022-04-26 15:51:55,681 alphaction.inference INFO: ==> 0.0505998 seconds to write file /tmp/tmp_apvpzo5
2022-04-26 15:51:55,682 alphaction.inference INFO: CATEGORIES (12):
[ {'id': 1, 'name': 'cut (an object)'},
  {'id': 2, 'name': 'holding for (a person)'},
  {'id': 3, 'name': 'handover to (a person)'},
  {'id': 4, 'name': 'squeeze (an object)'},
  {'id': 5, 'name': 'sprinkle (an object)'},
  {'id': 6, 'name': 'transfer (an object)'},
  {'id': 7, 'name': 'pour (an object)'},
  {'id': 8, 'name': 'heat (an object)'},
  {'id': 9, 'name': 'stir (an object)'},
  {'id': 10, 'name': 'wrap (an object)'},
  {'id': 11, 'name': 'roll (an object)'},
  {'id': 12, 'name': 'dip (an object)'}]
2022-04-26 15:51:55,683 alphaction.inference INFO: ==> 0.000578165 seconds to read file data/lfv_robalo/annotations/lfv_robalo_val.csv
2022-04-26 15:51:55,700 alphaction.inference INFO: ==> 0.0170846 seconds to convert groundtruth
2022-04-26 15:51:55,719 alphaction.inference INFO: ==> 0.0187364 seconds to read file /tmp/tmp_apvpzo5
2022-04-26 15:51:56,056 alphaction.inference INFO: ==> 0.33689 seconds to convert detections
2022-04-26 15:51:56,056 alphaction.inference INFO: The following classes have no ground truth examples: [ 2  3 10 11 12]
2022-04-26 15:51:56,059 alphaction.inference INFO: ==> 0.00267053 seconds to run_evaluator
2022-04-26 15:51:56,059 alphaction.inference INFO: { 'PascalBoxes_PerformanceByCategory/AP@0.5IOU/cut (an object)': 0.6406389894680938,
  'PascalBoxes_PerformanceByCategory/AP@0.5IOU/dip (an object)': nan,
  'PascalBoxes_PerformanceByCategory/AP@0.5IOU/handover to (a person)': nan,
  'PascalBoxes_PerformanceByCategory/AP@0.5IOU/heat (an object)': 0.6860443064429925,
  'PascalBoxes_PerformanceByCategory/AP@0.5IOU/holding for (a person)': nan,
  'PascalBoxes_PerformanceByCategory/AP@0.5IOU/pour (an object)': 0.06337483853207124,
  'PascalBoxes_PerformanceByCategory/AP@0.5IOU/roll (an object)': nan,
  'PascalBoxes_PerformanceByCategory/AP@0.5IOU/sprinkle (an object)': 0.023268398268398268,
  'PascalBoxes_PerformanceByCategory/AP@0.5IOU/squeeze (an object)': 0.13684278760592597,
  'PascalBoxes_PerformanceByCategory/AP@0.5IOU/stir (an object)': 0.48050395764138804,
  'PascalBoxes_PerformanceByCategory/AP@0.5IOU/transfer (an object)': 0.3924622851895579,
  'PascalBoxes_PerformanceByCategory/AP@0.5IOU/wrap (an object)': nan,
  'PascalBoxes_Precision/mAP@0.5IOU': 0.34616222330691826}
2022-04-26 15:52:06,110 alphaction.trainer INFO: eta: 5 days, 2:55:00  iter: 420  loss_pose_action: 0.9131 (1.2699)  loss_object_interaction: 0.0004 (0.0032)  loss_person_interaction: 0.0003 (0.0034)  total_loss: 1.1048 (1.7395)  accuracy_pose_action: 0.5000 (0.4282)  accuracy_object_interaction: 1.0000 (0.9810)  accuracy_person_interaction: 1.0000 (0.9833)  time: 0.5008 (0.5031)  data: 0.0122 (0.0161)  lr: 0.000051  max mem: 2403
2022-04-26 15:52:16,265 alphaction.trainer INFO: eta: 5 days, 2:57:57  iter: 440  loss_pose_action: 0.6116 (1.2583)  loss_object_interaction: 0.0004 (0.0031)  loss_person_interaction: 0.0004 (0.0033)  total_loss: 0.7581 (1.7179)  accuracy_pose_action: 0.5000 (0.4350)  accuracy_object_interaction: 1.0000 (0.9818)  accuracy_person_interaction: 1.0000 (0.9841)  time: 0.5092 (0.5033)  data: 0.0124 (0.0160)  lr: 0.000052  max mem: 2403
2022-04-26 15:52:26,436 alphaction.trainer INFO: eta: 5 days, 3:01:07  iter: 460  loss_pose_action: 0.5957 (1.2348)  loss_object_interaction: 0.0003 (0.0030)  loss_person_interaction: 0.0004 (0.0031)  total_loss: 0.7527 (1.6817)  accuracy_pose_action: 0.5000 (0.4437)  accuracy_object_interaction: 1.0000 (0.9826)  accuracy_person_interaction: 1.0000 (0.9848)  time: 0.5113 (0.5035)  data: 0.0130 (0.0158)  lr: 0.000053  max mem: 2403
2022-04-26 15:52:36,681 alphaction.trainer INFO: eta: 5 days, 3:06:16  iter: 480  loss_pose_action: 0.5207 (1.2186)  loss_object_interaction: 0.0002 (0.0029)  loss_person_interaction: 0.0003 (0.0030)  total_loss: 0.6499 (1.6549)  accuracy_pose_action: 0.5000 (0.4479)  accuracy_object_interaction: 1.0000 (0.9833)  accuracy_person_interaction: 1.0000 (0.9854)  time: 0.5137 (0.5039)  data: 0.0128 (0.0157)  lr: 0.000054  max mem: 2403
2022-04-26 15:52:46,917 alphaction.trainer INFO: eta: 5 days, 3:10:45  iter: 500  loss_pose_action: 0.3702 (1.1922)  loss_object_interaction: 0.0001 (0.0028)  loss_person_interaction: 0.0001 (0.0029)  total_loss: 0.4830 (1.6165)  accuracy_pose_action: 0.6667 (0.4550)  accuracy_object_interaction: 1.0000 (0.9840)  accuracy_person_interaction: 1.0000 (0.9860)  time: 0.5139 (0.5042)  data: 0.0129 (0.0156)  lr: 0.000055  max mem: 2403
2022-04-26 15:52:46,921 alphaction.utils.checkpoint INFO: Saving checkpoint to data/output/resnet50_4x16f_baseline_robalo/model_0000500.pth
2022-04-26 15:52:47,173 alphaction.inference INFO: Start evaluation on lfv_robalo_val_ava_video dataset(135 videos).
2022-04-26 15:53:01,754 alphaction.inference INFO: Total inference time: 0:00:14.580075 (0.10800055751094112 s / video per device, on 1 devices)
2022-04-26 15:53:01,754 alphaction.inference INFO: performing ava evaluation.
2022-04-26 15:53:01,754 alphaction.inference INFO: Preparing results for AVA format
2022-04-26 15:53:01,770 alphaction.inference INFO: Evaluating predictions
2022-04-26 15:53:01,820 alphaction.inference INFO: ==> 0.0498817 seconds to write file /tmp/tmp8pfr2ipr
2022-04-26 15:53:01,821 alphaction.inference INFO: CATEGORIES (12):
[ {'id': 1, 'name': 'cut (an object)'},
  {'id': 2, 'name': 'holding for (a person)'},
  {'id': 3, 'name': 'handover to (a person)'},
  {'id': 4, 'name': 'squeeze (an object)'},
  {'id': 5, 'name': 'sprinkle (an object)'},
  {'id': 6, 'name': 'transfer (an object)'},
  {'id': 7, 'name': 'pour (an object)'},
  {'id': 8, 'name': 'heat (an object)'},
  {'id': 9, 'name': 'stir (an object)'},
  {'id': 10, 'name': 'wrap (an object)'},
  {'id': 11, 'name': 'roll (an object)'},
  {'id': 12, 'name': 'dip (an object)'}]
2022-04-26 15:53:01,822 alphaction.inference INFO: ==> 0.000814199 seconds to read file data/lfv_robalo/annotations/lfv_robalo_val.csv
2022-04-26 15:53:01,838 alphaction.inference INFO: ==> 0.0163085 seconds to convert groundtruth
2022-04-26 15:53:01,858 alphaction.inference INFO: ==> 0.0192606 seconds to read file /tmp/tmp8pfr2ipr
2022-04-26 15:53:02,186 alphaction.inference INFO: ==> 0.328489 seconds to convert detections
2022-04-26 15:53:02,186 alphaction.inference INFO: The following classes have no ground truth examples: [ 2  3 10 11 12]
2022-04-26 15:53:02,189 alphaction.inference INFO: ==> 0.00267506 seconds to run_evaluator
2022-04-26 15:53:02,190 alphaction.inference INFO: { 'PascalBoxes_PerformanceByCategory/AP@0.5IOU/cut (an object)': 0.6917603741703352,
  'PascalBoxes_PerformanceByCategory/AP@0.5IOU/dip (an object)': nan,
  'PascalBoxes_PerformanceByCategory/AP@0.5IOU/handover to (a person)': nan,
  'PascalBoxes_PerformanceByCategory/AP@0.5IOU/heat (an object)': 0.6639754799637145,
  'PascalBoxes_PerformanceByCategory/AP@0.5IOU/holding for (a person)': nan,
  'PascalBoxes_PerformanceByCategory/AP@0.5IOU/pour (an object)': 0.03667599893117654,
  'PascalBoxes_PerformanceByCategory/AP@0.5IOU/roll (an object)': nan,
  'PascalBoxes_PerformanceByCategory/AP@0.5IOU/sprinkle (an object)': 0.021505376344086023,
  'PascalBoxes_PerformanceByCategory/AP@0.5IOU/squeeze (an object)': 0.2042204172638955,
  'PascalBoxes_PerformanceByCategory/AP@0.5IOU/stir (an object)': 0.5450275906587778,
  'PascalBoxes_PerformanceByCategory/AP@0.5IOU/transfer (an object)': 0.5268416271658828,
  'PascalBoxes_PerformanceByCategory/AP@0.5IOU/wrap (an object)': nan,
  'PascalBoxes_Precision/mAP@0.5IOU': 0.3842866949282669}
2022-04-26 15:53:12,250 alphaction.trainer INFO: eta: 5 days, 3:09:52  iter: 520  loss_pose_action: 0.5441 (1.1874)  loss_object_interaction: 0.0004 (0.0027)  loss_person_interaction: 0.0004 (0.0028)  total_loss: 0.6951 (1.6048)  accuracy_pose_action: 0.5000 (0.4599)  accuracy_object_interaction: 1.0000 (0.9846)  accuracy_person_interaction: 1.0000 (0.9865)  time: 0.4997 (0.5042)  data: 0.0126 (0.0155)  lr: 0.000056  max mem: 2403
2022-04-26 15:53:22,397 alphaction.trainer INFO: eta: 5 days, 3:11:24  iter: 540  loss_pose_action: 0.8023 (1.1791)  loss_object_interaction: 0.0004 (0.0026)  loss_person_interaction: 0.0004 (0.0027)  total_loss: 0.9791 (1.5895)  accuracy_pose_action: 0.5000 (0.4622)  accuracy_object_interaction: 1.0000 (0.9852)  accuracy_person_interaction: 1.0000 (0.9870)  time: 0.5102 (0.5043)  data: 0.0129 (0.0154)  lr: 0.000057  max mem: 2403
2022-04-26 15:53:32,550 alphaction.trainer INFO: eta: 5 days, 3:13:02  iter: 560  loss_pose_action: 0.3390 (1.1624)  loss_object_interaction: 0.0007 (0.0025)  loss_person_interaction: 0.0007 (0.0027)  total_loss: 0.4741 (1.5652)  accuracy_pose_action: 0.5000 (0.4632)  accuracy_object_interaction: 1.0000 (0.9857)  accuracy_person_interaction: 1.0000 (0.9875)  time: 0.5113 (0.5044)  data: 0.0129 (0.0154)  lr: 0.000057  max mem: 2403
2022-04-26 15:53:42,760 alphaction.trainer INFO: eta: 5 days, 3:15:57  iter: 580  loss_pose_action: 0.5981 (1.1462)  loss_object_interaction: 0.0002 (0.0025)  loss_person_interaction: 0.0003 (0.0026)  total_loss: 0.7257 (1.5407)  accuracy_pose_action: 0.5000 (0.4668)  accuracy_object_interaction: 1.0000 (0.9862)  accuracy_person_interaction: 1.0000 (0.9879)  time: 0.5135 (0.5046)  data: 0.0127 (0.0153)  lr: 0.000058  max mem: 2403
2022-04-26 15:53:52,971 alphaction.trainer INFO: eta: 5 days, 3:18:41  iter: 600  loss_pose_action: 0.1787 (1.1224)  loss_object_interaction: 0.0001 (0.0024)  loss_person_interaction: 0.0001 (0.0025)  total_loss: 0.2226 (1.5071)  accuracy_pose_action: 0.6667 (0.4754)  accuracy_object_interaction: 1.0000 (0.9867)  accuracy_person_interaction: 1.0000 (0.9883)  time: 0.5150 (0.5048)  data: 0.0129 (0.0152)  lr: 0.000059  max mem: 2403
2022-04-26 15:53:52,974 alphaction.utils.checkpoint INFO: Saving checkpoint to data/output/resnet50_4x16f_baseline_robalo/model_0000600.pth
2022-04-26 15:53:53,237 alphaction.inference INFO: Start evaluation on lfv_robalo_val_ava_video dataset(135 videos).
2022-04-26 15:54:07,976 alphaction.inference INFO: Total inference time: 0:00:14.739549 (0.10918184386359321 s / video per device, on 1 devices)
2022-04-26 15:54:07,977 alphaction.inference INFO: performing ava evaluation.
2022-04-26 15:54:07,977 alphaction.inference INFO: Preparing results for AVA format
2022-04-26 15:54:07,994 alphaction.inference INFO: Evaluating predictions
2022-04-26 15:54:08,044 alphaction.inference INFO: ==> 0.0496991 seconds to write file /tmp/tmpem1on3xz
2022-04-26 15:54:08,044 alphaction.inference INFO: CATEGORIES (12):
[ {'id': 1, 'name': 'cut (an object)'},
  {'id': 2, 'name': 'holding for (a person)'},
  {'id': 3, 'name': 'handover to (a person)'},
  {'id': 4, 'name': 'squeeze (an object)'},
  {'id': 5, 'name': 'sprinkle (an object)'},
  {'id': 6, 'name': 'transfer (an object)'},
  {'id': 7, 'name': 'pour (an object)'},
  {'id': 8, 'name': 'heat (an object)'},
  {'id': 9, 'name': 'stir (an object)'},
  {'id': 10, 'name': 'wrap (an object)'},
  {'id': 11, 'name': 'roll (an object)'},
  {'id': 12, 'name': 'dip (an object)'}]
2022-04-26 15:54:08,045 alphaction.inference INFO: ==> 0.000535727 seconds to read file data/lfv_robalo/annotations/lfv_robalo_val.csv
2022-04-26 15:54:08,061 alphaction.inference INFO: ==> 0.0163255 seconds to convert groundtruth
2022-04-26 15:54:08,081 alphaction.inference INFO: ==> 0.0200357 seconds to read file /tmp/tmpem1on3xz
2022-04-26 15:54:08,424 alphaction.inference INFO: ==> 0.342684 seconds to convert detections
2022-04-26 15:54:08,424 alphaction.inference INFO: The following classes have no ground truth examples: [ 2  3 10 11 12]
2022-04-26 15:54:08,427 alphaction.inference INFO: ==> 0.00271201 seconds to run_evaluator
2022-04-26 15:54:08,428 alphaction.inference INFO: { 'PascalBoxes_PerformanceByCategory/AP@0.5IOU/cut (an object)': 0.7508033732844811,
  'PascalBoxes_PerformanceByCategory/AP@0.5IOU/dip (an object)': nan,
  'PascalBoxes_PerformanceByCategory/AP@0.5IOU/handover to (a person)': nan,
  'PascalBoxes_PerformanceByCategory/AP@0.5IOU/heat (an object)': 0.683651528894925,
  'PascalBoxes_PerformanceByCategory/AP@0.5IOU/holding for (a person)': nan,
  'PascalBoxes_PerformanceByCategory/AP@0.5IOU/pour (an object)': 0.03484380276933468,
  'PascalBoxes_PerformanceByCategory/AP@0.5IOU/roll (an object)': nan,
  'PascalBoxes_PerformanceByCategory/AP@0.5IOU/sprinkle (an object)': 0.03508771929824561,
  'PascalBoxes_PerformanceByCategory/AP@0.5IOU/squeeze (an object)': 0.19603350189633376,
  'PascalBoxes_PerformanceByCategory/AP@0.5IOU/stir (an object)': 0.3645198399192179,
  'PascalBoxes_PerformanceByCategory/AP@0.5IOU/transfer (an object)': 0.4903722228148844,
  'PascalBoxes_PerformanceByCategory/AP@0.5IOU/wrap (an object)': nan,
  'PascalBoxes_Precision/mAP@0.5IOU': 0.36504456983963174}
2022-04-26 15:54:18,538 alphaction.trainer INFO: eta: 5 days, 3:18:48  iter: 620  loss_pose_action: 0.1625 (1.1029)  loss_object_interaction: 0.0001 (0.0023)  loss_person_interaction: 0.0001 (0.0024)  total_loss: 0.2172 (1.4791)  accuracy_pose_action: 1.0000 (0.4832)  accuracy_object_interaction: 1.0000 (0.9871)  accuracy_person_interaction: 1.0000 (0.9887)  time: 0.5068 (0.5048)  data: 0.0129 (0.0151)  lr: 0.000060  max mem: 2403
2022-04-26 15:54:28,735 alphaction.trainer INFO: eta: 5 days, 3:20:56  iter: 640  loss_pose_action: 0.4770 (1.0876)  loss_object_interaction: 0.0002 (0.0023)  loss_person_interaction: 0.0003 (0.0024)  total_loss: 0.5820 (1.4566)  accuracy_pose_action: 0.6667 (0.4879)  accuracy_object_interaction: 1.0000 (0.9875)  accuracy_person_interaction: 1.0000 (0.9891)  time: 0.5149 (0.5050)  data: 0.0129 (0.0151)  lr: 0.000061  max mem: 2403
2022-04-26 15:54:38,983 alphaction.trainer INFO: eta: 5 days, 3:24:04  iter: 660  loss_pose_action: 0.5638 (1.0741)  loss_object_interaction: 0.0003 (0.0022)  loss_person_interaction: 0.0004 (0.0023)  total_loss: 0.7190 (1.4370)  accuracy_pose_action: 0.5000 (0.4934)  accuracy_object_interaction: 1.0000 (0.9879)  accuracy_person_interaction: 1.0000 (0.9894)  time: 0.5144 (0.5052)  data: 0.0133 (0.0150)  lr: 0.000062  max mem: 2403
2022-04-26 15:54:49,182 alphaction.trainer INFO: eta: 5 days, 3:25:57  iter: 680  loss_pose_action: 0.3566 (1.0563)  loss_object_interaction: 0.0002 (0.0022)  loss_person_interaction: 0.0002 (0.0023)  total_loss: 0.4478 (1.4119)  accuracy_pose_action: 0.6667 (0.5007)  accuracy_object_interaction: 1.0000 (0.9882)  accuracy_person_interaction: 1.0000 (0.9897)  time: 0.5137 (0.5053)  data: 0.0133 (0.0150)  lr: 0.000063  max mem: 2403
2022-04-26 15:54:59,421 alphaction.trainer INFO: eta: 5 days, 3:28:33  iter: 700  loss_pose_action: 0.2172 (1.0455)  loss_object_interaction: 0.0001 (0.0021)  loss_person_interaction: 0.0001 (0.0022)  total_loss: 0.2721 (1.3950)  accuracy_pose_action: 0.6667 (0.5060)  accuracy_object_interaction: 1.0000 (0.9886)  accuracy_person_interaction: 1.0000 (0.9900)  time: 0.5144 (0.5055)  data: 0.0130 (0.0149)  lr: 0.000064  max mem: 2403
2022-04-26 15:54:59,424 alphaction.utils.checkpoint INFO: Saving checkpoint to data/output/resnet50_4x16f_baseline_robalo/model_0000700.pth
2022-04-26 15:54:59,685 alphaction.inference INFO: Start evaluation on lfv_robalo_val_ava_video dataset(135 videos).
2022-04-26 15:55:14,463 alphaction.inference INFO: Total inference time: 0:00:14.777826 (0.10946537476998788 s / video per device, on 1 devices)
2022-04-26 15:55:14,463 alphaction.inference INFO: performing ava evaluation.
2022-04-26 15:55:14,463 alphaction.inference INFO: Preparing results for AVA format
2022-04-26 15:55:14,480 alphaction.inference INFO: Evaluating predictions
2022-04-26 15:55:14,529 alphaction.inference INFO: ==> 0.0490856 seconds to write file /tmp/tmp36pnx705
2022-04-26 15:55:14,530 alphaction.inference INFO: CATEGORIES (12):
[ {'id': 1, 'name': 'cut (an object)'},
  {'id': 2, 'name': 'holding for (a person)'},
  {'id': 3, 'name': 'handover to (a person)'},
  {'id': 4, 'name': 'squeeze (an object)'},
  {'id': 5, 'name': 'sprinkle (an object)'},
  {'id': 6, 'name': 'transfer (an object)'},
  {'id': 7, 'name': 'pour (an object)'},
  {'id': 8, 'name': 'heat (an object)'},
  {'id': 9, 'name': 'stir (an object)'},
  {'id': 10, 'name': 'wrap (an object)'},
  {'id': 11, 'name': 'roll (an object)'},
  {'id': 12, 'name': 'dip (an object)'}]
2022-04-26 15:55:14,530 alphaction.inference INFO: ==> 0.000479221 seconds to read file data/lfv_robalo/annotations/lfv_robalo_val.csv
2022-04-26 15:55:14,547 alphaction.inference INFO: ==> 0.0170856 seconds to convert groundtruth
2022-04-26 15:55:14,568 alphaction.inference INFO: ==> 0.0207143 seconds to read file /tmp/tmp36pnx705
2022-04-26 15:55:14,903 alphaction.inference INFO: ==> 0.334952 seconds to convert detections
2022-04-26 15:55:14,904 alphaction.inference INFO: The following classes have no ground truth examples: [ 2  3 10 11 12]
2022-04-26 15:55:14,906 alphaction.inference INFO: ==> 0.00263858 seconds to run_evaluator
2022-04-26 15:55:14,907 alphaction.inference INFO: { 'PascalBoxes_PerformanceByCategory/AP@0.5IOU/cut (an object)': 0.8446492492928129,
  'PascalBoxes_PerformanceByCategory/AP@0.5IOU/dip (an object)': nan,
  'PascalBoxes_PerformanceByCategory/AP@0.5IOU/handover to (a person)': nan,
  'PascalBoxes_PerformanceByCategory/AP@0.5IOU/heat (an object)': 0.6840259767105267,
  'PascalBoxes_PerformanceByCategory/AP@0.5IOU/holding for (a person)': nan,
  'PascalBoxes_PerformanceByCategory/AP@0.5IOU/pour (an object)': 0.04787767379679145,
  'PascalBoxes_PerformanceByCategory/AP@0.5IOU/roll (an object)': nan,
  'PascalBoxes_PerformanceByCategory/AP@0.5IOU/sprinkle (an object)': 0.02857142857142857,
  'PascalBoxes_PerformanceByCategory/AP@0.5IOU/squeeze (an object)': 0.09915413232448227,
  'PascalBoxes_PerformanceByCategory/AP@0.5IOU/stir (an object)': 0.43478720991652026,
  'PascalBoxes_PerformanceByCategory/AP@0.5IOU/transfer (an object)': 0.44503306148042987,
  'PascalBoxes_PerformanceByCategory/AP@0.5IOU/wrap (an object)': nan,
  'PascalBoxes_Precision/mAP@0.5IOU': 0.3691569617275703}
2022-04-26 15:55:24,974 alphaction.trainer INFO: eta: 5 days, 3:27:26  iter: 720  loss_pose_action: 0.4147 (1.0347)  loss_object_interaction: 0.0002 (0.0021)  loss_person_interaction: 0.0002 (0.0022)  total_loss: 0.5110 (1.3789)  accuracy_pose_action: 0.5000 (0.5101)  accuracy_object_interaction: 1.0000 (0.9889)  accuracy_person_interaction: 1.0000 (0.9903)  time: 0.5029 (0.5055)  data: 0.0130 (0.0149)  lr: 0.000065  max mem: 2403
2022-04-26 15:55:35,203 alphaction.trainer INFO: eta: 5 days, 3:29:38  iter: 740  loss_pose_action: 0.4201 (1.0258)  loss_object_interaction: 0.0001 (0.0020)  loss_person_interaction: 0.0001 (0.0021)  total_loss: 0.5121 (1.3651)  accuracy_pose_action: 0.5000 (0.5145)  accuracy_object_interaction: 1.0000 (0.9892)  accuracy_person_interaction: 1.0000 (0.9905)  time: 0.5118 (0.5056)  data: 0.0129 (0.0148)  lr: 0.000066  max mem: 2403
2022-04-26 15:55:45,411 alphaction.trainer INFO: eta: 5 days, 3:31:20  iter: 760  loss_pose_action: 0.6536 (1.0221)  loss_object_interaction: 0.0004 (0.0020)  loss_person_interaction: 0.0003 (0.0021)  total_loss: 0.8018 (1.3581)  accuracy_pose_action: 0.5000 (0.5155)  accuracy_object_interaction: 1.0000 (0.9895)  accuracy_person_interaction: 1.0000 (0.9908)  time: 0.5137 (0.5058)  data: 0.0131 (0.0148)  lr: 0.000067  max mem: 2403
2022-04-26 15:55:55,633 alphaction.trainer INFO: eta: 5 days, 3:33:10  iter: 780  loss_pose_action: 0.6560 (1.0214)  loss_object_interaction: 0.0005 (0.0019)  loss_person_interaction: 0.0005 (0.0020)  total_loss: 0.8183 (1.3552)  accuracy_pose_action: 0.5000 (0.5170)  accuracy_object_interaction: 1.0000 (0.9897)  accuracy_person_interaction: 1.0000 (0.9910)  time: 0.5115 (0.5059)  data: 0.0130 (0.0148)  lr: 0.000068  max mem: 2403
2022-04-26 15:56:05,877 alphaction.trainer INFO: eta: 5 days, 3:35:18  iter: 800  loss_pose_action: 0.2514 (1.0139)  loss_object_interaction: 0.0004 (0.0019)  loss_person_interaction: 0.0005 (0.0020)  total_loss: 0.4575 (1.3439)  accuracy_pose_action: 0.6667 (0.5205)  accuracy_object_interaction: 1.0000 (0.9900)  accuracy_person_interaction: 1.0000 (0.9912)  time: 0.5125 (0.5060)  data: 0.0133 (0.0147)  lr: 0.000069  max mem: 2403
2022-04-26 15:56:05,881 alphaction.utils.checkpoint INFO: Saving checkpoint to data/output/resnet50_4x16f_baseline_robalo/model_0000800.pth
2022-04-26 15:56:06,138 alphaction.inference INFO: Start evaluation on lfv_robalo_val_ava_video dataset(135 videos).
2022-04-26 15:56:20,701 alphaction.inference INFO: Total inference time: 0:00:14.561971 (0.10786644970929181 s / video per device, on 1 devices)
2022-04-26 15:56:20,701 alphaction.inference INFO: performing ava evaluation.
2022-04-26 15:56:20,701 alphaction.inference INFO: Preparing results for AVA format
2022-04-26 15:56:20,718 alphaction.inference INFO: Evaluating predictions
2022-04-26 15:56:20,770 alphaction.inference INFO: ==> 0.0522292 seconds to write file /tmp/tmp_z9_szw5
2022-04-26 15:56:20,770 alphaction.inference INFO: CATEGORIES (12):
[ {'id': 1, 'name': 'cut (an object)'},
  {'id': 2, 'name': 'holding for (a person)'},
  {'id': 3, 'name': 'handover to (a person)'},
  {'id': 4, 'name': 'squeeze (an object)'},
  {'id': 5, 'name': 'sprinkle (an object)'},
  {'id': 6, 'name': 'transfer (an object)'},
  {'id': 7, 'name': 'pour (an object)'},
  {'id': 8, 'name': 'heat (an object)'},
  {'id': 9, 'name': 'stir (an object)'},
  {'id': 10, 'name': 'wrap (an object)'},
  {'id': 11, 'name': 'roll (an object)'},
  {'id': 12, 'name': 'dip (an object)'}]
2022-04-26 15:56:20,771 alphaction.inference INFO: ==> 0.000432491 seconds to read file data/lfv_robalo/annotations/lfv_robalo_val.csv
2022-04-26 15:56:20,788 alphaction.inference INFO: ==> 0.0168388 seconds to convert groundtruth
2022-04-26 15:56:20,807 alphaction.inference INFO: ==> 0.0190763 seconds to read file /tmp/tmp_z9_szw5
2022-04-26 15:56:21,147 alphaction.inference INFO: ==> 0.339861 seconds to convert detections
2022-04-26 15:56:21,147 alphaction.inference INFO: The following classes have no ground truth examples: [ 2  3 10 11 12]
2022-04-26 15:56:21,150 alphaction.inference INFO: ==> 0.00272226 seconds to run_evaluator
2022-04-26 15:56:21,151 alphaction.inference INFO: { 'PascalBoxes_PerformanceByCategory/AP@0.5IOU/cut (an object)': 0.735393008761121,
  'PascalBoxes_PerformanceByCategory/AP@0.5IOU/dip (an object)': nan,
  'PascalBoxes_PerformanceByCategory/AP@0.5IOU/handover to (a person)': nan,
  'PascalBoxes_PerformanceByCategory/AP@0.5IOU/heat (an object)': 0.6408543190243112,
  'PascalBoxes_PerformanceByCategory/AP@0.5IOU/holding for (a person)': nan,
  'PascalBoxes_PerformanceByCategory/AP@0.5IOU/pour (an object)': 0.18120941558441558,
  'PascalBoxes_PerformanceByCategory/AP@0.5IOU/roll (an object)': nan,
  'PascalBoxes_PerformanceByCategory/AP@0.5IOU/sprinkle (an object)': 0.03662790697674419,
  'PascalBoxes_PerformanceByCategory/AP@0.5IOU/squeeze (an object)': 0.07957474047479893,
  'PascalBoxes_PerformanceByCategory/AP@0.5IOU/stir (an object)': 0.33171157125356493,
  'PascalBoxes_PerformanceByCategory/AP@0.5IOU/transfer (an object)': 0.4015590424866315,
  'PascalBoxes_PerformanceByCategory/AP@0.5IOU/wrap (an object)': nan,
  'PascalBoxes_Precision/mAP@0.5IOU': 0.34384714350879825}
2022-04-26 15:56:31,196 alphaction.trainer INFO: eta: 5 days, 3:33:44  iter: 820  loss_pose_action: 0.3357 (1.0016)  loss_object_interaction: 0.0002 (0.0019)  loss_person_interaction: 0.0003 (0.0020)  total_loss: 0.4355 (1.3269)  accuracy_pose_action: 0.7500 (0.5261)  accuracy_object_interaction: 1.0000 (0.9902)  accuracy_person_interaction: 1.0000 (0.9915)  time: 0.4999 (0.5060)  data: 0.0129 (0.0147)  lr: 0.000070  max mem: 2403
2022-04-26 15:56:41,372 alphaction.trainer INFO: eta: 5 days, 3:34:34  iter: 840  loss_pose_action: 0.5986 (0.9922)  loss_object_interaction: 0.0003 (0.0018)  loss_person_interaction: 0.0002 (0.0019)  total_loss: 0.7587 (1.3132)  accuracy_pose_action: 0.5000 (0.5288)  accuracy_object_interaction: 1.0000 (0.9905)  accuracy_person_interaction: 1.0000 (0.9917)  time: 0.5097 (0.5060)  data: 0.0129 (0.0147)  lr: 0.000071  max mem: 2403
2022-04-26 15:56:51,561 alphaction.trainer INFO: eta: 5 days, 3:35:33  iter: 860  loss_pose_action: 0.1312 (0.9751)  loss_object_interaction: 0.0001 (0.0018)  loss_person_interaction: 0.0001 (0.0019)  total_loss: 0.1720 (1.2901)  accuracy_pose_action: 1.0000 (0.5365)  accuracy_object_interaction: 1.0000 (0.9907)  accuracy_person_interaction: 1.0000 (0.9919)  time: 0.5115 (0.5061)  data: 0.0132 (0.0146)  lr: 0.000072  max mem: 2403
2022-04-26 15:57:01,798 alphaction.trainer INFO: eta: 5 days, 3:37:18  iter: 880  loss_pose_action: 0.0185 (0.9597)  loss_object_interaction: 0.0000 (0.0018)  loss_person_interaction: 0.0000 (0.0018)  total_loss: 0.0507 (1.2691)  accuracy_pose_action: 1.0000 (0.5421)  accuracy_object_interaction: 1.0000 (0.9909)  accuracy_person_interaction: 1.0000 (0.9920)  time: 0.5143 (0.5062)  data: 0.0134 (0.0146)  lr: 0.000072  max mem: 2403
2022-04-26 15:57:12,028 alphaction.trainer INFO: eta: 5 days, 3:38:51  iter: 900  loss_pose_action: 0.2438 (0.9508)  loss_object_interaction: 0.0001 (0.0017)  loss_person_interaction: 0.0001 (0.0018)  total_loss: 0.2991 (1.2560)  accuracy_pose_action: 1.0000 (0.5477)  accuracy_object_interaction: 1.0000 (0.9911)  accuracy_person_interaction: 1.0000 (0.9922)  time: 0.5153 (0.5063)  data: 0.0130 (0.0146)  lr: 0.000073  max mem: 2403
2022-04-26 15:57:12,031 alphaction.utils.checkpoint INFO: Saving checkpoint to data/output/resnet50_4x16f_baseline_robalo/model_0000900.pth
2022-04-26 15:57:12,293 alphaction.inference INFO: Start evaluation on lfv_robalo_val_ava_video dataset(135 videos).
2022-04-26 15:57:27,298 alphaction.inference INFO: Total inference time: 0:00:15.005537 (0.11115212440490722 s / video per device, on 1 devices)
2022-04-26 15:57:27,299 alphaction.inference INFO: performing ava evaluation.
2022-04-26 15:57:27,302 alphaction.inference INFO: Preparing results for AVA format
2022-04-26 15:57:27,318 alphaction.inference INFO: Evaluating predictions
2022-04-26 15:57:27,378 alphaction.inference INFO: ==> 0.0591395 seconds to write file /tmp/tmpeiq1v0zb
2022-04-26 15:57:27,378 alphaction.inference INFO: CATEGORIES (12):
[ {'id': 1, 'name': 'cut (an object)'},
  {'id': 2, 'name': 'holding for (a person)'},
  {'id': 3, 'name': 'handover to (a person)'},
  {'id': 4, 'name': 'squeeze (an object)'},
  {'id': 5, 'name': 'sprinkle (an object)'},
  {'id': 6, 'name': 'transfer (an object)'},
  {'id': 7, 'name': 'pour (an object)'},
  {'id': 8, 'name': 'heat (an object)'},
  {'id': 9, 'name': 'stir (an object)'},
  {'id': 10, 'name': 'wrap (an object)'},
  {'id': 11, 'name': 'roll (an object)'},
  {'id': 12, 'name': 'dip (an object)'}]
2022-04-26 15:57:27,379 alphaction.inference INFO: ==> 0.000470638 seconds to read file data/lfv_robalo/annotations/lfv_robalo_val.csv
2022-04-26 15:57:27,396 alphaction.inference INFO: ==> 0.0168083 seconds to convert groundtruth
2022-04-26 15:57:27,415 alphaction.inference INFO: ==> 0.0194459 seconds to read file /tmp/tmpeiq1v0zb
2022-04-26 15:57:27,754 alphaction.inference INFO: ==> 0.338774 seconds to convert detections
2022-04-26 15:57:27,754 alphaction.inference INFO: The following classes have no ground truth examples: [ 2  3 10 11 12]
2022-04-26 15:57:27,757 alphaction.inference INFO: ==> 0.00274253 seconds to run_evaluator
2022-04-26 15:57:27,758 alphaction.inference INFO: { 'PascalBoxes_PerformanceByCategory/AP@0.5IOU/cut (an object)': 0.7768736353354031,
  'PascalBoxes_PerformanceByCategory/AP@0.5IOU/dip (an object)': nan,
  'PascalBoxes_PerformanceByCategory/AP@0.5IOU/handover to (a person)': nan,
  'PascalBoxes_PerformanceByCategory/AP@0.5IOU/heat (an object)': 0.6612444932694448,
  'PascalBoxes_PerformanceByCategory/AP@0.5IOU/holding for (a person)': nan,
  'PascalBoxes_PerformanceByCategory/AP@0.5IOU/pour (an object)': 0.17116026867799916,
  'PascalBoxes_PerformanceByCategory/AP@0.5IOU/roll (an object)': nan,
  'PascalBoxes_PerformanceByCategory/AP@0.5IOU/sprinkle (an object)': 0.02564102564102564,
  'PascalBoxes_PerformanceByCategory/AP@0.5IOU/squeeze (an object)': 0.07019777608012902,
  'PascalBoxes_PerformanceByCategory/AP@0.5IOU/stir (an object)': 0.447970315784081,
  'PascalBoxes_PerformanceByCategory/AP@0.5IOU/transfer (an object)': 0.4477786386903125,
  'PascalBoxes_PerformanceByCategory/AP@0.5IOU/wrap (an object)': nan,
  'PascalBoxes_Precision/mAP@0.5IOU': 0.37155230763977076}
2022-04-26 15:57:37,809 alphaction.trainer INFO: eta: 5 days, 3:37:26  iter: 920  loss_pose_action: 0.5181 (0.9455)  loss_object_interaction: 0.0002 (0.0017)  loss_person_interaction: 0.0001 (0.0018)  total_loss: 0.6422 (1.2475)  accuracy_pose_action: 0.5000 (0.5483)  accuracy_object_interaction: 1.0000 (0.9913)  accuracy_person_interaction: 1.0000 (0.9924)  time: 0.4994 (0.5063)  data: 0.0128 (0.0145)  lr: 0.000074  max mem: 2403
2022-04-26 15:57:47,977 alphaction.trainer INFO: eta: 5 days, 3:37:56  iter: 940  loss_pose_action: 0.4914 (0.9364)  loss_object_interaction: 0.0001 (0.0017)  loss_person_interaction: 0.0001 (0.0017)  total_loss: 0.5984 (1.2345)  accuracy_pose_action: 0.5000 (0.5492)  accuracy_object_interaction: 1.0000 (0.9915)  accuracy_person_interaction: 1.0000 (0.9926)  time: 0.5104 (0.5063)  data: 0.0135 (0.0145)  lr: 0.000075  max mem: 2403
2022-04-26 15:57:58,222 alphaction.trainer INFO: eta: 5 days, 3:39:34  iter: 960  loss_pose_action: 0.3816 (0.9329)  loss_object_interaction: 0.0002 (0.0016)  loss_person_interaction: 0.0001 (0.0017)  total_loss: 0.4646 (1.2283)  accuracy_pose_action: 0.5000 (0.5501)  accuracy_object_interaction: 1.0000 (0.9917)  accuracy_person_interaction: 1.0000 (0.9927)  time: 0.5141 (0.5064)  data: 0.0134 (0.0145)  lr: 0.000076  max mem: 2403
2022-04-26 15:58:08,450 alphaction.trainer INFO: eta: 5 days, 3:40:54  iter: 980  loss_pose_action: 0.3881 (0.9255)  loss_object_interaction: 0.0004 (0.0016)  loss_person_interaction: 0.0004 (0.0017)  total_loss: 0.4746 (1.2179)  accuracy_pose_action: 0.6667 (0.5531)  accuracy_object_interaction: 1.0000 (0.9918)  accuracy_person_interaction: 1.0000 (0.9929)  time: 0.5119 (0.5065)  data: 0.0133 (0.0145)  lr: 0.000077  max mem: 2403
2022-04-26 15:58:18,687 alphaction.trainer INFO: eta: 5 days, 3:42:17  iter: 1000  loss_pose_action: 0.1404 (0.9145)  loss_object_interaction: 0.0002 (0.0016)  loss_person_interaction: 0.0001 (0.0017)  total_loss: 0.1871 (1.2029)  accuracy_pose_action: 1.0000 (0.5577)  accuracy_object_interaction: 1.0000 (0.9920)  accuracy_person_interaction: 1.0000 (0.9930)  time: 0.5135 (0.5066)  data: 0.0134 (0.0145)  lr: 0.000078  max mem: 2403
2022-04-26 15:58:18,691 alphaction.utils.checkpoint INFO: Saving checkpoint to data/output/resnet50_4x16f_baseline_robalo/model_0001000.pth
2022-04-26 15:58:18,949 alphaction.inference INFO: Start evaluation on lfv_robalo_val_ava_video dataset(135 videos).
2022-04-26 15:58:33,744 alphaction.inference INFO: Total inference time: 0:00:14.794719 (0.10959050743668168 s / video per device, on 1 devices)
2022-04-26 15:58:33,744 alphaction.inference INFO: performing ava evaluation.
2022-04-26 15:58:33,744 alphaction.inference INFO: Preparing results for AVA format
2022-04-26 15:58:33,761 alphaction.inference INFO: Evaluating predictions
2022-04-26 15:58:33,810 alphaction.inference INFO: ==> 0.0490215 seconds to write file /tmp/tmp9cr1hjrl
2022-04-26 15:58:33,811 alphaction.inference INFO: CATEGORIES (12):
[ {'id': 1, 'name': 'cut (an object)'},
  {'id': 2, 'name': 'holding for (a person)'},
  {'id': 3, 'name': 'handover to (a person)'},
  {'id': 4, 'name': 'squeeze (an object)'},
  {'id': 5, 'name': 'sprinkle (an object)'},
  {'id': 6, 'name': 'transfer (an object)'},
  {'id': 7, 'name': 'pour (an object)'},
  {'id': 8, 'name': 'heat (an object)'},
  {'id': 9, 'name': 'stir (an object)'},
  {'id': 10, 'name': 'wrap (an object)'},
  {'id': 11, 'name': 'roll (an object)'},
  {'id': 12, 'name': 'dip (an object)'}]
2022-04-26 15:58:33,811 alphaction.inference INFO: ==> 0.000557423 seconds to read file data/lfv_robalo/annotations/lfv_robalo_val.csv
2022-04-26 15:58:33,830 alphaction.inference INFO: ==> 0.0187061 seconds to convert groundtruth
2022-04-26 15:58:33,851 alphaction.inference INFO: ==> 0.020766 seconds to read file /tmp/tmp9cr1hjrl
2022-04-26 15:58:34,192 alphaction.inference INFO: ==> 0.340214 seconds to convert detections
2022-04-26 15:58:34,192 alphaction.inference INFO: The following classes have no ground truth examples: [ 2  3 10 11 12]
2022-04-26 15:58:34,195 alphaction.inference INFO: ==> 0.00277472 seconds to run_evaluator
2022-04-26 15:58:34,195 alphaction.inference INFO: { 'PascalBoxes_PerformanceByCategory/AP@0.5IOU/cut (an object)': 0.8080643092738148,
  'PascalBoxes_PerformanceByCategory/AP@0.5IOU/dip (an object)': nan,
  'PascalBoxes_PerformanceByCategory/AP@0.5IOU/handover to (a person)': nan,
  'PascalBoxes_PerformanceByCategory/AP@0.5IOU/heat (an object)': 0.616427480495111,
  'PascalBoxes_PerformanceByCategory/AP@0.5IOU/holding for (a person)': nan,
  'PascalBoxes_PerformanceByCategory/AP@0.5IOU/pour (an object)': 0.05212418300653594,
  'PascalBoxes_PerformanceByCategory/AP@0.5IOU/roll (an object)': nan,
  'PascalBoxes_PerformanceByCategory/AP@0.5IOU/sprinkle (an object)': 0.023809523809523808,
  'PascalBoxes_PerformanceByCategory/AP@0.5IOU/squeeze (an object)': 0.05676790401199851,
  'PascalBoxes_PerformanceByCategory/AP@0.5IOU/stir (an object)': 0.43444675695589097,
  'PascalBoxes_PerformanceByCategory/AP@0.5IOU/transfer (an object)': 0.4151372212794807,
  'PascalBoxes_PerformanceByCategory/AP@0.5IOU/wrap (an object)': nan,
  'PascalBoxes_Precision/mAP@0.5IOU': 0.3438253398331937}
2022-04-26 15:58:44,285 alphaction.trainer INFO: eta: 5 days, 3:41:28  iter: 1020  loss_pose_action: 0.2736 (0.9037)  loss_object_interaction: 0.0001 (0.0016)  loss_person_interaction: 0.0001 (0.0016)  total_loss: 0.3335 (1.1882)  accuracy_pose_action: 0.6667 (0.5618)  accuracy_object_interaction: 1.0000 (0.9922)  accuracy_person_interaction: 1.0000 (0.9931)  time: 0.5044 (0.5066)  data: 0.0134 (0.0144)  lr: 0.000079  max mem: 2403
2022-04-26 15:58:54,434 alphaction.trainer INFO: eta: 5 days, 3:41:32  iter: 1040  loss_pose_action: 0.1789 (0.9019)  loss_object_interaction: 0.0001 (0.0015)  loss_person_interaction: 0.0001 (0.0016)  total_loss: 0.2202 (1.1844)  accuracy_pose_action: 0.7500 (0.5634)  accuracy_object_interaction: 1.0000 (0.9923)  accuracy_person_interaction: 1.0000 (0.9933)  time: 0.5094 (0.5066)  data: 0.0134 (0.0144)  lr: 0.000080  max mem: 2403
2022-04-26 15:59:04,670 alphaction.trainer INFO: eta: 5 days, 3:42:47  iter: 1060  loss_pose_action: 0.6427 (0.8994)  loss_object_interaction: 0.0003 (0.0015)  loss_person_interaction: 0.0003 (0.0016)  total_loss: 0.8137 (1.1804)  accuracy_pose_action: 0.5000 (0.5652)  accuracy_object_interaction: 1.0000 (0.9925)  accuracy_person_interaction: 1.0000 (0.9934)  time: 0.5122 (0.5067)  data: 0.0134 (0.0144)  lr: 0.000081  max mem: 2403
2022-04-26 15:59:14,915 alphaction.trainer INFO: eta: 5 days, 3:44:08  iter: 1080  loss_pose_action: 0.1799 (0.8886)  loss_object_interaction: 0.0002 (0.0015)  loss_person_interaction: 0.0001 (0.0016)  total_loss: 0.2320 (1.1659)  accuracy_pose_action: 0.6667 (0.5688)  accuracy_object_interaction: 1.0000 (0.9926)  accuracy_person_interaction: 1.0000 (0.9935)  time: 0.5116 (0.5068)  data: 0.0134 (0.0144)  lr: 0.000082  max mem: 2403
2022-04-26 15:59:25,143 alphaction.trainer INFO: eta: 5 days, 3:45:11  iter: 1100  loss_pose_action: 0.3841 (0.8839)  loss_object_interaction: 0.0004 (0.0015)  loss_person_interaction: 0.0003 (0.0015)  total_loss: 0.4926 (1.1591)  accuracy_pose_action: 0.5000 (0.5683)  accuracy_object_interaction: 1.0000 (0.9927)  accuracy_person_interaction: 1.0000 (0.9936)  time: 0.5105 (0.5069)  data: 0.0135 (0.0144)  lr: 0.000083  max mem: 2403
2022-04-26 15:59:25,146 alphaction.utils.checkpoint INFO: Saving checkpoint to data/output/resnet50_4x16f_baseline_robalo/model_0001100.pth
2022-04-26 15:59:25,408 alphaction.inference INFO: Start evaluation on lfv_robalo_val_ava_video dataset(135 videos).
2022-04-26 15:59:40,282 alphaction.inference INFO: Total inference time: 0:00:14.874091 (0.11017845471700033 s / video per device, on 1 devices)
2022-04-26 15:59:40,282 alphaction.inference INFO: performing ava evaluation.
2022-04-26 15:59:40,282 alphaction.inference INFO: Preparing results for AVA format
2022-04-26 15:59:40,299 alphaction.inference INFO: Evaluating predictions
2022-04-26 15:59:40,348 alphaction.inference INFO: ==> 0.0494282 seconds to write file /tmp/tmpw9hs5md2
2022-04-26 15:59:40,349 alphaction.inference INFO: CATEGORIES (12):
[ {'id': 1, 'name': 'cut (an object)'},
  {'id': 2, 'name': 'holding for (a person)'},
  {'id': 3, 'name': 'handover to (a person)'},
  {'id': 4, 'name': 'squeeze (an object)'},
  {'id': 5, 'name': 'sprinkle (an object)'},
  {'id': 6, 'name': 'transfer (an object)'},
  {'id': 7, 'name': 'pour (an object)'},
  {'id': 8, 'name': 'heat (an object)'},
  {'id': 9, 'name': 'stir (an object)'},
  {'id': 10, 'name': 'wrap (an object)'},
  {'id': 11, 'name': 'roll (an object)'},
  {'id': 12, 'name': 'dip (an object)'}]
2022-04-26 15:59:40,350 alphaction.inference INFO: ==> 0.000566959 seconds to read file data/lfv_robalo/annotations/lfv_robalo_val.csv
2022-04-26 15:59:40,368 alphaction.inference INFO: ==> 0.0186357 seconds to convert groundtruth
2022-04-26 15:59:40,388 alphaction.inference INFO: ==> 0.0195127 seconds to read file /tmp/tmpw9hs5md2
2022-04-26 15:59:40,724 alphaction.inference INFO: ==> 0.336094 seconds to convert detections
2022-04-26 15:59:40,724 alphaction.inference INFO: The following classes have no ground truth examples: [ 2  3 10 11 12]
2022-04-26 15:59:40,727 alphaction.inference INFO: ==> 0.00282979 seconds to run_evaluator
2022-04-26 15:59:40,728 alphaction.inference INFO: { 'PascalBoxes_PerformanceByCategory/AP@0.5IOU/cut (an object)': 0.878262068304144,
  'PascalBoxes_PerformanceByCategory/AP@0.5IOU/dip (an object)': nan,
  'PascalBoxes_PerformanceByCategory/AP@0.5IOU/handover to (a person)': nan,
  'PascalBoxes_PerformanceByCategory/AP@0.5IOU/heat (an object)': 0.7586325756821831,
  'PascalBoxes_PerformanceByCategory/AP@0.5IOU/holding for (a person)': nan,
  'PascalBoxes_PerformanceByCategory/AP@0.5IOU/pour (an object)': 0.06979405034324943,
  'PascalBoxes_PerformanceByCategory/AP@0.5IOU/roll (an object)': nan,
  'PascalBoxes_PerformanceByCategory/AP@0.5IOU/sprinkle (an object)': 0.023809523809523808,
  'PascalBoxes_PerformanceByCategory/AP@0.5IOU/squeeze (an object)': 0.06228866651791078,
  'PascalBoxes_PerformanceByCategory/AP@0.5IOU/stir (an object)': 0.5175917639728231,
  'PascalBoxes_PerformanceByCategory/AP@0.5IOU/transfer (an object)': 0.36620011827969196,
  'PascalBoxes_PerformanceByCategory/AP@0.5IOU/wrap (an object)': nan,
  'PascalBoxes_Precision/mAP@0.5IOU': 0.3823683952727895}
2022-04-26 15:59:50,772 alphaction.trainer INFO: eta: 5 days, 3:43:45  iter: 1120  loss_pose_action: 0.2492 (0.8763)  loss_object_interaction: 0.0002 (0.0015)  loss_person_interaction: 0.0001 (0.0015)  total_loss: 0.3211 (1.1485)  accuracy_pose_action: 1.0000 (0.5721)  accuracy_object_interaction: 1.0000 (0.9929)  accuracy_person_interaction: 1.0000 (0.9938)  time: 0.5004 (0.5068)  data: 0.0134 (0.0144)  lr: 0.000084  max mem: 2403
2022-04-26 16:00:00,923 alphaction.trainer INFO: eta: 5 days, 3:43:46  iter: 1140  loss_pose_action: 0.3054 (0.8700)  loss_object_interaction: 0.0002 (0.0014)  loss_person_interaction: 0.0001 (0.0015)  total_loss: 0.4831 (1.1398)  accuracy_pose_action: 0.6667 (0.5745)  accuracy_object_interaction: 1.0000 (0.9930)  accuracy_person_interaction: 1.0000 (0.9939)  time: 0.5108 (0.5068)  data: 0.0132 (0.0144)  lr: 0.000085  max mem: 2403
2022-04-26 16:00:11,136 alphaction.trainer INFO: eta: 5 days, 3:44:34  iter: 1160  loss_pose_action: 0.2364 (0.8630)  loss_object_interaction: 0.0002 (0.0014)  loss_person_interaction: 0.0002 (0.0015)  total_loss: 0.2918 (1.1300)  accuracy_pose_action: 0.5000 (0.5764)  accuracy_object_interaction: 1.0000 (0.9931)  accuracy_person_interaction: 1.0000 (0.9940)  time: 0.5122 (0.5069)  data: 0.0135 (0.0143)  lr: 0.000086  max mem: 2403
2022-04-26 16:00:21,368 alphaction.trainer INFO: eta: 5 days, 3:45:34  iter: 1180  loss_pose_action: 0.3852 (0.8625)  loss_object_interaction: 0.0003 (0.0014)  loss_person_interaction: 0.0004 (0.0015)  total_loss: 0.5073 (1.1287)  accuracy_pose_action: 0.6667 (0.5781)  accuracy_object_interaction: 1.0000 (0.9932)  accuracy_person_interaction: 1.0000 (0.9941)  time: 0.5127 (0.5070)  data: 0.0136 (0.0143)  lr: 0.000087  max mem: 2403
2022-04-26 16:00:31,608 alphaction.trainer INFO: eta: 5 days, 3:46:37  iter: 1200  loss_pose_action: 0.7302 (0.8642)  loss_object_interaction: 0.0009 (0.0014)  loss_person_interaction: 0.0008 (0.0015)  total_loss: 0.9322 (1.1308)  accuracy_pose_action: 0.5000 (0.5775)  accuracy_object_interaction: 1.0000 (0.9933)  accuracy_person_interaction: 1.0000 (0.9942)  time: 0.5128 (0.5071)  data: 0.0134 (0.0143)  lr: 0.000087  max mem: 2403
2022-04-26 16:00:31,611 alphaction.utils.checkpoint INFO: Saving checkpoint to data/output/resnet50_4x16f_baseline_robalo/model_0001200.pth
2022-04-26 16:00:31,864 alphaction.inference INFO: Start evaluation on lfv_robalo_val_ava_video dataset(135 videos).
2022-04-26 16:00:46,942 alphaction.inference INFO: Total inference time: 0:00:15.077482 (0.11168505350748698 s / video per device, on 1 devices)
2022-04-26 16:00:46,942 alphaction.inference INFO: performing ava evaluation.
2022-04-26 16:00:46,942 alphaction.inference INFO: Preparing results for AVA format
2022-04-26 16:00:46,960 alphaction.inference INFO: Evaluating predictions
2022-04-26 16:00:47,035 alphaction.inference INFO: ==> 0.0751441 seconds to write file /tmp/tmprb5elw3o
2022-04-26 16:00:47,036 alphaction.inference INFO: CATEGORIES (12):
[ {'id': 1, 'name': 'cut (an object)'},
  {'id': 2, 'name': 'holding for (a person)'},
  {'id': 3, 'name': 'handover to (a person)'},
  {'id': 4, 'name': 'squeeze (an object)'},
  {'id': 5, 'name': 'sprinkle (an object)'},
  {'id': 6, 'name': 'transfer (an object)'},
  {'id': 7, 'name': 'pour (an object)'},
  {'id': 8, 'name': 'heat (an object)'},
  {'id': 9, 'name': 'stir (an object)'},
  {'id': 10, 'name': 'wrap (an object)'},
  {'id': 11, 'name': 'roll (an object)'},
  {'id': 12, 'name': 'dip (an object)'}]
2022-04-26 16:00:47,037 alphaction.inference INFO: ==> 0.000774622 seconds to read file data/lfv_robalo/annotations/lfv_robalo_val.csv
2022-04-26 16:00:47,057 alphaction.inference INFO: ==> 0.0201349 seconds to convert groundtruth
2022-04-26 16:00:47,076 alphaction.inference INFO: ==> 0.0191984 seconds to read file /tmp/tmprb5elw3o
2022-04-26 16:00:47,424 alphaction.inference INFO: ==> 0.347194 seconds to convert detections
2022-04-26 16:00:47,424 alphaction.inference INFO: The following classes have no ground truth examples: [ 2  3 10 11 12]
2022-04-26 16:00:47,426 alphaction.inference INFO: ==> 0.00275588 seconds to run_evaluator
2022-04-26 16:00:47,427 alphaction.inference INFO: { 'PascalBoxes_PerformanceByCategory/AP@0.5IOU/cut (an object)': 0.5105083362235221,
  'PascalBoxes_PerformanceByCategory/AP@0.5IOU/dip (an object)': nan,
  'PascalBoxes_PerformanceByCategory/AP@0.5IOU/handover to (a person)': nan,
  'PascalBoxes_PerformanceByCategory/AP@0.5IOU/heat (an object)': 0.5533669518701032,
  'PascalBoxes_PerformanceByCategory/AP@0.5IOU/holding for (a person)': nan,
  'PascalBoxes_PerformanceByCategory/AP@0.5IOU/pour (an object)': 0.21915584415584416,
  'PascalBoxes_PerformanceByCategory/AP@0.5IOU/roll (an object)': nan,
  'PascalBoxes_PerformanceByCategory/AP@0.5IOU/sprinkle (an object)': 0.014814814814814815,
  'PascalBoxes_PerformanceByCategory/AP@0.5IOU/squeeze (an object)': 0.10878140124715469,
  'PascalBoxes_PerformanceByCategory/AP@0.5IOU/stir (an object)': 0.5321196146749859,
  'PascalBoxes_PerformanceByCategory/AP@0.5IOU/transfer (an object)': 0.400211310845662,
  'PascalBoxes_PerformanceByCategory/AP@0.5IOU/wrap (an object)': nan,
  'PascalBoxes_Precision/mAP@0.5IOU': 0.33413689626172666}
2022-04-26 16:00:57,486 alphaction.trainer INFO: eta: 5 days, 3:45:27  iter: 1220  loss_pose_action: 0.2382 (0.8560)  loss_object_interaction: 0.0002 (0.0014)  loss_person_interaction: 0.0002 (0.0015)  total_loss: 0.3219 (1.1198)  accuracy_pose_action: 1.0000 (0.5807)  accuracy_object_interaction: 1.0000 (0.9934)  accuracy_person_interaction: 1.0000 (0.9943)  time: 0.5004 (0.5070)  data: 0.0136 (0.0143)  lr: 0.000088  max mem: 2403
2022-04-26 16:01:07,676 alphaction.trainer INFO: eta: 5 days, 3:45:52  iter: 1240  loss_pose_action: 0.0813 (0.8467)  loss_object_interaction: 0.0001 (0.0014)  loss_person_interaction: 0.0001 (0.0014)  total_loss: 0.0991 (1.1073)  accuracy_pose_action: 1.0000 (0.5847)  accuracy_object_interaction: 1.0000 (0.9935)  accuracy_person_interaction: 1.0000 (0.9944)  time: 0.5120 (0.5070)  data: 0.0136 (0.0143)  lr: 0.000089  max mem: 2403
2022-04-26 16:01:17,892 alphaction.trainer INFO: eta: 5 days, 3:46:35  iter: 1260  loss_pose_action: 0.1869 (0.8388)  loss_object_interaction: 0.0001 (0.0013)  loss_person_interaction: 0.0001 (0.0014)  total_loss: 0.2261 (1.0965)  accuracy_pose_action: 1.0000 (0.5880)  accuracy_object_interaction: 1.0000 (0.9937)  accuracy_person_interaction: 1.0000 (0.9944)  time: 0.5114 (0.5071)  data: 0.0131 (0.0143)  lr: 0.000090  max mem: 2403
2022-04-26 16:01:28,139 alphaction.trainer INFO: eta: 5 days, 3:47:36  iter: 1280  loss_pose_action: 0.3261 (0.8342)  loss_object_interaction: 0.0001 (0.0013)  loss_person_interaction: 0.0001 (0.0014)  total_loss: 0.3992 (1.0899)  accuracy_pose_action: 0.5000 (0.5894)  accuracy_object_interaction: 1.0000 (0.9938)  accuracy_person_interaction: 1.0000 (0.9945)  time: 0.5117 (0.5072)  data: 0.0134 (0.0143)  lr: 0.000091  max mem: 2403
2022-04-26 16:01:38,362 alphaction.trainer INFO: eta: 5 days, 3:48:20  iter: 1300  loss_pose_action: 0.0809 (0.8313)  loss_object_interaction: 0.0002 (0.0013)  loss_person_interaction: 0.0003 (0.0014)  total_loss: 0.1297 (1.0853)  accuracy_pose_action: 0.6667 (0.5915)  accuracy_object_interaction: 1.0000 (0.9938)  accuracy_person_interaction: 1.0000 (0.9946)  time: 0.5124 (0.5072)  data: 0.0135 (0.0143)  lr: 0.000092  max mem: 2403
2022-04-26 16:01:38,365 alphaction.utils.checkpoint INFO: Saving checkpoint to data/output/resnet50_4x16f_baseline_robalo/model_0001300.pth
2022-04-26 16:01:38,626 alphaction.inference INFO: Start evaluation on lfv_robalo_val_ava_video dataset(135 videos).
2022-04-26 16:01:53,305 alphaction.inference INFO: Total inference time: 0:00:14.678819 (0.10873199568854439 s / video per device, on 1 devices)
2022-04-26 16:01:53,306 alphaction.inference INFO: performing ava evaluation.
2022-04-26 16:01:53,306 alphaction.inference INFO: Preparing results for AVA format
2022-04-26 16:01:53,323 alphaction.inference INFO: Evaluating predictions
2022-04-26 16:01:53,373 alphaction.inference INFO: ==> 0.0501473 seconds to write file /tmp/tmphhh_6toe
2022-04-26 16:01:53,373 alphaction.inference INFO: CATEGORIES (12):
[ {'id': 1, 'name': 'cut (an object)'},
  {'id': 2, 'name': 'holding for (a person)'},
  {'id': 3, 'name': 'handover to (a person)'},
  {'id': 4, 'name': 'squeeze (an object)'},
  {'id': 5, 'name': 'sprinkle (an object)'},
  {'id': 6, 'name': 'transfer (an object)'},
  {'id': 7, 'name': 'pour (an object)'},
  {'id': 8, 'name': 'heat (an object)'},
  {'id': 9, 'name': 'stir (an object)'},
  {'id': 10, 'name': 'wrap (an object)'},
  {'id': 11, 'name': 'roll (an object)'},
  {'id': 12, 'name': 'dip (an object)'}]
2022-04-26 16:01:53,374 alphaction.inference INFO: ==> 0.000436783 seconds to read file data/lfv_robalo/annotations/lfv_robalo_val.csv
2022-04-26 16:01:53,393 alphaction.inference INFO: ==> 0.0188286 seconds to convert groundtruth
2022-04-26 16:01:53,413 alphaction.inference INFO: ==> 0.0195725 seconds to read file /tmp/tmphhh_6toe
2022-04-26 16:01:53,744 alphaction.inference INFO: ==> 0.331208 seconds to convert detections
2022-04-26 16:01:53,744 alphaction.inference INFO: The following classes have no ground truth examples: [ 2  3 10 11 12]
2022-04-26 16:01:53,747 alphaction.inference INFO: ==> 0.00279045 seconds to run_evaluator
2022-04-26 16:01:53,748 alphaction.inference INFO: { 'PascalBoxes_PerformanceByCategory/AP@0.5IOU/cut (an object)': 0.4511242488410215,
  'PascalBoxes_PerformanceByCategory/AP@0.5IOU/dip (an object)': nan,
  'PascalBoxes_PerformanceByCategory/AP@0.5IOU/handover to (a person)': nan,
  'PascalBoxes_PerformanceByCategory/AP@0.5IOU/heat (an object)': 0.7302639873295798,
  'PascalBoxes_PerformanceByCategory/AP@0.5IOU/holding for (a person)': nan,
  'PascalBoxes_PerformanceByCategory/AP@0.5IOU/pour (an object)': 0.06547619047619047,
  'PascalBoxes_PerformanceByCategory/AP@0.5IOU/roll (an object)': nan,
  'PascalBoxes_PerformanceByCategory/AP@0.5IOU/sprinkle (an object)': 0.05405405405405406,
  'PascalBoxes_PerformanceByCategory/AP@0.5IOU/squeeze (an object)': 0.10838435374149659,
  'PascalBoxes_PerformanceByCategory/AP@0.5IOU/stir (an object)': 0.42737378592860314,
  'PascalBoxes_PerformanceByCategory/AP@0.5IOU/transfer (an object)': 0.49333525387466787,
  'PascalBoxes_PerformanceByCategory/AP@0.5IOU/wrap (an object)': nan,
  'PascalBoxes_Precision/mAP@0.5IOU': 0.3328588391779448}
2022-04-26 16:02:03,819 alphaction.trainer INFO: eta: 5 days, 3:47:20  iter: 1320  loss_pose_action: 0.0537 (0.8244)  loss_object_interaction: 0.0003 (0.0013)  loss_person_interaction: 0.0004 (0.0014)  total_loss: 0.1088 (1.0762)  accuracy_pose_action: 1.0000 (0.5948)  accuracy_object_interaction: 1.0000 (0.9939)  accuracy_person_interaction: 1.0000 (0.9947)  time: 0.5031 (0.5072)  data: 0.0132 (0.0143)  lr: 0.000093  max mem: 2403
2022-04-26 16:02:13,984 alphaction.trainer INFO: eta: 5 days, 3:47:24  iter: 1340  loss_pose_action: 0.3358 (0.8201)  loss_object_interaction: 0.0002 (0.0013)  loss_person_interaction: 0.0002 (0.0013)  total_loss: 0.4131 (1.0700)  accuracy_pose_action: 0.5000 (0.5956)  accuracy_object_interaction: 1.0000 (0.9940)  accuracy_person_interaction: 1.0000 (0.9948)  time: 0.5104 (0.5072)  data: 0.0135 (0.0143)  lr: 0.000094  max mem: 2403
2022-04-26 16:02:24,156 alphaction.trainer INFO: eta: 5 days, 3:47:32  iter: 1360  loss_pose_action: 0.1643 (0.8114)  loss_object_interaction: 0.0001 (0.0013)  loss_person_interaction: 0.0001 (0.0013)  total_loss: 0.2156 (1.0585)  accuracy_pose_action: 0.7500 (0.5988)  accuracy_object_interaction: 1.0000 (0.9941)  accuracy_person_interaction: 1.0000 (0.9949)  time: 0.5138 (0.5072)  data: 0.0137 (0.0143)  lr: 0.000095  max mem: 2403
2022-04-26 16:02:34,375 alphaction.trainer INFO: eta: 5 days, 3:48:10  iter: 1380  loss_pose_action: 0.2082 (0.8084)  loss_object_interaction: 0.0000 (0.0013)  loss_person_interaction: 0.0000 (0.0013)  total_loss: 0.2570 (1.0537)  accuracy_pose_action: 0.6667 (0.6012)  accuracy_object_interaction: 1.0000 (0.9942)  accuracy_person_interaction: 1.0000 (0.9949)  time: 0.5138 (0.5073)  data: 0.0133 (0.0142)  lr: 0.000096  max mem: 2403
2022-04-26 16:02:44,632 alphaction.trainer INFO: eta: 5 days, 3:49:10  iter: 1400  loss_pose_action: 0.1700 (0.8046)  loss_object_interaction: 0.0005 (0.0012)  loss_person_interaction: 0.0004 (0.0013)  total_loss: 0.2594 (1.0488)  accuracy_pose_action: 1.0000 (0.6036)  accuracy_object_interaction: 1.0000 (0.9943)  accuracy_person_interaction: 1.0000 (0.9950)  time: 0.5160 (0.5073)  data: 0.0137 (0.0142)  lr: 0.000097  max mem: 2403
2022-04-26 16:02:44,636 alphaction.utils.checkpoint INFO: Saving checkpoint to data/output/resnet50_4x16f_baseline_robalo/model_0001400.pth
2022-04-26 16:02:44,895 alphaction.inference INFO: Start evaluation on lfv_robalo_val_ava_video dataset(135 videos).
2022-04-26 16:02:59,460 alphaction.inference INFO: Total inference time: 0:00:14.565248 (0.10789072425277145 s / video per device, on 1 devices)
2022-04-26 16:02:59,461 alphaction.inference INFO: performing ava evaluation.
2022-04-26 16:02:59,461 alphaction.inference INFO: Preparing results for AVA format
2022-04-26 16:02:59,477 alphaction.inference INFO: Evaluating predictions
2022-04-26 16:02:59,528 alphaction.inference INFO: ==> 0.0508018 seconds to write file /tmp/tmpr4n6n_s8
2022-04-26 16:02:59,528 alphaction.inference INFO: CATEGORIES (12):
[ {'id': 1, 'name': 'cut (an object)'},
  {'id': 2, 'name': 'holding for (a person)'},
  {'id': 3, 'name': 'handover to (a person)'},
  {'id': 4, 'name': 'squeeze (an object)'},
  {'id': 5, 'name': 'sprinkle (an object)'},
  {'id': 6, 'name': 'transfer (an object)'},
  {'id': 7, 'name': 'pour (an object)'},
  {'id': 8, 'name': 'heat (an object)'},
  {'id': 9, 'name': 'stir (an object)'},
  {'id': 10, 'name': 'wrap (an object)'},
  {'id': 11, 'name': 'roll (an object)'},
  {'id': 12, 'name': 'dip (an object)'}]
2022-04-26 16:02:59,529 alphaction.inference INFO: ==> 0.00080204 seconds to read file data/lfv_robalo/annotations/lfv_robalo_val.csv
2022-04-26 16:02:59,546 alphaction.inference INFO: ==> 0.0163174 seconds to convert groundtruth
2022-04-26 16:02:59,565 alphaction.inference INFO: ==> 0.0192032 seconds to read file /tmp/tmpr4n6n_s8
2022-04-26 16:02:59,894 alphaction.inference INFO: ==> 0.329232 seconds to convert detections
2022-04-26 16:02:59,894 alphaction.inference INFO: The following classes have no ground truth examples: [ 2  3 10 11 12]
2022-04-26 16:02:59,897 alphaction.inference INFO: ==> 0.00267029 seconds to run_evaluator
2022-04-26 16:02:59,898 alphaction.inference INFO: { 'PascalBoxes_PerformanceByCategory/AP@0.5IOU/cut (an object)': 0.6434749440066724,
  'PascalBoxes_PerformanceByCategory/AP@0.5IOU/dip (an object)': nan,
  'PascalBoxes_PerformanceByCategory/AP@0.5IOU/handover to (a person)': nan,
  'PascalBoxes_PerformanceByCategory/AP@0.5IOU/heat (an object)': 0.7036289321819869,
  'PascalBoxes_PerformanceByCategory/AP@0.5IOU/holding for (a person)': nan,
  'PascalBoxes_PerformanceByCategory/AP@0.5IOU/pour (an object)': 0.1718669250645995,
  'PascalBoxes_PerformanceByCategory/AP@0.5IOU/roll (an object)': nan,
  'PascalBoxes_PerformanceByCategory/AP@0.5IOU/sprinkle (an object)': 0.06135531135531135,
  'PascalBoxes_PerformanceByCategory/AP@0.5IOU/squeeze (an object)': 0.11915530691040896,
  'PascalBoxes_PerformanceByCategory/AP@0.5IOU/stir (an object)': 0.3001374523113654,
  'PascalBoxes_PerformanceByCategory/AP@0.5IOU/transfer (an object)': 0.508392641898288,
  'PascalBoxes_PerformanceByCategory/AP@0.5IOU/wrap (an object)': nan,
  'PascalBoxes_Precision/mAP@0.5IOU': 0.3582873591040904}
2022-04-26 16:03:09,968 alphaction.trainer INFO: eta: 5 days, 3:48:11  iter: 1420  loss_pose_action: 0.0986 (0.7989)  loss_object_interaction: 0.0003 (0.0012)  loss_person_interaction: 0.0002 (0.0013)  total_loss: 0.1714 (1.0411)  accuracy_pose_action: 0.7500 (0.6065)  accuracy_object_interaction: 1.0000 (0.9944)  accuracy_person_interaction: 1.0000 (0.9951)  time: 0.5013 (0.5073)  data: 0.0133 (0.0142)  lr: 0.000098  max mem: 2403
2022-04-26 16:03:20,157 alphaction.trainer INFO: eta: 5 days, 3:48:27  iter: 1440  loss_pose_action: 0.1047 (0.7923)  loss_object_interaction: 0.0002 (0.0012)  loss_person_interaction: 0.0002 (0.0013)  total_loss: 0.1446 (1.0322)  accuracy_pose_action: 1.0000 (0.6091)  accuracy_object_interaction: 1.0000 (0.9944)  accuracy_person_interaction: 1.0000 (0.9951)  time: 0.5129 (0.5073)  data: 0.0135 (0.0142)  lr: 0.000099  max mem: 2403
2022-04-26 16:03:30,389 alphaction.trainer INFO: eta: 5 days, 3:49:08  iter: 1460  loss_pose_action: 0.0289 (0.7828)  loss_object_interaction: 0.0001 (0.0012)  loss_person_interaction: 0.0001 (0.0013)  total_loss: 0.0424 (1.0197)  accuracy_pose_action: 1.0000 (0.6134)  accuracy_object_interaction: 1.0000 (0.9945)  accuracy_person_interaction: 1.0000 (0.9952)  time: 0.5133 (0.5074)  data: 0.0137 (0.0142)  lr: 0.000100  max mem: 2403
2022-04-26 16:03:40,640 alphaction.trainer INFO: eta: 5 days, 3:50:00  iter: 1480  loss_pose_action: 0.0327 (0.7753)  loss_object_interaction: 0.0000 (0.0012)  loss_person_interaction: 0.0000 (0.0012)  total_loss: 0.0424 (1.0098)  accuracy_pose_action: 1.0000 (0.6172)  accuracy_object_interaction: 1.0000 (0.9946)  accuracy_person_interaction: 1.0000 (0.9953)  time: 0.5140 (0.5074)  data: 0.0136 (0.0142)  lr: 0.000101  max mem: 2403
2022-04-26 16:03:50,870 alphaction.trainer INFO: eta: 5 days, 3:50:37  iter: 1500  loss_pose_action: 0.0597 (0.7690)  loss_object_interaction: 0.0001 (0.0012)  loss_person_interaction: 0.0001 (0.0012)  total_loss: 0.0859 (1.0013)  accuracy_pose_action: 1.0000 (0.6205)  accuracy_object_interaction: 1.0000 (0.9947)  accuracy_person_interaction: 1.0000 (0.9953)  time: 0.5154 (0.5075)  data: 0.0138 (0.0142)  lr: 0.000102  max mem: 2403
2022-04-26 16:03:50,873 alphaction.utils.checkpoint INFO: Saving checkpoint to data/output/resnet50_4x16f_baseline_robalo/model_0001500.pth
2022-04-26 16:03:51,138 alphaction.inference INFO: Start evaluation on lfv_robalo_val_ava_video dataset(135 videos).
2022-04-26 16:04:05,765 alphaction.inference INFO: Total inference time: 0:00:14.626931 (0.10834763844807943 s / video per device, on 1 devices)
2022-04-26 16:04:05,765 alphaction.inference INFO: performing ava evaluation.
2022-04-26 16:04:05,765 alphaction.inference INFO: Preparing results for AVA format
2022-04-26 16:04:05,782 alphaction.inference INFO: Evaluating predictions
2022-04-26 16:04:05,832 alphaction.inference INFO: ==> 0.0496037 seconds to write file /tmp/tmpkz7x1lom
2022-04-26 16:04:05,833 alphaction.inference INFO: CATEGORIES (12):
[ {'id': 1, 'name': 'cut (an object)'},
  {'id': 2, 'name': 'holding for (a person)'},
  {'id': 3, 'name': 'handover to (a person)'},
  {'id': 4, 'name': 'squeeze (an object)'},
  {'id': 5, 'name': 'sprinkle (an object)'},
  {'id': 6, 'name': 'transfer (an object)'},
  {'id': 7, 'name': 'pour (an object)'},
  {'id': 8, 'name': 'heat (an object)'},
  {'id': 9, 'name': 'stir (an object)'},
  {'id': 10, 'name': 'wrap (an object)'},
  {'id': 11, 'name': 'roll (an object)'},
  {'id': 12, 'name': 'dip (an object)'}]
2022-04-26 16:04:05,833 alphaction.inference INFO: ==> 0.000478268 seconds to read file data/lfv_robalo/annotations/lfv_robalo_val.csv
2022-04-26 16:04:05,851 alphaction.inference INFO: ==> 0.0180376 seconds to convert groundtruth
2022-04-26 16:04:05,871 alphaction.inference INFO: ==> 0.0191324 seconds to read file /tmp/tmpkz7x1lom
2022-04-26 16:04:06,206 alphaction.inference INFO: ==> 0.334988 seconds to convert detections
2022-04-26 16:04:06,206 alphaction.inference INFO: The following classes have no ground truth examples: [ 2  3 10 11 12]
2022-04-26 16:04:06,208 alphaction.inference INFO: ==> 0.00266409 seconds to run_evaluator
2022-04-26 16:04:06,209 alphaction.inference INFO: { 'PascalBoxes_PerformanceByCategory/AP@0.5IOU/cut (an object)': 0.854845036855814,
  'PascalBoxes_PerformanceByCategory/AP@0.5IOU/dip (an object)': nan,
  'PascalBoxes_PerformanceByCategory/AP@0.5IOU/handover to (a person)': nan,
  'PascalBoxes_PerformanceByCategory/AP@0.5IOU/heat (an object)': 0.7189165353317594,
  'PascalBoxes_PerformanceByCategory/AP@0.5IOU/holding for (a person)': nan,
  'PascalBoxes_PerformanceByCategory/AP@0.5IOU/pour (an object)': 0.17989417989417988,
  'PascalBoxes_PerformanceByCategory/AP@0.5IOU/roll (an object)': nan,
  'PascalBoxes_PerformanceByCategory/AP@0.5IOU/sprinkle (an object)': 0.08391608391608392,
  'PascalBoxes_PerformanceByCategory/AP@0.5IOU/squeeze (an object)': 0.06987548347258984,
  'PascalBoxes_PerformanceByCategory/AP@0.5IOU/stir (an object)': 0.3485410501352319,
  'PascalBoxes_PerformanceByCategory/AP@0.5IOU/transfer (an object)': 0.4928696784778045,
  'PascalBoxes_PerformanceByCategory/AP@0.5IOU/wrap (an object)': nan,
  'PascalBoxes_Precision/mAP@0.5IOU': 0.39269400686906625}
2022-04-26 16:04:16,311 alphaction.trainer INFO: eta: 5 days, 3:49:58  iter: 1520  loss_pose_action: 0.3037 (0.7654)  loss_object_interaction: 0.0001 (0.0012)  loss_person_interaction: 0.0001 (0.0012)  total_loss: 0.3810 (0.9961)  accuracy_pose_action: 0.6667 (0.6217)  accuracy_object_interaction: 1.0000 (0.9947)  accuracy_person_interaction: 1.0000 (0.9954)  time: 0.5037 (0.5075)  data: 0.0137 (0.0142)  lr: 0.000102  max mem: 2403
2022-04-26 16:04:26,512 alphaction.trainer INFO: eta: 5 days, 3:50:17  iter: 1540  loss_pose_action: 0.2123 (0.7622)  loss_object_interaction: 0.0001 (0.0012)  loss_person_interaction: 0.0002 (0.0012)  total_loss: 0.2796 (0.9915)  accuracy_pose_action: 0.6667 (0.6233)  accuracy_object_interaction: 1.0000 (0.9948)  accuracy_person_interaction: 1.0000 (0.9955)  time: 0.5121 (0.5075)  data: 0.0136 (0.0142)  lr: 0.000103  max mem: 2403
2022-04-26 16:04:36,754 alphaction.trainer INFO: eta: 5 days, 3:50:59  iter: 1560  loss_pose_action: 0.0525 (0.7557)  loss_object_interaction: 0.0002 (0.0011)  loss_person_interaction: 0.0002 (0.0012)  total_loss: 0.0796 (0.9830)  accuracy_pose_action: 1.0000 (0.6261)  accuracy_object_interaction: 1.0000 (0.9949)  accuracy_person_interaction: 1.0000 (0.9955)  time: 0.5131 (0.5076)  data: 0.0137 (0.0142)  lr: 0.000104  max mem: 2403
2022-04-26 16:04:46,995 alphaction.trainer INFO: eta: 5 days, 3:51:39  iter: 1580  loss_pose_action: 0.0786 (0.7506)  loss_object_interaction: 0.0001 (0.0011)  loss_person_interaction: 0.0001 (0.0012)  total_loss: 0.1277 (0.9761)  accuracy_pose_action: 1.0000 (0.6284)  accuracy_object_interaction: 1.0000 (0.9949)  accuracy_person_interaction: 1.0000 (0.9956)  time: 0.5126 (0.5076)  data: 0.0137 (0.0142)  lr: 0.000105  max mem: 2403
2022-04-26 16:04:57,233 alphaction.trainer INFO: eta: 5 days, 3:52:16  iter: 1600  loss_pose_action: 0.0383 (0.7456)  loss_object_interaction: 0.0000 (0.0011)  loss_person_interaction: 0.0000 (0.0012)  total_loss: 0.0620 (0.9692)  accuracy_pose_action: 1.0000 (0.6308)  accuracy_object_interaction: 1.0000 (0.9950)  accuracy_person_interaction: 1.0000 (0.9956)  time: 0.5125 (0.5077)  data: 0.0134 (0.0142)  lr: 0.000106  max mem: 2403
2022-04-26 16:04:57,237 alphaction.utils.checkpoint INFO: Saving checkpoint to data/output/resnet50_4x16f_baseline_robalo/model_0001600.pth
2022-04-26 16:04:57,525 alphaction.inference INFO: Start evaluation on lfv_robalo_val_ava_video dataset(135 videos).
2022-04-26 16:05:12,800 alphaction.inference INFO: Total inference time: 0:00:15.275083 (0.11314876344468859 s / video per device, on 1 devices)
2022-04-26 16:05:12,800 alphaction.inference INFO: performing ava evaluation.
2022-04-26 16:05:12,800 alphaction.inference INFO: Preparing results for AVA format
2022-04-26 16:05:12,818 alphaction.inference INFO: Evaluating predictions
2022-04-26 16:05:12,866 alphaction.inference INFO: ==> 0.0485761 seconds to write file /tmp/tmpi0lbukxd
2022-04-26 16:05:12,867 alphaction.inference INFO: CATEGORIES (12):
[ {'id': 1, 'name': 'cut (an object)'},
  {'id': 2, 'name': 'holding for (a person)'},
  {'id': 3, 'name': 'handover to (a person)'},
  {'id': 4, 'name': 'squeeze (an object)'},
  {'id': 5, 'name': 'sprinkle (an object)'},
  {'id': 6, 'name': 'transfer (an object)'},
  {'id': 7, 'name': 'pour (an object)'},
  {'id': 8, 'name': 'heat (an object)'},
  {'id': 9, 'name': 'stir (an object)'},
  {'id': 10, 'name': 'wrap (an object)'},
  {'id': 11, 'name': 'roll (an object)'},
  {'id': 12, 'name': 'dip (an object)'}]
2022-04-26 16:05:12,867 alphaction.inference INFO: ==> 0.000417471 seconds to read file data/lfv_robalo/annotations/lfv_robalo_val.csv
2022-04-26 16:05:12,884 alphaction.inference INFO: ==> 0.0163374 seconds to convert groundtruth
2022-04-26 16:05:12,904 alphaction.inference INFO: ==> 0.0201821 seconds to read file /tmp/tmpi0lbukxd
2022-04-26 16:05:13,262 alphaction.inference INFO: ==> 0.35777 seconds to convert detections
2022-04-26 16:05:13,262 alphaction.inference INFO: The following classes have no ground truth examples: [ 2  3 10 11 12]
2022-04-26 16:05:13,265 alphaction.inference INFO: ==> 0.00280881 seconds to run_evaluator
2022-04-26 16:05:13,266 alphaction.inference INFO: { 'PascalBoxes_PerformanceByCategory/AP@0.5IOU/cut (an object)': 0.3581504793775936,
  'PascalBoxes_PerformanceByCategory/AP@0.5IOU/dip (an object)': nan,
  'PascalBoxes_PerformanceByCategory/AP@0.5IOU/handover to (a person)': nan,
  'PascalBoxes_PerformanceByCategory/AP@0.5IOU/heat (an object)': 0.6917260024025045,
  'PascalBoxes_PerformanceByCategory/AP@0.5IOU/holding for (a person)': nan,
  'PascalBoxes_PerformanceByCategory/AP@0.5IOU/pour (an object)': 0.1128871128871129,
  'PascalBoxes_PerformanceByCategory/AP@0.5IOU/roll (an object)': nan,
  'PascalBoxes_PerformanceByCategory/AP@0.5IOU/sprinkle (an object)': 0.02564102564102564,
  'PascalBoxes_PerformanceByCategory/AP@0.5IOU/squeeze (an object)': 0.1595825793276052,
  'PascalBoxes_PerformanceByCategory/AP@0.5IOU/stir (an object)': 0.22305416186671045,
  'PascalBoxes_PerformanceByCategory/AP@0.5IOU/transfer (an object)': 0.47821949612647296,
  'PascalBoxes_PerformanceByCategory/AP@0.5IOU/wrap (an object)': nan,
  'PascalBoxes_Precision/mAP@0.5IOU': 0.2927515510898608}
2022-04-26 16:05:23,319 alphaction.trainer INFO: eta: 5 days, 3:51:10  iter: 1620  loss_pose_action: 0.3256 (0.7436)  loss_object_interaction: 0.0002 (0.0011)  loss_person_interaction: 0.0002 (0.0012)  total_loss: 0.4099 (0.9662)  accuracy_pose_action: 1.0000 (0.6327)  accuracy_object_interaction: 1.0000 (0.9951)  accuracy_person_interaction: 1.0000 (0.9957)  time: 0.5028 (0.5076)  data: 0.0138 (0.0142)  lr: 0.000107  max mem: 2403
2022-04-26 16:05:33,484 alphaction.trainer INFO: eta: 5 days, 3:51:07  iter: 1640  loss_pose_action: 0.2573 (0.7393)  loss_object_interaction: 0.0002 (0.0011)  loss_person_interaction: 0.0002 (0.0011)  total_loss: 0.3278 (0.9604)  accuracy_pose_action: 0.6667 (0.6345)  accuracy_object_interaction: 1.0000 (0.9951)  accuracy_person_interaction: 1.0000 (0.9957)  time: 0.5116 (0.5076)  data: 0.0137 (0.0142)  lr: 0.000108  max mem: 2403
2022-04-26 16:05:43,713 alphaction.trainer INFO: eta: 5 days, 3:51:37  iter: 1660  loss_pose_action: 0.0181 (0.7342)  loss_object_interaction: 0.0001 (0.0011)  loss_person_interaction: 0.0001 (0.0011)  total_loss: 0.0263 (0.9535)  accuracy_pose_action: 1.0000 (0.6363)  accuracy_object_interaction: 1.0000 (0.9952)  accuracy_person_interaction: 1.0000 (0.9958)  time: 0.5123 (0.5077)  data: 0.0137 (0.0142)  lr: 0.000109  max mem: 2403
2022-04-26 16:05:53,945 alphaction.trainer INFO: eta: 5 days, 3:52:09  iter: 1680  loss_pose_action: 0.0655 (0.7297)  loss_object_interaction: 0.0001 (0.0011)  loss_person_interaction: 0.0001 (0.0011)  total_loss: 0.1011 (0.9473)  accuracy_pose_action: 1.0000 (0.6389)  accuracy_object_interaction: 1.0000 (0.9952)  accuracy_person_interaction: 1.0000 (0.9958)  time: 0.5125 (0.5077)  data: 0.0139 (0.0142)  lr: 0.000110  max mem: 2403
2022-04-26 16:06:04,110 alphaction.trainer INFO: eta: 5 days, 3:52:04  iter: 1700  loss_pose_action: 0.1099 (0.7259)  loss_object_interaction: 0.0000 (0.0011)  loss_person_interaction: 0.0001 (0.0011)  total_loss: 0.1340 (0.9420)  accuracy_pose_action: 1.0000 (0.6404)  accuracy_object_interaction: 1.0000 (0.9953)  accuracy_person_interaction: 1.0000 (0.9959)  time: 0.5111 (0.5077)  data: 0.0136 (0.0142)  lr: 0.000111  max mem: 2403
2022-04-26 16:06:04,114 alphaction.utils.checkpoint INFO: Saving checkpoint to data/output/resnet50_4x16f_baseline_robalo/model_0001700.pth
2022-04-26 16:06:04,389 alphaction.inference INFO: Start evaluation on lfv_robalo_val_ava_video dataset(135 videos).
2022-04-26 16:06:19,005 alphaction.inference INFO: Total inference time: 0:00:14.616382 (0.10826949366816768 s / video per device, on 1 devices)
2022-04-26 16:06:19,005 alphaction.inference INFO: performing ava evaluation.
2022-04-26 16:06:19,005 alphaction.inference INFO: Preparing results for AVA format
2022-04-26 16:06:19,022 alphaction.inference INFO: Evaluating predictions
2022-04-26 16:06:19,073 alphaction.inference INFO: ==> 0.0508537 seconds to write file /tmp/tmp3v0j2p2l
2022-04-26 16:06:19,074 alphaction.inference INFO: CATEGORIES (12):
[ {'id': 1, 'name': 'cut (an object)'},
  {'id': 2, 'name': 'holding for (a person)'},
  {'id': 3, 'name': 'handover to (a person)'},
  {'id': 4, 'name': 'squeeze (an object)'},
  {'id': 5, 'name': 'sprinkle (an object)'},
  {'id': 6, 'name': 'transfer (an object)'},
  {'id': 7, 'name': 'pour (an object)'},
  {'id': 8, 'name': 'heat (an object)'},
  {'id': 9, 'name': 'stir (an object)'},
  {'id': 10, 'name': 'wrap (an object)'},
  {'id': 11, 'name': 'roll (an object)'},
  {'id': 12, 'name': 'dip (an object)'}]
2022-04-26 16:06:19,074 alphaction.inference INFO: ==> 0.000539541 seconds to read file data/lfv_robalo/annotations/lfv_robalo_val.csv
2022-04-26 16:06:19,091 alphaction.inference INFO: ==> 0.0167775 seconds to convert groundtruth
2022-04-26 16:06:19,111 alphaction.inference INFO: ==> 0.0194445 seconds to read file /tmp/tmp3v0j2p2l
2022-04-26 16:06:19,454 alphaction.inference INFO: ==> 0.343059 seconds to convert detections
2022-04-26 16:06:19,454 alphaction.inference INFO: The following classes have no ground truth examples: [ 2  3 10 11 12]
2022-04-26 16:06:19,458 alphaction.inference INFO: ==> 0.00413775 seconds to run_evaluator
2022-04-26 16:06:19,459 alphaction.inference INFO: { 'PascalBoxes_PerformanceByCategory/AP@0.5IOU/cut (an object)': 0.6931568606942228,
  'PascalBoxes_PerformanceByCategory/AP@0.5IOU/dip (an object)': nan,
  'PascalBoxes_PerformanceByCategory/AP@0.5IOU/handover to (a person)': nan,
  'PascalBoxes_PerformanceByCategory/AP@0.5IOU/heat (an object)': 0.6998823971065758,
  'PascalBoxes_PerformanceByCategory/AP@0.5IOU/holding for (a person)': nan,
  'PascalBoxes_PerformanceByCategory/AP@0.5IOU/pour (an object)': 0.08083333333333334,
  'PascalBoxes_PerformanceByCategory/AP@0.5IOU/roll (an object)': nan,
  'PascalBoxes_PerformanceByCategory/AP@0.5IOU/sprinkle (an object)': 0.07142857142857142,
  'PascalBoxes_PerformanceByCategory/AP@0.5IOU/squeeze (an object)': 0.08978729988083425,
  'PascalBoxes_PerformanceByCategory/AP@0.5IOU/stir (an object)': 0.41832604568837367,
  'PascalBoxes_PerformanceByCategory/AP@0.5IOU/transfer (an object)': 0.4441498660967951,
  'PascalBoxes_PerformanceByCategory/AP@0.5IOU/wrap (an object)': nan,
  'PascalBoxes_Precision/mAP@0.5IOU': 0.35679491060410085}
2022-04-26 16:06:29,565 alphaction.trainer INFO: eta: 5 days, 3:51:28  iter: 1720  loss_pose_action: 0.0777 (0.7228)  loss_object_interaction: 0.0002 (0.0011)  loss_person_interaction: 0.0002 (0.0011)  total_loss: 0.1301 (0.9378)  accuracy_pose_action: 1.0000 (0.6419)  accuracy_object_interaction: 1.0000 (0.9953)  accuracy_person_interaction: 1.0000 (0.9959)  time: 0.5038 (0.5077)  data: 0.0133 (0.0142)  lr: 0.000112  max mem: 2403
2022-04-26 16:06:39,733 alphaction.trainer INFO: eta: 5 days, 3:51:25  iter: 1740  loss_pose_action: 0.1192 (0.7191)  loss_object_interaction: 0.0002 (0.0010)  loss_person_interaction: 0.0002 (0.0011)  total_loss: 0.1634 (0.9329)  accuracy_pose_action: 1.0000 (0.6437)  accuracy_object_interaction: 1.0000 (0.9954)  accuracy_person_interaction: 1.0000 (0.9960)  time: 0.5101 (0.5077)  data: 0.0140 (0.0142)  lr: 0.000113  max mem: 2403
2022-04-26 16:06:49,988 alphaction.trainer INFO: eta: 5 days, 3:52:05  iter: 1760  loss_pose_action: 0.0546 (0.7132)  loss_object_interaction: 0.0000 (0.0010)  loss_person_interaction: 0.0000 (0.0011)  total_loss: 0.0751 (0.9250)  accuracy_pose_action: 1.0000 (0.6467)  accuracy_object_interaction: 1.0000 (0.9955)  accuracy_person_interaction: 1.0000 (0.9960)  time: 0.5146 (0.5077)  data: 0.0135 (0.0141)  lr: 0.000114  max mem: 2403
2022-04-26 16:07:00,220 alphaction.trainer INFO: eta: 5 days, 3:52:33  iter: 1780  loss_pose_action: 0.0027 (0.7075)  loss_object_interaction: 0.0000 (0.0010)  loss_person_interaction: 0.0000 (0.0011)  total_loss: 0.0059 (0.9174)  accuracy_pose_action: 1.0000 (0.6495)  accuracy_object_interaction: 1.0000 (0.9955)  accuracy_person_interaction: 1.0000 (0.9961)  time: 0.5138 (0.5078)  data: 0.0136 (0.0141)  lr: 0.000115  max mem: 2403
2022-04-26 16:07:10,442 alphaction.trainer INFO: eta: 5 days, 3:52:56  iter: 1800  loss_pose_action: 0.0109 (0.7023)  loss_object_interaction: 0.0001 (0.0010)  loss_person_interaction: 0.0000 (0.0011)  total_loss: 0.0172 (0.9105)  accuracy_pose_action: 1.0000 (0.6519)  accuracy_object_interaction: 1.0000 (0.9956)  accuracy_person_interaction: 1.0000 (0.9961)  time: 0.5141 (0.5078)  data: 0.0138 (0.0141)  lr: 0.000116  max mem: 2403
2022-04-26 16:07:10,445 alphaction.utils.checkpoint INFO: Saving checkpoint to data/output/resnet50_4x16f_baseline_robalo/model_0001800.pth
2022-04-26 16:07:10,709 alphaction.inference INFO: Start evaluation on lfv_robalo_val_ava_video dataset(135 videos).
2022-04-26 16:07:25,350 alphaction.inference INFO: Total inference time: 0:00:14.641202 (0.10845335147998951 s / video per device, on 1 devices)
2022-04-26 16:07:25,350 alphaction.inference INFO: performing ava evaluation.
2022-04-26 16:07:25,351 alphaction.inference INFO: Preparing results for AVA format
2022-04-26 16:07:25,368 alphaction.inference INFO: Evaluating predictions
2022-04-26 16:07:25,419 alphaction.inference INFO: ==> 0.0509422 seconds to write file /tmp/tmppjqnaluc
2022-04-26 16:07:25,420 alphaction.inference INFO: CATEGORIES (12):
[ {'id': 1, 'name': 'cut (an object)'},
  {'id': 2, 'name': 'holding for (a person)'},
  {'id': 3, 'name': 'handover to (a person)'},
  {'id': 4, 'name': 'squeeze (an object)'},
  {'id': 5, 'name': 'sprinkle (an object)'},
  {'id': 6, 'name': 'transfer (an object)'},
  {'id': 7, 'name': 'pour (an object)'},
  {'id': 8, 'name': 'heat (an object)'},
  {'id': 9, 'name': 'stir (an object)'},
  {'id': 10, 'name': 'wrap (an object)'},
  {'id': 11, 'name': 'roll (an object)'},
  {'id': 12, 'name': 'dip (an object)'}]
2022-04-26 16:07:25,420 alphaction.inference INFO: ==> 0.000444412 seconds to read file data/lfv_robalo/annotations/lfv_robalo_val.csv
2022-04-26 16:07:25,440 alphaction.inference INFO: ==> 0.0193589 seconds to convert groundtruth
2022-04-26 16:07:25,460 alphaction.inference INFO: ==> 0.0201671 seconds to read file /tmp/tmppjqnaluc
2022-04-26 16:07:25,796 alphaction.inference INFO: ==> 0.335318 seconds to convert detections
2022-04-26 16:07:25,796 alphaction.inference INFO: The following classes have no ground truth examples: [ 2  3 10 11 12]
2022-04-26 16:07:25,798 alphaction.inference INFO: ==> 0.00269198 seconds to run_evaluator
2022-04-26 16:07:25,799 alphaction.inference INFO: { 'PascalBoxes_PerformanceByCategory/AP@0.5IOU/cut (an object)': 0.8625478386347951,
  'PascalBoxes_PerformanceByCategory/AP@0.5IOU/dip (an object)': nan,
  'PascalBoxes_PerformanceByCategory/AP@0.5IOU/handover to (a person)': nan,
  'PascalBoxes_PerformanceByCategory/AP@0.5IOU/heat (an object)': 0.6310503625081203,
  'PascalBoxes_PerformanceByCategory/AP@0.5IOU/holding for (a person)': nan,
  'PascalBoxes_PerformanceByCategory/AP@0.5IOU/pour (an object)': 0.1672473867595819,
  'PascalBoxes_PerformanceByCategory/AP@0.5IOU/roll (an object)': nan,
  'PascalBoxes_PerformanceByCategory/AP@0.5IOU/sprinkle (an object)': 0.03278688524590164,
  'PascalBoxes_PerformanceByCategory/AP@0.5IOU/squeeze (an object)': 0.11470550011545057,
  'PascalBoxes_PerformanceByCategory/AP@0.5IOU/stir (an object)': 0.3324060967951816,
  'PascalBoxes_PerformanceByCategory/AP@0.5IOU/transfer (an object)': 0.5992189571946175,
  'PascalBoxes_PerformanceByCategory/AP@0.5IOU/wrap (an object)': nan,
  'PascalBoxes_Precision/mAP@0.5IOU': 0.3914232896076641}
2022-04-26 16:07:35,835 alphaction.trainer INFO: eta: 5 days, 3:51:46  iter: 1820  loss_pose_action: 0.0707 (0.6988)  loss_object_interaction: 0.0001 (0.0010)  loss_person_interaction: 0.0001 (0.0011)  total_loss: 0.0882 (0.9056)  accuracy_pose_action: 1.0000 (0.6541)  accuracy_object_interaction: 1.0000 (0.9956)  accuracy_person_interaction: 1.0000 (0.9962)  time: 0.4971 (0.5078)  data: 0.0135 (0.0141)  lr: 0.000117  max mem: 2403
2022-04-26 16:07:45,981 alphaction.trainer INFO: eta: 5 days, 3:51:31  iter: 1840  loss_pose_action: 0.0839 (0.6953)  loss_object_interaction: 0.0001 (0.0010)  loss_person_interaction: 0.0001 (0.0010)  total_loss: 0.1057 (0.9010)  accuracy_pose_action: 1.0000 (0.6554)  accuracy_object_interaction: 1.0000 (0.9957)  accuracy_person_interaction: 1.0000 (0.9962)  time: 0.5127 (0.5078)  data: 0.0140 (0.0141)  lr: 0.000117  max mem: 2403
2022-04-26 16:07:56,220 alphaction.trainer INFO: eta: 5 days, 3:52:01  iter: 1860  loss_pose_action: 0.0133 (0.6898)  loss_object_interaction: 0.0001 (0.0010)  loss_person_interaction: 0.0001 (0.0010)  total_loss: 0.0189 (0.8937)  accuracy_pose_action: 1.0000 (0.6573)  accuracy_object_interaction: 1.0000 (0.9957)  accuracy_person_interaction: 1.0000 (0.9962)  time: 0.5156 (0.5078)  data: 0.0139 (0.0141)  lr: 0.000118  max mem: 2403
2022-04-26 16:08:06,457 alphaction.trainer INFO: eta: 5 days, 3:52:29  iter: 1880  loss_pose_action: 0.0100 (0.6841)  loss_object_interaction: 0.0000 (0.0010)  loss_person_interaction: 0.0000 (0.0010)  total_loss: 0.0166 (0.8864)  accuracy_pose_action: 1.0000 (0.6597)  accuracy_object_interaction: 1.0000 (0.9957)  accuracy_person_interaction: 1.0000 (0.9963)  time: 0.5144 (0.5078)  data: 0.0139 (0.0141)  lr: 0.000119  max mem: 2403
2022-04-26 16:08:16,701 alphaction.trainer INFO: eta: 5 days, 3:52:59  iter: 1900  loss_pose_action: 0.0666 (0.6824)  loss_object_interaction: 0.0001 (0.0010)  loss_person_interaction: 0.0000 (0.0010)  total_loss: 0.0843 (0.8837)  accuracy_pose_action: 0.6667 (0.6600)  accuracy_object_interaction: 1.0000 (0.9958)  accuracy_person_interaction: 1.0000 (0.9963)  time: 0.5130 (0.5079)  data: 0.0138 (0.0141)  lr: 0.000120  max mem: 2403
2022-04-26 16:08:16,705 alphaction.utils.checkpoint INFO: Saving checkpoint to data/output/resnet50_4x16f_baseline_robalo/model_0001900.pth
2022-04-26 16:08:16,964 alphaction.inference INFO: Start evaluation on lfv_robalo_val_ava_video dataset(135 videos).
2022-04-26 16:08:31,969 alphaction.inference INFO: Total inference time: 0:00:15.004497 (0.11114442436783402 s / video per device, on 1 devices)
2022-04-26 16:08:31,969 alphaction.inference INFO: performing ava evaluation.
2022-04-26 16:08:31,969 alphaction.inference INFO: Preparing results for AVA format
2022-04-26 16:08:31,985 alphaction.inference INFO: Evaluating predictions
2022-04-26 16:08:32,035 alphaction.inference INFO: ==> 0.0499065 seconds to write file /tmp/tmpaf_hcbar
2022-04-26 16:08:32,036 alphaction.inference INFO: CATEGORIES (12):
[ {'id': 1, 'name': 'cut (an object)'},
  {'id': 2, 'name': 'holding for (a person)'},
  {'id': 3, 'name': 'handover to (a person)'},
  {'id': 4, 'name': 'squeeze (an object)'},
  {'id': 5, 'name': 'sprinkle (an object)'},
  {'id': 6, 'name': 'transfer (an object)'},
  {'id': 7, 'name': 'pour (an object)'},
  {'id': 8, 'name': 'heat (an object)'},
  {'id': 9, 'name': 'stir (an object)'},
  {'id': 10, 'name': 'wrap (an object)'},
  {'id': 11, 'name': 'roll (an object)'},
  {'id': 12, 'name': 'dip (an object)'}]
2022-04-26 16:08:32,036 alphaction.inference INFO: ==> 0.00047636 seconds to read file data/lfv_robalo/annotations/lfv_robalo_val.csv
2022-04-26 16:08:32,053 alphaction.inference INFO: ==> 0.0162902 seconds to convert groundtruth
2022-04-26 16:08:32,073 alphaction.inference INFO: ==> 0.0204453 seconds to read file /tmp/tmpaf_hcbar
2022-04-26 16:08:32,407 alphaction.inference INFO: ==> 0.333326 seconds to convert detections
2022-04-26 16:08:32,407 alphaction.inference INFO: The following classes have no ground truth examples: [ 2  3 10 11 12]
2022-04-26 16:08:32,409 alphaction.inference INFO: ==> 0.00266409 seconds to run_evaluator
2022-04-26 16:08:32,410 alphaction.inference INFO: { 'PascalBoxes_PerformanceByCategory/AP@0.5IOU/cut (an object)': 0.7726323489267839,
  'PascalBoxes_PerformanceByCategory/AP@0.5IOU/dip (an object)': nan,
  'PascalBoxes_PerformanceByCategory/AP@0.5IOU/handover to (a person)': nan,
  'PascalBoxes_PerformanceByCategory/AP@0.5IOU/heat (an object)': 0.5571083140568683,
  'PascalBoxes_PerformanceByCategory/AP@0.5IOU/holding for (a person)': nan,
  'PascalBoxes_PerformanceByCategory/AP@0.5IOU/pour (an object)': 0.221505376344086,
  'PascalBoxes_PerformanceByCategory/AP@0.5IOU/roll (an object)': nan,
  'PascalBoxes_PerformanceByCategory/AP@0.5IOU/sprinkle (an object)': 0.034482758620689655,
  'PascalBoxes_PerformanceByCategory/AP@0.5IOU/squeeze (an object)': 0.062496357171999764,
  'PascalBoxes_PerformanceByCategory/AP@0.5IOU/stir (an object)': 0.2576310944216546,
  'PascalBoxes_PerformanceByCategory/AP@0.5IOU/transfer (an object)': 0.43939425231487295,
  'PascalBoxes_PerformanceByCategory/AP@0.5IOU/wrap (an object)': nan,
  'PascalBoxes_Precision/mAP@0.5IOU': 0.335035785979565}
2022-04-26 16:08:42,522 alphaction.trainer INFO: eta: 5 days, 3:52:27  iter: 1920  loss_pose_action: 0.1338 (0.6791)  loss_object_interaction: 0.0004 (0.0010)  loss_person_interaction: 0.0003 (0.0010)  total_loss: 0.2021 (0.8794)  accuracy_pose_action: 1.0000 (0.6619)  accuracy_object_interaction: 1.0000 (0.9958)  accuracy_person_interaction: 1.0000 (0.9964)  time: 0.5082 (0.5079)  data: 0.0137 (0.0141)  lr: 0.000121  max mem: 2403
2022-04-26 16:08:52,753 alphaction.trainer INFO: eta: 5 days, 3:52:50  iter: 1940  loss_pose_action: 0.1378 (0.6770)  loss_object_interaction: 0.0001 (0.0010)  loss_person_interaction: 0.0001 (0.0010)  total_loss: 0.1830 (0.8763)  accuracy_pose_action: 1.0000 (0.6626)  accuracy_object_interaction: 1.0000 (0.9959)  accuracy_person_interaction: 1.0000 (0.9964)  time: 0.5128 (0.5079)  data: 0.0145 (0.0141)  lr: 0.000122  max mem: 2403
2022-04-26 16:09:02,909 alphaction.trainer INFO: eta: 5 days, 3:52:39  iter: 1960  loss_pose_action: 0.2484 (0.6751)  loss_object_interaction: 0.0001 (0.0009)  loss_person_interaction: 0.0001 (0.0010)  total_loss: 0.3024 (0.8735)  accuracy_pose_action: 1.0000 (0.6641)  accuracy_object_interaction: 1.0000 (0.9959)  accuracy_person_interaction: 1.0000 (0.9964)  time: 0.5136 (0.5079)  data: 0.0138 (0.0141)  lr: 0.000123  max mem: 2403
2022-04-26 16:09:13,126 alphaction.trainer INFO: eta: 5 days, 3:52:55  iter: 1980  loss_pose_action: 0.0495 (0.6711)  loss_object_interaction: 0.0001 (0.0009)  loss_person_interaction: 0.0001 (0.0010)  total_loss: 0.0852 (0.8681)  accuracy_pose_action: 1.0000 (0.6651)  accuracy_object_interaction: 1.0000 (0.9960)  accuracy_person_interaction: 1.0000 (0.9965)  time: 0.5136 (0.5079)  data: 0.0138 (0.0141)  lr: 0.000124  max mem: 2403
2022-04-26 16:09:23,367 alphaction.trainer INFO: eta: 5 days, 3:53:21  iter: 2000  loss_pose_action: 0.1477 (0.6716)  loss_object_interaction: 0.0001 (0.0009)  loss_person_interaction: 0.0002 (0.0010)  total_loss: 0.2218 (0.8684)  accuracy_pose_action: 0.6667 (0.6654)  accuracy_object_interaction: 1.0000 (0.9960)  accuracy_person_interaction: 1.0000 (0.9965)  time: 0.5143 (0.5080)  data: 0.0135 (0.0141)  lr: 0.000125  max mem: 2403
2022-04-26 16:09:23,370 alphaction.utils.checkpoint INFO: Saving checkpoint to data/output/resnet50_4x16f_baseline_robalo/model_0002000.pth
2022-04-26 16:09:23,636 alphaction.inference INFO: Start evaluation on lfv_robalo_val_ava_video dataset(135 videos).
2022-04-26 16:09:38,305 alphaction.inference INFO: Total inference time: 0:00:14.667987 (0.10865175812332718 s / video per device, on 1 devices)
2022-04-26 16:09:38,305 alphaction.inference INFO: performing ava evaluation.
2022-04-26 16:09:38,305 alphaction.inference INFO: Preparing results for AVA format
2022-04-26 16:09:38,322 alphaction.inference INFO: Evaluating predictions
2022-04-26 16:09:38,374 alphaction.inference INFO: ==> 0.0516465 seconds to write file /tmp/tmpjfzo9u1y
2022-04-26 16:09:38,374 alphaction.inference INFO: CATEGORIES (12):
[ {'id': 1, 'name': 'cut (an object)'},
  {'id': 2, 'name': 'holding for (a person)'},
  {'id': 3, 'name': 'handover to (a person)'},
  {'id': 4, 'name': 'squeeze (an object)'},
  {'id': 5, 'name': 'sprinkle (an object)'},
  {'id': 6, 'name': 'transfer (an object)'},
  {'id': 7, 'name': 'pour (an object)'},
  {'id': 8, 'name': 'heat (an object)'},
  {'id': 9, 'name': 'stir (an object)'},
  {'id': 10, 'name': 'wrap (an object)'},
  {'id': 11, 'name': 'roll (an object)'},
  {'id': 12, 'name': 'dip (an object)'}]
2022-04-26 16:09:38,375 alphaction.inference INFO: ==> 0.000605822 seconds to read file data/lfv_robalo/annotations/lfv_robalo_val.csv
2022-04-26 16:09:38,392 alphaction.inference INFO: ==> 0.0168073 seconds to convert groundtruth
2022-04-26 16:09:38,413 alphaction.inference INFO: ==> 0.0207443 seconds to read file /tmp/tmpjfzo9u1y
2022-04-26 16:09:38,751 alphaction.inference INFO: ==> 0.33837 seconds to convert detections
2022-04-26 16:09:38,752 alphaction.inference INFO: The following classes have no ground truth examples: [ 2  3 10 11 12]
2022-04-26 16:09:38,754 alphaction.inference INFO: ==> 0.00277591 seconds to run_evaluator
2022-04-26 16:09:38,755 alphaction.inference INFO: { 'PascalBoxes_PerformanceByCategory/AP@0.5IOU/cut (an object)': 0.6487818227049214,
  'PascalBoxes_PerformanceByCategory/AP@0.5IOU/dip (an object)': nan,
  'PascalBoxes_PerformanceByCategory/AP@0.5IOU/handover to (a person)': nan,
  'PascalBoxes_PerformanceByCategory/AP@0.5IOU/heat (an object)': 0.7107199161463332,
  'PascalBoxes_PerformanceByCategory/AP@0.5IOU/holding for (a person)': nan,
  'PascalBoxes_PerformanceByCategory/AP@0.5IOU/pour (an object)': 0.11742424242424242,
  'PascalBoxes_PerformanceByCategory/AP@0.5IOU/roll (an object)': nan,
  'PascalBoxes_PerformanceByCategory/AP@0.5IOU/sprinkle (an object)': 0.019417475728155338,
  'PascalBoxes_PerformanceByCategory/AP@0.5IOU/squeeze (an object)': 0.056790537706568237,
  'PascalBoxes_PerformanceByCategory/AP@0.5IOU/stir (an object)': 0.27254779915005417,
  'PascalBoxes_PerformanceByCategory/AP@0.5IOU/transfer (an object)': 0.3925418055402049,
  'PascalBoxes_PerformanceByCategory/AP@0.5IOU/wrap (an object)': nan,
  'PascalBoxes_Precision/mAP@0.5IOU': 0.31688908562863993}
2022-04-26 16:09:48,810 alphaction.trainer INFO: eta: 5 days, 3:52:24  iter: 2020  loss_pose_action: 0.5447 (0.6732)  loss_object_interaction: 0.0007 (0.0009)  loss_person_interaction: 0.0008 (0.0010)  total_loss: 0.7012 (0.8701)  accuracy_pose_action: 0.6667 (0.6655)  accuracy_object_interaction: 1.0000 (0.9960)  accuracy_person_interaction: 1.0000 (0.9965)  time: 0.5033 (0.5079)  data: 0.0133 (0.0141)  lr: 0.000125  max mem: 2403
2022-04-26 16:09:59,005 alphaction.trainer INFO: eta: 5 days, 3:52:30  iter: 2040  loss_pose_action: 0.6638 (0.6743)  loss_object_interaction: 0.0003 (0.0009)  loss_person_interaction: 0.0004 (0.0010)  total_loss: 0.8054 (0.8712)  accuracy_pose_action: 0.6667 (0.6648)  accuracy_object_interaction: 1.0000 (0.9961)  accuracy_person_interaction: 1.0000 (0.9966)  time: 0.5132 (0.5079)  data: 0.0137 (0.0141)  lr: 0.000125  max mem: 2403
2022-04-26 16:10:09,238 alphaction.trainer INFO: eta: 5 days, 3:52:51  iter: 2060  loss_pose_action: 0.4272 (0.6727)  loss_object_interaction: 0.0002 (0.0009)  loss_person_interaction: 0.0003 (0.0010)  total_loss: 0.5272 (0.8689)  accuracy_pose_action: 0.6667 (0.6652)  accuracy_object_interaction: 1.0000 (0.9961)  accuracy_person_interaction: 1.0000 (0.9966)  time: 0.5116 (0.5080)  data: 0.0143 (0.0141)  lr: 0.000125  max mem: 2403
2022-04-26 16:10:19,410 alphaction.trainer INFO: eta: 5 days, 3:52:46  iter: 2080  loss_pose_action: 0.0772 (0.6689)  loss_object_interaction: 0.0001 (0.0009)  loss_person_interaction: 0.0001 (0.0010)  total_loss: 0.1113 (0.8638)  accuracy_pose_action: 1.0000 (0.6664)  accuracy_object_interaction: 1.0000 (0.9962)  accuracy_person_interaction: 1.0000 (0.9966)  time: 0.5105 (0.5080)  data: 0.0140 (0.0141)  lr: 0.000125  max mem: 2403
2022-04-26 16:10:29,625 alphaction.trainer INFO: eta: 5 days, 3:52:59  iter: 2100  loss_pose_action: 0.0664 (0.6653)  loss_object_interaction: 0.0001 (0.0009)  loss_person_interaction: 0.0001 (0.0009)  total_loss: 0.0866 (0.8590)  accuracy_pose_action: 1.0000 (0.6683)  accuracy_object_interaction: 1.0000 (0.9962)  accuracy_person_interaction: 1.0000 (0.9967)  time: 0.5136 (0.5080)  data: 0.0136 (0.0141)  lr: 0.000125  max mem: 2403
2022-04-26 16:10:29,629 alphaction.utils.checkpoint INFO: Saving checkpoint to data/output/resnet50_4x16f_baseline_robalo/model_0002100.pth
2022-04-26 16:10:29,887 alphaction.inference INFO: Start evaluation on lfv_robalo_val_ava_video dataset(135 videos).
2022-04-26 16:10:44,454 alphaction.inference INFO: Total inference time: 0:00:14.566289 (0.10789843841835305 s / video per device, on 1 devices)
2022-04-26 16:10:44,454 alphaction.inference INFO: performing ava evaluation.
2022-04-26 16:10:44,454 alphaction.inference INFO: Preparing results for AVA format
2022-04-26 16:10:44,471 alphaction.inference INFO: Evaluating predictions
2022-04-26 16:10:44,521 alphaction.inference INFO: ==> 0.0500107 seconds to write file /tmp/tmp04wf3ubg
2022-04-26 16:10:44,521 alphaction.inference INFO: CATEGORIES (12):
[ {'id': 1, 'name': 'cut (an object)'},
  {'id': 2, 'name': 'holding for (a person)'},
  {'id': 3, 'name': 'handover to (a person)'},
  {'id': 4, 'name': 'squeeze (an object)'},
  {'id': 5, 'name': 'sprinkle (an object)'},
  {'id': 6, 'name': 'transfer (an object)'},
  {'id': 7, 'name': 'pour (an object)'},
  {'id': 8, 'name': 'heat (an object)'},
  {'id': 9, 'name': 'stir (an object)'},
  {'id': 10, 'name': 'wrap (an object)'},
  {'id': 11, 'name': 'roll (an object)'},
  {'id': 12, 'name': 'dip (an object)'}]
2022-04-26 16:10:44,522 alphaction.inference INFO: ==> 0.000425577 seconds to read file data/lfv_robalo/annotations/lfv_robalo_val.csv
2022-04-26 16:10:44,538 alphaction.inference INFO: ==> 0.0163014 seconds to convert groundtruth
2022-04-26 16:10:44,559 alphaction.inference INFO: ==> 0.0206268 seconds to read file /tmp/tmp04wf3ubg
2022-04-26 16:10:44,900 alphaction.inference INFO: ==> 0.340791 seconds to convert detections
2022-04-26 16:10:44,900 alphaction.inference INFO: The following classes have no ground truth examples: [ 2  3 10 11 12]
2022-04-26 16:10:44,903 alphaction.inference INFO: ==> 0.00300694 seconds to run_evaluator
2022-04-26 16:10:44,904 alphaction.inference INFO: { 'PascalBoxes_PerformanceByCategory/AP@0.5IOU/cut (an object)': 0.6554409123064328,
  'PascalBoxes_PerformanceByCategory/AP@0.5IOU/dip (an object)': nan,
  'PascalBoxes_PerformanceByCategory/AP@0.5IOU/handover to (a person)': nan,
  'PascalBoxes_PerformanceByCategory/AP@0.5IOU/heat (an object)': 0.6916547436810787,
  'PascalBoxes_PerformanceByCategory/AP@0.5IOU/holding for (a person)': nan,
  'PascalBoxes_PerformanceByCategory/AP@0.5IOU/pour (an object)': 0.3094827586206897,
  'PascalBoxes_PerformanceByCategory/AP@0.5IOU/roll (an object)': nan,
  'PascalBoxes_PerformanceByCategory/AP@0.5IOU/sprinkle (an object)': 0.031746031746031744,
  'PascalBoxes_PerformanceByCategory/AP@0.5IOU/squeeze (an object)': 0.06481481481481481,
  'PascalBoxes_PerformanceByCategory/AP@0.5IOU/stir (an object)': 0.41436978555858633,
  'PascalBoxes_PerformanceByCategory/AP@0.5IOU/transfer (an object)': 0.411362451876935,
  'PascalBoxes_PerformanceByCategory/AP@0.5IOU/wrap (an object)': nan,
  'PascalBoxes_Precision/mAP@0.5IOU': 0.36841021408636704}
2022-04-26 16:10:54,988 alphaction.trainer INFO: eta: 5 days, 3:52:17  iter: 2120  loss_pose_action: 0.0396 (0.6613)  loss_object_interaction: 0.0001 (0.0009)  loss_person_interaction: 0.0001 (0.0009)  total_loss: 0.0526 (0.8537)  accuracy_pose_action: 1.0000 (0.6702)  accuracy_object_interaction: 1.0000 (0.9962)  accuracy_person_interaction: 1.0000 (0.9967)  time: 0.5008 (0.5080)  data: 0.0133 (0.0141)  lr: 0.000125  max mem: 2403
2022-04-26 16:11:05,152 alphaction.trainer INFO: eta: 5 days, 3:52:08  iter: 2140  loss_pose_action: 0.0138 (0.6561)  loss_object_interaction: 0.0000 (0.0009)  loss_person_interaction: 0.0001 (0.0009)  total_loss: 0.0227 (0.8470)  accuracy_pose_action: 1.0000 (0.6726)  accuracy_object_interaction: 1.0000 (0.9963)  accuracy_person_interaction: 1.0000 (0.9967)  time: 0.5096 (0.5080)  data: 0.0138 (0.0141)  lr: 0.000125  max mem: 2403
2022-04-26 16:11:15,416 alphaction.trainer INFO: eta: 5 days, 3:52:41  iter: 2160  loss_pose_action: 0.0270 (0.6530)  loss_object_interaction: 0.0000 (0.0009)  loss_person_interaction: 0.0000 (0.0009)  total_loss: 0.0406 (0.8428)  accuracy_pose_action: 1.0000 (0.6738)  accuracy_object_interaction: 1.0000 (0.9963)  accuracy_person_interaction: 1.0000 (0.9968)  time: 0.5165 (0.5080)  data: 0.0137 (0.0141)  lr: 0.000125  max mem: 2403
2022-04-26 16:11:25,627 alphaction.trainer INFO: eta: 5 days, 3:52:51  iter: 2180  loss_pose_action: 0.1248 (0.6511)  loss_object_interaction: 0.0001 (0.0009)  loss_person_interaction: 0.0002 (0.0009)  total_loss: 0.1636 (0.8400)  accuracy_pose_action: 1.0000 (0.6744)  accuracy_object_interaction: 1.0000 (0.9963)  accuracy_person_interaction: 1.0000 (0.9968)  time: 0.5122 (0.5080)  data: 0.0138 (0.0141)  lr: 0.000125  max mem: 2403
2022-04-26 16:11:35,889 alphaction.trainer INFO: eta: 5 days, 3:53:21  iter: 2200  loss_pose_action: 0.1300 (0.6499)  loss_object_interaction: 0.0003 (0.0009)  loss_person_interaction: 0.0004 (0.0009)  total_loss: 0.2366 (0.8385)  accuracy_pose_action: 1.0000 (0.6754)  accuracy_object_interaction: 1.0000 (0.9964)  accuracy_person_interaction: 1.0000 (0.9968)  time: 0.5147 (0.5081)  data: 0.0133 (0.0141)  lr: 0.000125  max mem: 2403
2022-04-26 16:11:35,893 alphaction.utils.checkpoint INFO: Saving checkpoint to data/output/resnet50_4x16f_baseline_robalo/model_0002200.pth
2022-04-26 16:11:36,151 alphaction.inference INFO: Start evaluation on lfv_robalo_val_ava_video dataset(135 videos).
2022-04-26 16:11:51,175 alphaction.inference INFO: Total inference time: 0:00:15.023166 (0.11128271244190358 s / video per device, on 1 devices)
2022-04-26 16:11:51,175 alphaction.inference INFO: performing ava evaluation.
2022-04-26 16:11:51,175 alphaction.inference INFO: Preparing results for AVA format
2022-04-26 16:11:51,192 alphaction.inference INFO: Evaluating predictions
2022-04-26 16:11:51,241 alphaction.inference INFO: ==> 0.0489056 seconds to write file /tmp/tmpfdqwp4_l
2022-04-26 16:11:51,241 alphaction.inference INFO: CATEGORIES (12):
[ {'id': 1, 'name': 'cut (an object)'},
  {'id': 2, 'name': 'holding for (a person)'},
  {'id': 3, 'name': 'handover to (a person)'},
  {'id': 4, 'name': 'squeeze (an object)'},
  {'id': 5, 'name': 'sprinkle (an object)'},
  {'id': 6, 'name': 'transfer (an object)'},
  {'id': 7, 'name': 'pour (an object)'},
  {'id': 8, 'name': 'heat (an object)'},
  {'id': 9, 'name': 'stir (an object)'},
  {'id': 10, 'name': 'wrap (an object)'},
  {'id': 11, 'name': 'roll (an object)'},
  {'id': 12, 'name': 'dip (an object)'}]
2022-04-26 16:11:51,242 alphaction.inference INFO: ==> 0.000509501 seconds to read file data/lfv_robalo/annotations/lfv_robalo_val.csv
2022-04-26 16:11:51,259 alphaction.inference INFO: ==> 0.0172069 seconds to convert groundtruth
2022-04-26 16:11:51,278 alphaction.inference INFO: ==> 0.0188971 seconds to read file /tmp/tmpfdqwp4_l
2022-04-26 16:11:51,611 alphaction.inference INFO: ==> 0.332776 seconds to convert detections
2022-04-26 16:11:51,611 alphaction.inference INFO: The following classes have no ground truth examples: [ 2  3 10 11 12]
2022-04-26 16:11:51,614 alphaction.inference INFO: ==> 0.00290084 seconds to run_evaluator
2022-04-26 16:11:51,615 alphaction.inference INFO: { 'PascalBoxes_PerformanceByCategory/AP@0.5IOU/cut (an object)': 0.7022192275052686,
  'PascalBoxes_PerformanceByCategory/AP@0.5IOU/dip (an object)': nan,
  'PascalBoxes_PerformanceByCategory/AP@0.5IOU/handover to (a person)': nan,
  'PascalBoxes_PerformanceByCategory/AP@0.5IOU/heat (an object)': 0.6852940079074499,
  'PascalBoxes_PerformanceByCategory/AP@0.5IOU/holding for (a person)': nan,
  'PascalBoxes_PerformanceByCategory/AP@0.5IOU/pour (an object)': 0.3044117647058824,
  'PascalBoxes_PerformanceByCategory/AP@0.5IOU/roll (an object)': nan,
  'PascalBoxes_PerformanceByCategory/AP@0.5IOU/sprinkle (an object)': 0.02666666666666667,
  'PascalBoxes_PerformanceByCategory/AP@0.5IOU/squeeze (an object)': 0.09204931972789114,
  'PascalBoxes_PerformanceByCategory/AP@0.5IOU/stir (an object)': 0.5106952954879223,
  'PascalBoxes_PerformanceByCategory/AP@0.5IOU/transfer (an object)': 0.38332291433541377,
  'PascalBoxes_PerformanceByCategory/AP@0.5IOU/wrap (an object)': nan,
  'PascalBoxes_Precision/mAP@0.5IOU': 0.3863798851909278}
2022-04-26 16:12:01,714 alphaction.trainer INFO: eta: 5 days, 3:52:46  iter: 2220  loss_pose_action: 0.1569 (0.6466)  loss_object_interaction: 0.0002 (0.0009)  loss_person_interaction: 0.0002 (0.0009)  total_loss: 0.1994 (0.8341)  accuracy_pose_action: 0.6667 (0.6763)  accuracy_object_interaction: 1.0000 (0.9964)  accuracy_person_interaction: 1.0000 (0.9968)  time: 0.5000 (0.5081)  data: 0.0135 (0.0141)  lr: 0.000125  max mem: 2403
2022-04-26 16:12:11,909 alphaction.trainer INFO: eta: 5 days, 3:52:49  iter: 2240  loss_pose_action: 0.0379 (0.6430)  loss_object_interaction: 0.0001 (0.0009)  loss_person_interaction: 0.0001 (0.0009)  total_loss: 0.0504 (0.8293)  accuracy_pose_action: 1.0000 (0.6778)  accuracy_object_interaction: 1.0000 (0.9964)  accuracy_person_interaction: 1.0000 (0.9969)  time: 0.5123 (0.5081)  data: 0.0140 (0.0141)  lr: 0.000125  max mem: 2403
2022-04-26 16:12:22,101 alphaction.trainer INFO: eta: 5 days, 3:52:50  iter: 2260  loss_pose_action: 0.2208 (0.6421)  loss_object_interaction: 0.0001 (0.0009)  loss_person_interaction: 0.0001 (0.0009)  total_loss: 0.2839 (0.8279)  accuracy_pose_action: 0.6667 (0.6780)  accuracy_object_interaction: 1.0000 (0.9965)  accuracy_person_interaction: 1.0000 (0.9969)  time: 0.5135 (0.5081)  data: 0.0141 (0.0141)  lr: 0.000125  max mem: 2403
2022-04-26 16:12:32,298 alphaction.trainer INFO: eta: 5 days, 3:52:53  iter: 2280  loss_pose_action: 0.2287 (0.6400)  loss_object_interaction: 0.0003 (0.0009)  loss_person_interaction: 0.0003 (0.0009)  total_loss: 0.3120 (0.8252)  accuracy_pose_action: 0.6667 (0.6783)  accuracy_object_interaction: 1.0000 (0.9965)  accuracy_person_interaction: 1.0000 (0.9969)  time: 0.5122 (0.5081)  data: 0.0140 (0.0141)  lr: 0.000125  max mem: 2403
2022-04-26 16:12:42,535 alphaction.trainer INFO: eta: 5 days, 3:53:12  iter: 2300  loss_pose_action: 0.0253 (0.6364)  loss_object_interaction: 0.0001 (0.0009)  loss_person_interaction: 0.0001 (0.0009)  total_loss: 0.0523 (0.8205)  accuracy_pose_action: 1.0000 (0.6799)  accuracy_object_interaction: 1.0000 (0.9965)  accuracy_person_interaction: 1.0000 (0.9970)  time: 0.5140 (0.5081)  data: 0.0140 (0.0141)  lr: 0.000125  max mem: 2403
2022-04-26 16:12:42,538 alphaction.utils.checkpoint INFO: Saving checkpoint to data/output/resnet50_4x16f_baseline_robalo/model_0002300.pth
2022-04-26 16:12:42,808 alphaction.inference INFO: Start evaluation on lfv_robalo_val_ava_video dataset(135 videos).
2022-04-26 16:12:57,714 alphaction.inference INFO: Total inference time: 0:00:14.905343 (0.11040994856092665 s / video per device, on 1 devices)
2022-04-26 16:12:57,714 alphaction.inference INFO: performing ava evaluation.
2022-04-26 16:12:57,714 alphaction.inference INFO: Preparing results for AVA format
2022-04-26 16:12:57,730 alphaction.inference INFO: Evaluating predictions
2022-04-26 16:12:57,779 alphaction.inference INFO: ==> 0.0485523 seconds to write file /tmp/tmpjcw0nu5j
2022-04-26 16:12:57,780 alphaction.inference INFO: CATEGORIES (12):
[ {'id': 1, 'name': 'cut (an object)'},
  {'id': 2, 'name': 'holding for (a person)'},
  {'id': 3, 'name': 'handover to (a person)'},
  {'id': 4, 'name': 'squeeze (an object)'},
  {'id': 5, 'name': 'sprinkle (an object)'},
  {'id': 6, 'name': 'transfer (an object)'},
  {'id': 7, 'name': 'pour (an object)'},
  {'id': 8, 'name': 'heat (an object)'},
  {'id': 9, 'name': 'stir (an object)'},
  {'id': 10, 'name': 'wrap (an object)'},
  {'id': 11, 'name': 'roll (an object)'},
  {'id': 12, 'name': 'dip (an object)'}]
2022-04-26 16:12:57,781 alphaction.inference INFO: ==> 0.000644207 seconds to read file data/lfv_robalo/annotations/lfv_robalo_val.csv
2022-04-26 16:12:57,798 alphaction.inference INFO: ==> 0.0170939 seconds to convert groundtruth
2022-04-26 16:12:57,819 alphaction.inference INFO: ==> 0.0202155 seconds to read file /tmp/tmpjcw0nu5j
2022-04-26 16:12:58,151 alphaction.inference INFO: ==> 0.33207 seconds to convert detections
2022-04-26 16:12:58,151 alphaction.inference INFO: The following classes have no ground truth examples: [ 2  3 10 11 12]
2022-04-26 16:12:58,154 alphaction.inference INFO: ==> 0.00278211 seconds to run_evaluator
2022-04-26 16:12:58,155 alphaction.inference INFO: { 'PascalBoxes_PerformanceByCategory/AP@0.5IOU/cut (an object)': 0.7766825388354668,
  'PascalBoxes_PerformanceByCategory/AP@0.5IOU/dip (an object)': nan,
  'PascalBoxes_PerformanceByCategory/AP@0.5IOU/handover to (a person)': nan,
  'PascalBoxes_PerformanceByCategory/AP@0.5IOU/heat (an object)': 0.6896633850859883,
  'PascalBoxes_PerformanceByCategory/AP@0.5IOU/holding for (a person)': nan,
  'PascalBoxes_PerformanceByCategory/AP@0.5IOU/pour (an object)': 0.1828042328042328,
  'PascalBoxes_PerformanceByCategory/AP@0.5IOU/roll (an object)': nan,
  'PascalBoxes_PerformanceByCategory/AP@0.5IOU/sprinkle (an object)': 0.058823529411764705,
  'PascalBoxes_PerformanceByCategory/AP@0.5IOU/squeeze (an object)': 0.0958215697346132,
  'PascalBoxes_PerformanceByCategory/AP@0.5IOU/stir (an object)': 0.522792328100089,
  'PascalBoxes_PerformanceByCategory/AP@0.5IOU/transfer (an object)': 0.4360174379471619,
  'PascalBoxes_PerformanceByCategory/AP@0.5IOU/wrap (an object)': nan,
  'PascalBoxes_Precision/mAP@0.5IOU': 0.3946578602741881}
2022-04-26 16:13:08,286 alphaction.trainer INFO: eta: 5 days, 3:52:49  iter: 2320  loss_pose_action: 0.1529 (0.6334)  loss_object_interaction: 0.0002 (0.0008)  loss_person_interaction: 0.0001 (0.0009)  total_loss: 0.2112 (0.8165)  accuracy_pose_action: 1.0000 (0.6810)  accuracy_object_interaction: 1.0000 (0.9966)  accuracy_person_interaction: 1.0000 (0.9970)  time: 0.5076 (0.5081)  data: 0.0134 (0.0141)  lr: 0.000125  max mem: 2403
2022-04-26 16:13:18,474 alphaction.trainer INFO: eta: 5 days, 3:52:49  iter: 2340  loss_pose_action: 0.0084 (0.6300)  loss_object_interaction: 0.0000 (0.0008)  loss_person_interaction: 0.0000 (0.0009)  total_loss: 0.0137 (0.8120)  accuracy_pose_action: 1.0000 (0.6830)  accuracy_object_interaction: 1.0000 (0.9966)  accuracy_person_interaction: 1.0000 (0.9970)  time: 0.5098 (0.5081)  data: 0.0140 (0.0141)  lr: 0.000125  max mem: 2403
2022-04-26 16:13:28,724 alphaction.trainer INFO: eta: 5 days, 3:53:11  iter: 2360  loss_pose_action: 0.0495 (0.6270)  loss_object_interaction: 0.0001 (0.0008)  loss_person_interaction: 0.0001 (0.0009)  total_loss: 0.0837 (0.8081)  accuracy_pose_action: 1.0000 (0.6839)  accuracy_object_interaction: 1.0000 (0.9966)  accuracy_person_interaction: 1.0000 (0.9970)  time: 0.5120 (0.5082)  data: 0.0138 (0.0141)  lr: 0.000125  max mem: 2403
2022-04-26 16:13:38,956 alphaction.trainer INFO: eta: 5 days, 3:53:26  iter: 2380  loss_pose_action: 0.0067 (0.6237)  loss_object_interaction: 0.0001 (0.0008)  loss_person_interaction: 0.0001 (0.0009)  total_loss: 0.0171 (0.8038)  accuracy_pose_action: 1.0000 (0.6853)  accuracy_object_interaction: 1.0000 (0.9966)  accuracy_person_interaction: 1.0000 (0.9971)  time: 0.5125 (0.5082)  data: 0.0143 (0.0141)  lr: 0.000125  max mem: 2403
2022-04-26 16:13:49,198 alphaction.trainer INFO: eta: 5 days, 3:53:44  iter: 2400  loss_pose_action: 0.1811 (0.6228)  loss_object_interaction: 0.0001 (0.0008)  loss_person_interaction: 0.0001 (0.0009)  total_loss: 0.2391 (0.8024)  accuracy_pose_action: 0.6667 (0.6860)  accuracy_object_interaction: 1.0000 (0.9967)  accuracy_person_interaction: 1.0000 (0.9971)  time: 0.5135 (0.5082)  data: 0.0139 (0.0141)  lr: 0.000125  max mem: 2403
2022-04-26 16:13:49,201 alphaction.utils.checkpoint INFO: Saving checkpoint to data/output/resnet50_4x16f_baseline_robalo/model_0002400.pth
2022-04-26 16:13:49,457 alphaction.inference INFO: Start evaluation on lfv_robalo_val_ava_video dataset(135 videos).
2022-04-26 16:14:04,002 alphaction.inference INFO: Total inference time: 0:00:14.545384 (0.10774358290213126 s / video per device, on 1 devices)
2022-04-26 16:14:04,003 alphaction.inference INFO: performing ava evaluation.
2022-04-26 16:14:04,004 alphaction.inference INFO: Preparing results for AVA format
2022-04-26 16:14:04,026 alphaction.inference INFO: Evaluating predictions
2022-04-26 16:14:04,080 alphaction.inference INFO: ==> 0.05358 seconds to write file /tmp/tmpl7yo377h
2022-04-26 16:14:04,081 alphaction.inference INFO: CATEGORIES (12):
[ {'id': 1, 'name': 'cut (an object)'},
  {'id': 2, 'name': 'holding for (a person)'},
  {'id': 3, 'name': 'handover to (a person)'},
  {'id': 4, 'name': 'squeeze (an object)'},
  {'id': 5, 'name': 'sprinkle (an object)'},
  {'id': 6, 'name': 'transfer (an object)'},
  {'id': 7, 'name': 'pour (an object)'},
  {'id': 8, 'name': 'heat (an object)'},
  {'id': 9, 'name': 'stir (an object)'},
  {'id': 10, 'name': 'wrap (an object)'},
  {'id': 11, 'name': 'roll (an object)'},
  {'id': 12, 'name': 'dip (an object)'}]
2022-04-26 16:14:04,081 alphaction.inference INFO: ==> 0.00042367 seconds to read file data/lfv_robalo/annotations/lfv_robalo_val.csv
2022-04-26 16:14:04,099 alphaction.inference INFO: ==> 0.0172901 seconds to convert groundtruth
2022-04-26 16:14:04,120 alphaction.inference INFO: ==> 0.020596 seconds to read file /tmp/tmpl7yo377h
2022-04-26 16:14:04,461 alphaction.inference INFO: ==> 0.341555 seconds to convert detections
2022-04-26 16:14:04,461 alphaction.inference INFO: The following classes have no ground truth examples: [ 2  3 10 11 12]
2022-04-26 16:14:04,464 alphaction.inference INFO: ==> 0.00273681 seconds to run_evaluator
2022-04-26 16:14:04,465 alphaction.inference INFO: { 'PascalBoxes_PerformanceByCategory/AP@0.5IOU/cut (an object)': 0.7668308751589524,
  'PascalBoxes_PerformanceByCategory/AP@0.5IOU/dip (an object)': nan,
  'PascalBoxes_PerformanceByCategory/AP@0.5IOU/handover to (a person)': nan,
  'PascalBoxes_PerformanceByCategory/AP@0.5IOU/heat (an object)': 0.6977125277209508,
  'PascalBoxes_PerformanceByCategory/AP@0.5IOU/holding for (a person)': nan,
  'PascalBoxes_PerformanceByCategory/AP@0.5IOU/pour (an object)': 0.13407148407148406,
  'PascalBoxes_PerformanceByCategory/AP@0.5IOU/roll (an object)': nan,
  'PascalBoxes_PerformanceByCategory/AP@0.5IOU/sprinkle (an object)': 0.05213903743315508,
  'PascalBoxes_PerformanceByCategory/AP@0.5IOU/squeeze (an object)': 0.0649185927782419,
  'PascalBoxes_PerformanceByCategory/AP@0.5IOU/stir (an object)': 0.2057232049429272,
  'PascalBoxes_PerformanceByCategory/AP@0.5IOU/transfer (an object)': 0.4536230274809684,
  'PascalBoxes_PerformanceByCategory/AP@0.5IOU/wrap (an object)': nan,
  'PascalBoxes_Precision/mAP@0.5IOU': 0.33928839279809714}
2022-04-26 16:14:14,537 alphaction.trainer INFO: eta: 5 days, 3:53:00  iter: 2420  loss_pose_action: 0.0423 (0.6192)  loss_object_interaction: 0.0002 (0.0008)  loss_person_interaction: 0.0002 (0.0009)  total_loss: 0.0910 (0.7978)  accuracy_pose_action: 1.0000 (0.6873)  accuracy_object_interaction: 1.0000 (0.9967)  accuracy_person_interaction: 1.0000 (0.9971)  time: 0.5057 (0.5082)  data: 0.0136 (0.0141)  lr: 0.000125  max mem: 2403
2022-04-26 16:14:24,697 alphaction.trainer INFO: eta: 5 days, 3:52:48  iter: 2440  loss_pose_action: 0.0424 (0.6153)  loss_object_interaction: 0.0001 (0.0008)  loss_person_interaction: 0.0001 (0.0009)  total_loss: 0.0581 (0.7928)  accuracy_pose_action: 1.0000 (0.6893)  accuracy_object_interaction: 1.0000 (0.9967)  accuracy_person_interaction: 1.0000 (0.9971)  time: 0.5062 (0.5082)  data: 0.0143 (0.0141)  lr: 0.000125  max mem: 2403
2022-04-26 16:14:34,880 alphaction.trainer INFO: eta: 5 days, 3:52:45  iter: 2460  loss_pose_action: 0.0010 (0.6106)  loss_object_interaction: 0.0000 (0.0008)  loss_person_interaction: 0.0000 (0.0008)  total_loss: 0.0049 (0.7867)  accuracy_pose_action: 1.0000 (0.6917)  accuracy_object_interaction: 1.0000 (0.9967)  accuracy_person_interaction: 1.0000 (0.9972)  time: 0.5124 (0.5082)  data: 0.0138 (0.0141)  lr: 0.000125  max mem: 2403
2022-04-26 16:14:45,114 alphaction.trainer INFO: eta: 5 days, 3:53:00  iter: 2480  loss_pose_action: 0.0005 (0.6071)  loss_object_interaction: 0.0000 (0.0008)  loss_person_interaction: 0.0000 (0.0008)  total_loss: 0.0018 (0.7822)  accuracy_pose_action: 1.0000 (0.6935)  accuracy_object_interaction: 1.0000 (0.9968)  accuracy_person_interaction: 1.0000 (0.9972)  time: 0.5156 (0.5082)  data: 0.0140 (0.0141)  lr: 0.000125  max mem: 2403
2022-04-26 16:14:55,349 alphaction.trainer INFO: eta: 5 days, 3:53:14  iter: 2500  loss_pose_action: 0.0149 (0.6037)  loss_object_interaction: 0.0000 (0.0008)  loss_person_interaction: 0.0000 (0.0008)  total_loss: 0.0250 (0.7776)  accuracy_pose_action: 1.0000 (0.6950)  accuracy_object_interaction: 1.0000 (0.9968)  accuracy_person_interaction: 1.0000 (0.9972)  time: 0.5148 (0.5083)  data: 0.0139 (0.0141)  lr: 0.000125  max mem: 2403
2022-04-26 16:14:55,352 alphaction.utils.checkpoint INFO: Saving checkpoint to data/output/resnet50_4x16f_baseline_robalo/model_0002500.pth
2022-04-26 16:14:55,652 alphaction.inference INFO: Start evaluation on lfv_robalo_val_ava_video dataset(135 videos).
2022-04-26 16:15:10,342 alphaction.inference INFO: Total inference time: 0:00:14.689681 (0.10881245401170518 s / video per device, on 1 devices)
2022-04-26 16:15:10,342 alphaction.inference INFO: performing ava evaluation.
2022-04-26 16:15:10,342 alphaction.inference INFO: Preparing results for AVA format
2022-04-26 16:15:10,359 alphaction.inference INFO: Evaluating predictions
2022-04-26 16:15:10,408 alphaction.inference INFO: ==> 0.0491321 seconds to write file /tmp/tmp6ry0lx_r
2022-04-26 16:15:10,408 alphaction.inference INFO: CATEGORIES (12):
[ {'id': 1, 'name': 'cut (an object)'},
  {'id': 2, 'name': 'holding for (a person)'},
  {'id': 3, 'name': 'handover to (a person)'},
  {'id': 4, 'name': 'squeeze (an object)'},
  {'id': 5, 'name': 'sprinkle (an object)'},
  {'id': 6, 'name': 'transfer (an object)'},
  {'id': 7, 'name': 'pour (an object)'},
  {'id': 8, 'name': 'heat (an object)'},
  {'id': 9, 'name': 'stir (an object)'},
  {'id': 10, 'name': 'wrap (an object)'},
  {'id': 11, 'name': 'roll (an object)'},
  {'id': 12, 'name': 'dip (an object)'}]
2022-04-26 16:15:10,409 alphaction.inference INFO: ==> 0.0004282 seconds to read file data/lfv_robalo/annotations/lfv_robalo_val.csv
2022-04-26 16:15:10,427 alphaction.inference INFO: ==> 0.0182517 seconds to convert groundtruth
2022-04-26 16:15:10,448 alphaction.inference INFO: ==> 0.0201628 seconds to read file /tmp/tmp6ry0lx_r
2022-04-26 16:15:10,792 alphaction.inference INFO: ==> 0.344516 seconds to convert detections
2022-04-26 16:15:10,792 alphaction.inference INFO: The following classes have no ground truth examples: [ 2  3 10 11 12]
2022-04-26 16:15:10,795 alphaction.inference INFO: ==> 0.0027318 seconds to run_evaluator
2022-04-26 16:15:10,796 alphaction.inference INFO: { 'PascalBoxes_PerformanceByCategory/AP@0.5IOU/cut (an object)': 0.7028730812230456,
  'PascalBoxes_PerformanceByCategory/AP@0.5IOU/dip (an object)': nan,
  'PascalBoxes_PerformanceByCategory/AP@0.5IOU/handover to (a person)': nan,
  'PascalBoxes_PerformanceByCategory/AP@0.5IOU/heat (an object)': 0.6758708023267633,
  'PascalBoxes_PerformanceByCategory/AP@0.5IOU/holding for (a person)': nan,
  'PascalBoxes_PerformanceByCategory/AP@0.5IOU/pour (an object)': 0.25892448512585814,
  'PascalBoxes_PerformanceByCategory/AP@0.5IOU/roll (an object)': nan,
  'PascalBoxes_PerformanceByCategory/AP@0.5IOU/sprinkle (an object)': 0.05128205128205128,
  'PascalBoxes_PerformanceByCategory/AP@0.5IOU/squeeze (an object)': 0.08132165937043985,
  'PascalBoxes_PerformanceByCategory/AP@0.5IOU/stir (an object)': 0.5039011786471874,
  'PascalBoxes_PerformanceByCategory/AP@0.5IOU/transfer (an object)': 0.506154584805365,
  'PascalBoxes_PerformanceByCategory/AP@0.5IOU/wrap (an object)': nan,
  'PascalBoxes_Precision/mAP@0.5IOU': 0.3971896918258158}
2022-04-26 16:15:20,910 alphaction.trainer INFO: eta: 5 days, 3:52:46  iter: 2520  loss_pose_action: 0.0123 (0.6003)  loss_object_interaction: 0.0000 (0.0008)  loss_person_interaction: 0.0000 (0.0008)  total_loss: 0.0288 (0.7732)  accuracy_pose_action: 1.0000 (0.6967)  accuracy_object_interaction: 1.0000 (0.9968)  accuracy_person_interaction: 1.0000 (0.9972)  time: 0.5077 (0.5082)  data: 0.0138 (0.0141)  lr: 0.000125  max mem: 2403
2022-04-26 16:15:31,074 alphaction.trainer INFO: eta: 5 days, 3:52:35  iter: 2540  loss_pose_action: 0.0219 (0.5976)  loss_object_interaction: 0.0001 (0.0008)  loss_person_interaction: 0.0001 (0.0008)  total_loss: 0.0332 (0.7696)  accuracy_pose_action: 1.0000 (0.6974)  accuracy_object_interaction: 1.0000 (0.9969)  accuracy_person_interaction: 1.0000 (0.9972)  time: 0.5118 (0.5082)  data: 0.0135 (0.0141)  lr: 0.000125  max mem: 2403
2022-04-26 16:15:41,322 alphaction.trainer INFO: eta: 5 days, 3:52:53  iter: 2560  loss_pose_action: 0.0318 (0.5958)  loss_object_interaction: 0.0001 (0.0008)  loss_person_interaction: 0.0001 (0.0008)  total_loss: 0.0653 (0.7672)  accuracy_pose_action: 1.0000 (0.6981)  accuracy_object_interaction: 1.0000 (0.9969)  accuracy_person_interaction: 1.0000 (0.9973)  time: 0.5138 (0.5083)  data: 0.0140 (0.0141)  lr: 0.000125  max mem: 2403
2022-04-26 16:15:51,567 alphaction.trainer INFO: eta: 5 days, 3:53:10  iter: 2580  loss_pose_action: 0.0306 (0.5922)  loss_object_interaction: 0.0002 (0.0008)  loss_person_interaction: 0.0002 (0.0008)  total_loss: 0.0674 (0.7627)  accuracy_pose_action: 1.0000 (0.6997)  accuracy_object_interaction: 1.0000 (0.9969)  accuracy_person_interaction: 1.0000 (0.9973)  time: 0.5131 (0.5083)  data: 0.0136 (0.0141)  lr: 0.000125  max mem: 2403
2022-04-26 16:16:01,809 alphaction.trainer INFO: eta: 5 days, 3:53:26  iter: 2600  loss_pose_action: 0.0041 (0.5881)  loss_object_interaction: 0.0001 (0.0008)  loss_person_interaction: 0.0001 (0.0008)  total_loss: 0.0116 (0.7575)  accuracy_pose_action: 1.0000 (0.7016)  accuracy_object_interaction: 1.0000 (0.9969)  accuracy_person_interaction: 1.0000 (0.9973)  time: 0.5138 (0.5083)  data: 0.0142 (0.0141)  lr: 0.000125  max mem: 2403
2022-04-26 16:16:01,811 alphaction.utils.checkpoint INFO: Saving checkpoint to data/output/resnet50_4x16f_baseline_robalo/model_0002600.pth
2022-04-26 16:16:02,073 alphaction.inference INFO: Start evaluation on lfv_robalo_val_ava_video dataset(135 videos).
2022-04-26 16:16:17,045 alphaction.inference INFO: Total inference time: 0:00:14.971058 (0.11089672335871943 s / video per device, on 1 devices)
2022-04-26 16:16:17,045 alphaction.inference INFO: performing ava evaluation.
2022-04-26 16:16:17,046 alphaction.inference INFO: Preparing results for AVA format
2022-04-26 16:16:17,078 alphaction.inference INFO: Evaluating predictions
2022-04-26 16:16:17,129 alphaction.inference INFO: ==> 0.0506275 seconds to write file /tmp/tmpofa6tu83
2022-04-26 16:16:17,129 alphaction.inference INFO: CATEGORIES (12):
[ {'id': 1, 'name': 'cut (an object)'},
  {'id': 2, 'name': 'holding for (a person)'},
  {'id': 3, 'name': 'handover to (a person)'},
  {'id': 4, 'name': 'squeeze (an object)'},
  {'id': 5, 'name': 'sprinkle (an object)'},
  {'id': 6, 'name': 'transfer (an object)'},
  {'id': 7, 'name': 'pour (an object)'},
  {'id': 8, 'name': 'heat (an object)'},
  {'id': 9, 'name': 'stir (an object)'},
  {'id': 10, 'name': 'wrap (an object)'},
  {'id': 11, 'name': 'roll (an object)'},
  {'id': 12, 'name': 'dip (an object)'}]
2022-04-26 16:16:17,130 alphaction.inference INFO: ==> 0.00056839 seconds to read file data/lfv_robalo/annotations/lfv_robalo_val.csv
2022-04-26 16:16:17,146 alphaction.inference INFO: ==> 0.0160537 seconds to convert groundtruth
2022-04-26 16:16:17,166 alphaction.inference INFO: ==> 0.0191643 seconds to read file /tmp/tmpofa6tu83
2022-04-26 16:16:17,499 alphaction.inference INFO: ==> 0.332963 seconds to convert detections
2022-04-26 16:16:17,499 alphaction.inference INFO: The following classes have no ground truth examples: [ 2  3 10 11 12]
2022-04-26 16:16:17,501 alphaction.inference INFO: ==> 0.00275016 seconds to run_evaluator
2022-04-26 16:16:17,502 alphaction.inference INFO: { 'PascalBoxes_PerformanceByCategory/AP@0.5IOU/cut (an object)': 0.6500546188615746,
  'PascalBoxes_PerformanceByCategory/AP@0.5IOU/dip (an object)': nan,
  'PascalBoxes_PerformanceByCategory/AP@0.5IOU/handover to (a person)': nan,
  'PascalBoxes_PerformanceByCategory/AP@0.5IOU/heat (an object)': 0.7015447056760187,
  'PascalBoxes_PerformanceByCategory/AP@0.5IOU/holding for (a person)': nan,
  'PascalBoxes_PerformanceByCategory/AP@0.5IOU/pour (an object)': 0.2923351158645276,
  'PascalBoxes_PerformanceByCategory/AP@0.5IOU/roll (an object)': nan,
  'PascalBoxes_PerformanceByCategory/AP@0.5IOU/sprinkle (an object)': 0.02666666666666667,
  'PascalBoxes_PerformanceByCategory/AP@0.5IOU/squeeze (an object)': 0.07610957004160887,
  'PascalBoxes_PerformanceByCategory/AP@0.5IOU/stir (an object)': 0.2904922285820653,
  'PascalBoxes_PerformanceByCategory/AP@0.5IOU/transfer (an object)': 0.5217039460002493,
  'PascalBoxes_PerformanceByCategory/AP@0.5IOU/wrap (an object)': nan,
  'PascalBoxes_Precision/mAP@0.5IOU': 0.36555812167038726}
2022-04-26 16:16:27,609 alphaction.trainer INFO: eta: 5 days, 3:52:55  iter: 2620  loss_pose_action: 0.0049 (0.5857)  loss_object_interaction: 0.0000 (0.0008)  loss_person_interaction: 0.0000 (0.0008)  total_loss: 0.0083 (0.7541)  accuracy_pose_action: 1.0000 (0.7029)  accuracy_object_interaction: 1.0000 (0.9969)  accuracy_person_interaction: 1.0000 (0.9973)  time: 0.5069 (0.5083)  data: 0.0136 (0.0141)  lr: 0.000125  max mem: 2403
2022-04-26 16:16:37,760 alphaction.trainer INFO: eta: 5 days, 3:52:40  iter: 2640  loss_pose_action: 0.0049 (0.5824)  loss_object_interaction: 0.0001 (0.0008)  loss_person_interaction: 0.0001 (0.0008)  total_loss: 0.0284 (0.7499)  accuracy_pose_action: 1.0000 (0.7046)  accuracy_object_interaction: 1.0000 (0.9970)  accuracy_person_interaction: 1.0000 (0.9973)  time: 0.5095 (0.5083)  data: 0.0137 (0.0141)  lr: 0.000125  max mem: 2403
2022-04-26 16:16:47,987 alphaction.trainer INFO: eta: 5 days, 3:52:50  iter: 2660  loss_pose_action: 0.0061 (0.5798)  loss_object_interaction: 0.0001 (0.0008)  loss_person_interaction: 0.0000 (0.0008)  total_loss: 0.0237 (0.7465)  accuracy_pose_action: 1.0000 (0.7058)  accuracy_object_interaction: 1.0000 (0.9970)  accuracy_person_interaction: 1.0000 (0.9974)  time: 0.5129 (0.5083)  data: 0.0140 (0.0141)  lr: 0.000125  max mem: 2403
2022-04-26 16:16:58,238 alphaction.trainer INFO: eta: 5 days, 3:53:07  iter: 2680  loss_pose_action: 0.0025 (0.5761)  loss_object_interaction: 0.0001 (0.0008)  loss_person_interaction: 0.0001 (0.0008)  total_loss: 0.0175 (0.7418)  accuracy_pose_action: 1.0000 (0.7071)  accuracy_object_interaction: 1.0000 (0.9970)  accuracy_person_interaction: 1.0000 (0.9974)  time: 0.5160 (0.5084)  data: 0.0143 (0.0141)  lr: 0.000125  max mem: 2403
2022-04-26 16:17:08,474 alphaction.trainer INFO: eta: 5 days, 3:53:19  iter: 2700  loss_pose_action: 0.0037 (0.5728)  loss_object_interaction: 0.0001 (0.0008)  loss_person_interaction: 0.0001 (0.0008)  total_loss: 0.0088 (0.7375)  accuracy_pose_action: 1.0000 (0.7087)  accuracy_object_interaction: 1.0000 (0.9970)  accuracy_person_interaction: 1.0000 (0.9974)  time: 0.5163 (0.5084)  data: 0.0141 (0.0141)  lr: 0.000125  max mem: 2403
2022-04-26 16:17:08,478 alphaction.utils.checkpoint INFO: Saving checkpoint to data/output/resnet50_4x16f_baseline_robalo/model_0002700.pth
2022-04-26 16:17:08,733 alphaction.inference INFO: Start evaluation on lfv_robalo_val_ava_video dataset(135 videos).
2022-04-26 16:17:23,426 alphaction.inference INFO: Total inference time: 0:00:14.693034 (0.10883729016339337 s / video per device, on 1 devices)
2022-04-26 16:17:23,426 alphaction.inference INFO: performing ava evaluation.
2022-04-26 16:17:23,426 alphaction.inference INFO: Preparing results for AVA format
2022-04-26 16:17:23,443 alphaction.inference INFO: Evaluating predictions
2022-04-26 16:17:23,493 alphaction.inference INFO: ==> 0.0492775 seconds to write file /tmp/tmp2it8h32l
2022-04-26 16:17:23,493 alphaction.inference INFO: CATEGORIES (12):
[ {'id': 1, 'name': 'cut (an object)'},
  {'id': 2, 'name': 'holding for (a person)'},
  {'id': 3, 'name': 'handover to (a person)'},
  {'id': 4, 'name': 'squeeze (an object)'},
  {'id': 5, 'name': 'sprinkle (an object)'},
  {'id': 6, 'name': 'transfer (an object)'},
  {'id': 7, 'name': 'pour (an object)'},
  {'id': 8, 'name': 'heat (an object)'},
  {'id': 9, 'name': 'stir (an object)'},
  {'id': 10, 'name': 'wrap (an object)'},
  {'id': 11, 'name': 'roll (an object)'},
  {'id': 12, 'name': 'dip (an object)'}]
2022-04-26 16:17:23,494 alphaction.inference INFO: ==> 0.000501156 seconds to read file data/lfv_robalo/annotations/lfv_robalo_val.csv
2022-04-26 16:17:23,512 alphaction.inference INFO: ==> 0.0179563 seconds to convert groundtruth
2022-04-26 16:17:23,531 alphaction.inference INFO: ==> 0.0191135 seconds to read file /tmp/tmp2it8h32l
2022-04-26 16:17:23,870 alphaction.inference INFO: ==> 0.338491 seconds to convert detections
2022-04-26 16:17:23,870 alphaction.inference INFO: The following classes have no ground truth examples: [ 2  3 10 11 12]
2022-04-26 16:17:23,873 alphaction.inference INFO: ==> 0.00279045 seconds to run_evaluator
2022-04-26 16:17:23,873 alphaction.inference INFO: { 'PascalBoxes_PerformanceByCategory/AP@0.5IOU/cut (an object)': 0.8464425000831284,
  'PascalBoxes_PerformanceByCategory/AP@0.5IOU/dip (an object)': nan,
  'PascalBoxes_PerformanceByCategory/AP@0.5IOU/handover to (a person)': nan,
  'PascalBoxes_PerformanceByCategory/AP@0.5IOU/heat (an object)': 0.7643542591918238,
  'PascalBoxes_PerformanceByCategory/AP@0.5IOU/holding for (a person)': nan,
  'PascalBoxes_PerformanceByCategory/AP@0.5IOU/pour (an object)': 0.287037037037037,
  'PascalBoxes_PerformanceByCategory/AP@0.5IOU/roll (an object)': nan,
  'PascalBoxes_PerformanceByCategory/AP@0.5IOU/sprinkle (an object)': 0.018518518518518517,
  'PascalBoxes_PerformanceByCategory/AP@0.5IOU/squeeze (an object)': 0.061946902654867256,
  'PascalBoxes_PerformanceByCategory/AP@0.5IOU/stir (an object)': 0.43925055991945616,
  'PascalBoxes_PerformanceByCategory/AP@0.5IOU/transfer (an object)': 0.4270301392319845,
  'PascalBoxes_PerformanceByCategory/AP@0.5IOU/wrap (an object)': nan,
  'PascalBoxes_Precision/mAP@0.5IOU': 0.40636855951954504}
2022-04-26 16:17:33,960 alphaction.trainer INFO: eta: 5 days, 3:52:42  iter: 2720  loss_pose_action: 0.0073 (0.5699)  loss_object_interaction: 0.0000 (0.0007)  loss_person_interaction: 0.0001 (0.0008)  total_loss: 0.0154 (0.7336)  accuracy_pose_action: 1.0000 (0.7102)  accuracy_object_interaction: 1.0000 (0.9971)  accuracy_person_interaction: 1.0000 (0.9974)  time: 0.5066 (0.5083)  data: 0.0141 (0.0141)  lr: 0.000125  max mem: 2403
2022-04-26 16:17:44,210 alphaction.trainer INFO: eta: 5 days, 3:52:59  iter: 2740  loss_pose_action: 0.0003 (0.5659)  loss_object_interaction: 0.0000 (0.0007)  loss_person_interaction: 0.0000 (0.0008)  total_loss: 0.0023 (0.7285)  accuracy_pose_action: 1.0000 (0.7121)  accuracy_object_interaction: 1.0000 (0.9971)  accuracy_person_interaction: 1.0000 (0.9974)  time: 0.5129 (0.5084)  data: 0.0141 (0.0141)  lr: 0.000125  max mem: 2403
2022-04-26 16:17:54,430 alphaction.trainer INFO: eta: 5 days, 3:53:05  iter: 2760  loss_pose_action: 0.0059 (0.5623)  loss_object_interaction: 0.0000 (0.0007)  loss_person_interaction: 0.0000 (0.0008)  total_loss: 0.0094 (0.7239)  accuracy_pose_action: 1.0000 (0.7140)  accuracy_object_interaction: 1.0000 (0.9971)  accuracy_person_interaction: 1.0000 (0.9975)  time: 0.5113 (0.5084)  data: 0.0137 (0.0141)  lr: 0.000125  max mem: 2403
2022-04-26 16:18:04,603 alphaction.trainer INFO: eta: 5 days, 3:52:57  iter: 2780  loss_pose_action: 0.0070 (0.5587)  loss_object_interaction: 0.0000 (0.0007)  loss_person_interaction: 0.0000 (0.0008)  total_loss: 0.0111 (0.7192)  accuracy_pose_action: 1.0000 (0.7158)  accuracy_object_interaction: 1.0000 (0.9971)  accuracy_person_interaction: 1.0000 (0.9975)  time: 0.5116 (0.5084)  data: 0.0136 (0.0141)  lr: 0.000125  max mem: 2403
2022-04-26 16:18:14,832 alphaction.trainer INFO: eta: 5 days, 3:53:06  iter: 2800  loss_pose_action: 0.0001 (0.5552)  loss_object_interaction: 0.0000 (0.0007)  loss_person_interaction: 0.0000 (0.0008)  total_loss: 0.0007 (0.7147)  accuracy_pose_action: 1.0000 (0.7174)  accuracy_object_interaction: 1.0000 (0.9971)  accuracy_person_interaction: 1.0000 (0.9975)  time: 0.5147 (0.5084)  data: 0.0141 (0.0141)  lr: 0.000125  max mem: 2403
2022-04-26 16:18:14,836 alphaction.utils.checkpoint INFO: Saving checkpoint to data/output/resnet50_4x16f_baseline_robalo/model_0002800.pth
2022-04-26 16:18:15,098 alphaction.inference INFO: Start evaluation on lfv_robalo_val_ava_video dataset(135 videos).
2022-04-26 16:18:29,793 alphaction.inference INFO: Total inference time: 0:00:14.694683 (0.10884950249283402 s / video per device, on 1 devices)
2022-04-26 16:18:29,793 alphaction.inference INFO: performing ava evaluation.
2022-04-26 16:18:29,793 alphaction.inference INFO: Preparing results for AVA format
2022-04-26 16:18:29,810 alphaction.inference INFO: Evaluating predictions
2022-04-26 16:18:29,862 alphaction.inference INFO: ==> 0.0513186 seconds to write file /tmp/tmpxbrr_frq
2022-04-26 16:18:29,862 alphaction.inference INFO: CATEGORIES (12):
[ {'id': 1, 'name': 'cut (an object)'},
  {'id': 2, 'name': 'holding for (a person)'},
  {'id': 3, 'name': 'handover to (a person)'},
  {'id': 4, 'name': 'squeeze (an object)'},
  {'id': 5, 'name': 'sprinkle (an object)'},
  {'id': 6, 'name': 'transfer (an object)'},
  {'id': 7, 'name': 'pour (an object)'},
  {'id': 8, 'name': 'heat (an object)'},
  {'id': 9, 'name': 'stir (an object)'},
  {'id': 10, 'name': 'wrap (an object)'},
  {'id': 11, 'name': 'roll (an object)'},
  {'id': 12, 'name': 'dip (an object)'}]
2022-04-26 16:18:29,863 alphaction.inference INFO: ==> 0.000478029 seconds to read file data/lfv_robalo/annotations/lfv_robalo_val.csv
2022-04-26 16:18:29,881 alphaction.inference INFO: ==> 0.0183759 seconds to convert groundtruth
2022-04-26 16:18:29,902 alphaction.inference INFO: ==> 0.0200317 seconds to read file /tmp/tmpxbrr_frq
2022-04-26 16:18:30,241 alphaction.inference INFO: ==> 0.338853 seconds to convert detections
2022-04-26 16:18:30,241 alphaction.inference INFO: The following classes have no ground truth examples: [ 2  3 10 11 12]
2022-04-26 16:18:30,244 alphaction.inference INFO: ==> 0.00275207 seconds to run_evaluator
2022-04-26 16:18:30,244 alphaction.inference INFO: { 'PascalBoxes_PerformanceByCategory/AP@0.5IOU/cut (an object)': 0.6390860994044945,
  'PascalBoxes_PerformanceByCategory/AP@0.5IOU/dip (an object)': nan,
  'PascalBoxes_PerformanceByCategory/AP@0.5IOU/handover to (a person)': nan,
  'PascalBoxes_PerformanceByCategory/AP@0.5IOU/heat (an object)': 0.7012336772070694,
  'PascalBoxes_PerformanceByCategory/AP@0.5IOU/holding for (a person)': nan,
  'PascalBoxes_PerformanceByCategory/AP@0.5IOU/pour (an object)': 0.08194164989939638,
  'PascalBoxes_PerformanceByCategory/AP@0.5IOU/roll (an object)': nan,
  'PascalBoxes_PerformanceByCategory/AP@0.5IOU/sprinkle (an object)': 0.04878048780487805,
  'PascalBoxes_PerformanceByCategory/AP@0.5IOU/squeeze (an object)': 0.0958904109589041,
  'PascalBoxes_PerformanceByCategory/AP@0.5IOU/stir (an object)': 0.4211787200763938,
  'PascalBoxes_PerformanceByCategory/AP@0.5IOU/transfer (an object)': 0.41015666180221677,
  'PascalBoxes_PerformanceByCategory/AP@0.5IOU/wrap (an object)': nan,
  'PascalBoxes_Precision/mAP@0.5IOU': 0.34260967245047896}
2022-04-26 16:18:40,324 alphaction.trainer INFO: eta: 5 days, 3:52:27  iter: 2820  loss_pose_action: 0.0060 (0.5522)  loss_object_interaction: 0.0000 (0.0007)  loss_person_interaction: 0.0000 (0.0008)  total_loss: 0.0078 (0.7108)  accuracy_pose_action: 1.0000 (0.7184)  accuracy_object_interaction: 1.0000 (0.9972)  accuracy_person_interaction: 1.0000 (0.9975)  time: 0.5081 (0.5084)  data: 0.0140 (0.0141)  lr: 0.000125  max mem: 2403
2022-04-26 16:18:50,452 alphaction.trainer INFO: eta: 5 days, 3:52:05  iter: 2840  loss_pose_action: 0.0009 (0.5486)  loss_object_interaction: 0.0000 (0.0007)  loss_person_interaction: 0.0000 (0.0007)  total_loss: 0.0043 (0.7062)  accuracy_pose_action: 1.0000 (0.7201)  accuracy_object_interaction: 1.0000 (0.9972)  accuracy_person_interaction: 1.0000 (0.9975)  time: 0.5074 (0.5084)  data: 0.0142 (0.0141)  lr: 0.000125  max mem: 2403
2022-04-26 16:19:00,705 alphaction.trainer INFO: eta: 5 days, 3:52:21  iter: 2860  loss_pose_action: 0.0066 (0.5466)  loss_object_interaction: 0.0001 (0.0007)  loss_person_interaction: 0.0000 (0.0007)  total_loss: 0.0114 (0.7035)  accuracy_pose_action: 1.0000 (0.7213)  accuracy_object_interaction: 1.0000 (0.9972)  accuracy_person_interaction: 1.0000 (0.9976)  time: 0.5149 (0.5084)  data: 0.0137 (0.0141)  lr: 0.000125  max mem: 2403
2022-04-26 16:19:10,930 alphaction.trainer INFO: eta: 5 days, 3:52:28  iter: 2880  loss_pose_action: 0.0186 (0.5444)  loss_object_interaction: 0.0000 (0.0007)  loss_person_interaction: 0.0001 (0.0007)  total_loss: 0.0261 (0.7005)  accuracy_pose_action: 1.0000 (0.7226)  accuracy_object_interaction: 1.0000 (0.9972)  accuracy_person_interaction: 1.0000 (0.9976)  time: 0.5136 (0.5084)  data: 0.0142 (0.0141)  lr: 0.000125  max mem: 2403
2022-04-26 16:19:21,173 alphaction.trainer INFO: eta: 5 days, 3:52:40  iter: 2900  loss_pose_action: 0.0091 (0.5409)  loss_object_interaction: 0.0000 (0.0007)  loss_person_interaction: 0.0000 (0.0007)  total_loss: 0.0143 (0.6960)  accuracy_pose_action: 1.0000 (0.7245)  accuracy_object_interaction: 1.0000 (0.9972)  accuracy_person_interaction: 1.0000 (0.9976)  time: 0.5163 (0.5084)  data: 0.0142 (0.0141)  lr: 0.000125  max mem: 2403
2022-04-26 16:19:21,176 alphaction.utils.checkpoint INFO: Saving checkpoint to data/output/resnet50_4x16f_baseline_robalo/model_0002900.pth
2022-04-26 16:19:21,451 alphaction.inference INFO: Start evaluation on lfv_robalo_val_ava_video dataset(135 videos).
2022-04-26 16:19:36,458 alphaction.inference INFO: Total inference time: 0:00:15.006247 (0.1111573819760923 s / video per device, on 1 devices)
2022-04-26 16:19:36,458 alphaction.inference INFO: performing ava evaluation.
2022-04-26 16:19:36,458 alphaction.inference INFO: Preparing results for AVA format
2022-04-26 16:19:36,476 alphaction.inference INFO: Evaluating predictions
2022-04-26 16:19:36,526 alphaction.inference INFO: ==> 0.0503063 seconds to write file /tmp/tmpl36nalhd
2022-04-26 16:19:36,527 alphaction.inference INFO: CATEGORIES (12):
[ {'id': 1, 'name': 'cut (an object)'},
  {'id': 2, 'name': 'holding for (a person)'},
  {'id': 3, 'name': 'handover to (a person)'},
  {'id': 4, 'name': 'squeeze (an object)'},
  {'id': 5, 'name': 'sprinkle (an object)'},
  {'id': 6, 'name': 'transfer (an object)'},
  {'id': 7, 'name': 'pour (an object)'},
  {'id': 8, 'name': 'heat (an object)'},
  {'id': 9, 'name': 'stir (an object)'},
  {'id': 10, 'name': 'wrap (an object)'},
  {'id': 11, 'name': 'roll (an object)'},
  {'id': 12, 'name': 'dip (an object)'}]
2022-04-26 16:19:36,527 alphaction.inference INFO: ==> 0.000426769 seconds to read file data/lfv_robalo/annotations/lfv_robalo_val.csv
2022-04-26 16:19:36,545 alphaction.inference INFO: ==> 0.017674 seconds to convert groundtruth
2022-04-26 16:19:36,564 alphaction.inference INFO: ==> 0.0194137 seconds to read file /tmp/tmpl36nalhd
2022-04-26 16:19:36,899 alphaction.inference INFO: ==> 0.33415 seconds to convert detections
2022-04-26 16:19:36,899 alphaction.inference INFO: The following classes have no ground truth examples: [ 2  3 10 11 12]
2022-04-26 16:19:36,901 alphaction.inference INFO: ==> 0.00260282 seconds to run_evaluator
2022-04-26 16:19:36,902 alphaction.inference INFO: { 'PascalBoxes_PerformanceByCategory/AP@0.5IOU/cut (an object)': 0.5576517336356069,
  'PascalBoxes_PerformanceByCategory/AP@0.5IOU/dip (an object)': nan,
  'PascalBoxes_PerformanceByCategory/AP@0.5IOU/handover to (a person)': nan,
  'PascalBoxes_PerformanceByCategory/AP@0.5IOU/heat (an object)': 0.7068520731324177,
  'PascalBoxes_PerformanceByCategory/AP@0.5IOU/holding for (a person)': nan,
  'PascalBoxes_PerformanceByCategory/AP@0.5IOU/pour (an object)': 0.08972073677956031,
  'PascalBoxes_PerformanceByCategory/AP@0.5IOU/roll (an object)': nan,
  'PascalBoxes_PerformanceByCategory/AP@0.5IOU/sprinkle (an object)': 0.023809523809523808,
  'PascalBoxes_PerformanceByCategory/AP@0.5IOU/squeeze (an object)': 0.06655844155844157,
  'PascalBoxes_PerformanceByCategory/AP@0.5IOU/stir (an object)': 0.543808328423713,
  'PascalBoxes_PerformanceByCategory/AP@0.5IOU/transfer (an object)': 0.4198449280321075,
  'PascalBoxes_PerformanceByCategory/AP@0.5IOU/wrap (an object)': nan,
  'PascalBoxes_Precision/mAP@0.5IOU': 0.34403510933876724}
2022-04-26 16:19:46,994 alphaction.trainer INFO: eta: 5 days, 3:52:06  iter: 2920  loss_pose_action: 0.0003 (0.5376)  loss_object_interaction: 0.0000 (0.0007)  loss_person_interaction: 0.0000 (0.0007)  total_loss: 0.0041 (0.6917)  accuracy_pose_action: 1.0000 (0.7261)  accuracy_object_interaction: 1.0000 (0.9973)  accuracy_person_interaction: 1.0000 (0.9976)  time: 0.5053 (0.5084)  data: 0.0140 (0.0141)  lr: 0.000125  max mem: 2403
2022-04-26 16:19:57,220 alphaction.trainer INFO: eta: 5 days, 3:52:13  iter: 2940  loss_pose_action: 0.0003 (0.5341)  loss_object_interaction: 0.0000 (0.0007)  loss_person_interaction: 0.0000 (0.0007)  total_loss: 0.0031 (0.6873)  accuracy_pose_action: 1.0000 (0.7278)  accuracy_object_interaction: 1.0000 (0.9973)  accuracy_person_interaction: 1.0000 (0.9976)  time: 0.5122 (0.5084)  data: 0.0139 (0.0141)  lr: 0.000125  max mem: 2403
2022-04-26 16:20:07,446 alphaction.trainer INFO: eta: 5 days, 3:52:20  iter: 2960  loss_pose_action: 0.0017 (0.5314)  loss_object_interaction: 0.0000 (0.0007)  loss_person_interaction: 0.0000 (0.0007)  total_loss: 0.0040 (0.6837)  accuracy_pose_action: 1.0000 (0.7289)  accuracy_object_interaction: 1.0000 (0.9973)  accuracy_person_interaction: 1.0000 (0.9976)  time: 0.5116 (0.5085)  data: 0.0143 (0.0141)  lr: 0.000125  max mem: 2403
2022-04-26 16:20:17,636 alphaction.trainer INFO: eta: 5 days, 3:52:16  iter: 2980  loss_pose_action: 0.0024 (0.5281)  loss_object_interaction: 0.0000 (0.0007)  loss_person_interaction: 0.0000 (0.0007)  total_loss: 0.0049 (0.6795)  accuracy_pose_action: 1.0000 (0.7304)  accuracy_object_interaction: 1.0000 (0.9973)  accuracy_person_interaction: 1.0000 (0.9977)  time: 0.5140 (0.5085)  data: 0.0142 (0.0141)  lr: 0.000125  max mem: 2403
2022-04-26 16:20:27,848 alphaction.trainer INFO: eta: 5 days, 3:52:18  iter: 3000  loss_pose_action: 0.0005 (0.5248)  loss_object_interaction: 0.0000 (0.0007)  loss_person_interaction: 0.0000 (0.0007)  total_loss: 0.0020 (0.6753)  accuracy_pose_action: 1.0000 (0.7321)  accuracy_object_interaction: 1.0000 (0.9973)  accuracy_person_interaction: 1.0000 (0.9977)  time: 0.5138 (0.5085)  data: 0.0140 (0.0141)  lr: 0.000125  max mem: 2403
2022-04-26 16:20:27,851 alphaction.utils.checkpoint INFO: Saving checkpoint to data/output/resnet50_4x16f_baseline_robalo/model_0003000.pth
2022-04-26 16:20:28,111 alphaction.inference INFO: Start evaluation on lfv_robalo_val_ava_video dataset(135 videos).
2022-04-26 16:20:42,558 alphaction.inference INFO: Total inference time: 0:00:14.446424 (0.10701055173520689 s / video per device, on 1 devices)
2022-04-26 16:20:42,558 alphaction.inference INFO: performing ava evaluation.
2022-04-26 16:20:42,558 alphaction.inference INFO: Preparing results for AVA format
2022-04-26 16:20:42,575 alphaction.inference INFO: Evaluating predictions
2022-04-26 16:20:42,625 alphaction.inference INFO: ==> 0.0498776 seconds to write file /tmp/tmp88n4ze4q
2022-04-26 16:20:42,625 alphaction.inference INFO: CATEGORIES (12):
[ {'id': 1, 'name': 'cut (an object)'},
  {'id': 2, 'name': 'holding for (a person)'},
  {'id': 3, 'name': 'handover to (a person)'},
  {'id': 4, 'name': 'squeeze (an object)'},
  {'id': 5, 'name': 'sprinkle (an object)'},
  {'id': 6, 'name': 'transfer (an object)'},
  {'id': 7, 'name': 'pour (an object)'},
  {'id': 8, 'name': 'heat (an object)'},
  {'id': 9, 'name': 'stir (an object)'},
  {'id': 10, 'name': 'wrap (an object)'},
  {'id': 11, 'name': 'roll (an object)'},
  {'id': 12, 'name': 'dip (an object)'}]
2022-04-26 16:20:42,627 alphaction.inference INFO: ==> 0.00116634 seconds to read file data/lfv_robalo/annotations/lfv_robalo_val.csv
2022-04-26 16:20:42,643 alphaction.inference INFO: ==> 0.0167897 seconds to convert groundtruth
2022-04-26 16:20:42,663 alphaction.inference INFO: ==> 0.0189943 seconds to read file /tmp/tmp88n4ze4q
2022-04-26 16:20:43,013 alphaction.inference INFO: ==> 0.350351 seconds to convert detections
2022-04-26 16:20:43,013 alphaction.inference INFO: The following classes have no ground truth examples: [ 2  3 10 11 12]
2022-04-26 16:20:43,016 alphaction.inference INFO: ==> 0.00281882 seconds to run_evaluator
2022-04-26 16:20:43,017 alphaction.inference INFO: { 'PascalBoxes_PerformanceByCategory/AP@0.5IOU/cut (an object)': 0.38302983469159047,
  'PascalBoxes_PerformanceByCategory/AP@0.5IOU/dip (an object)': nan,
  'PascalBoxes_PerformanceByCategory/AP@0.5IOU/handover to (a person)': nan,
  'PascalBoxes_PerformanceByCategory/AP@0.5IOU/heat (an object)': 0.6393692144352172,
  'PascalBoxes_PerformanceByCategory/AP@0.5IOU/holding for (a person)': nan,
  'PascalBoxes_PerformanceByCategory/AP@0.5IOU/pour (an object)': 0.11172506738544474,
  'PascalBoxes_PerformanceByCategory/AP@0.5IOU/roll (an object)': nan,
  'PascalBoxes_PerformanceByCategory/AP@0.5IOU/sprinkle (an object)': 0.047619047619047616,
  'PascalBoxes_PerformanceByCategory/AP@0.5IOU/squeeze (an object)': 0.07778115501519757,
  'PascalBoxes_PerformanceByCategory/AP@0.5IOU/stir (an object)': 0.3814413924556428,
  'PascalBoxes_PerformanceByCategory/AP@0.5IOU/transfer (an object)': 0.40353331120986946,
  'PascalBoxes_PerformanceByCategory/AP@0.5IOU/wrap (an object)': nan,
  'PascalBoxes_Precision/mAP@0.5IOU': 0.2920712889731443}
2022-04-26 16:20:53,081 alphaction.trainer INFO: eta: 5 days, 3:51:37  iter: 3020  loss_pose_action: 0.0013 (0.5216)  loss_object_interaction: 0.0000 (0.0007)  loss_person_interaction: 0.0000 (0.0007)  total_loss: 0.0030 (0.6711)  accuracy_pose_action: 1.0000 (0.7335)  accuracy_object_interaction: 1.0000 (0.9974)  accuracy_person_interaction: 1.0000 (0.9977)  time: 0.4998 (0.5084)  data: 0.0140 (0.0141)  lr: 0.000125  max mem: 2403
2022-04-26 16:21:03,261 alphaction.trainer INFO: eta: 5 days, 3:51:30  iter: 3040  loss_pose_action: 0.0001 (0.5187)  loss_object_interaction: 0.0000 (0.0007)  loss_person_interaction: 0.0000 (0.0007)  total_loss: 0.0016 (0.6673)  accuracy_pose_action: 1.0000 (0.7350)  accuracy_object_interaction: 1.0000 (0.9974)  accuracy_person_interaction: 1.0000 (0.9977)  time: 0.5086 (0.5084)  data: 0.0137 (0.0141)  lr: 0.000125  max mem: 2403
2022-04-26 16:21:13,508 alphaction.trainer INFO: eta: 5 days, 3:51:42  iter: 3060  loss_pose_action: 0.0000 (0.5159)  loss_object_interaction: 0.0000 (0.0007)  loss_person_interaction: 0.0000 (0.0007)  total_loss: 0.0004 (0.6637)  accuracy_pose_action: 1.0000 (0.7365)  accuracy_object_interaction: 1.0000 (0.9974)  accuracy_person_interaction: 1.0000 (0.9977)  time: 0.5126 (0.5085)  data: 0.0144 (0.0141)  lr: 0.000125  max mem: 2403
2022-04-26 16:21:23,756 alphaction.trainer INFO: eta: 5 days, 3:51:54  iter: 3080  loss_pose_action: 0.0000 (0.5130)  loss_object_interaction: 0.0000 (0.0007)  loss_person_interaction: 0.0000 (0.0007)  total_loss: 0.0015 (0.6599)  accuracy_pose_action: 1.0000 (0.7378)  accuracy_object_interaction: 1.0000 (0.9974)  accuracy_person_interaction: 1.0000 (0.9977)  time: 0.5131 (0.5085)  data: 0.0141 (0.0141)  lr: 0.000125  max mem: 2403
2022-04-26 16:21:33,979 alphaction.trainer INFO: eta: 5 days, 3:51:59  iter: 3100  loss_pose_action: 0.0002 (0.5105)  loss_object_interaction: 0.0000 (0.0007)  loss_person_interaction: 0.0000 (0.0007)  total_loss: 0.0007 (0.6567)  accuracy_pose_action: 1.0000 (0.7391)  accuracy_object_interaction: 1.0000 (0.9974)  accuracy_person_interaction: 1.0000 (0.9977)  time: 0.5128 (0.5085)  data: 0.0143 (0.0141)  lr: 0.000125  max mem: 2403
2022-04-26 16:21:33,981 alphaction.utils.checkpoint INFO: Saving checkpoint to data/output/resnet50_4x16f_baseline_robalo/model_0003100.pth
2022-04-26 16:21:34,246 alphaction.inference INFO: Start evaluation on lfv_robalo_val_ava_video dataset(135 videos).
2022-04-26 16:21:48,725 alphaction.inference INFO: Total inference time: 0:00:14.478441 (0.10724771111099808 s / video per device, on 1 devices)
2022-04-26 16:21:48,725 alphaction.inference INFO: performing ava evaluation.
2022-04-26 16:21:48,727 alphaction.inference INFO: Preparing results for AVA format
2022-04-26 16:21:48,744 alphaction.inference INFO: Evaluating predictions
2022-04-26 16:21:48,794 alphaction.inference INFO: ==> 0.0504611 seconds to write file /tmp/tmpd0avzi_w
2022-04-26 16:21:48,795 alphaction.inference INFO: CATEGORIES (12):
[ {'id': 1, 'name': 'cut (an object)'},
  {'id': 2, 'name': 'holding for (a person)'},
  {'id': 3, 'name': 'handover to (a person)'},
  {'id': 4, 'name': 'squeeze (an object)'},
  {'id': 5, 'name': 'sprinkle (an object)'},
  {'id': 6, 'name': 'transfer (an object)'},
  {'id': 7, 'name': 'pour (an object)'},
  {'id': 8, 'name': 'heat (an object)'},
  {'id': 9, 'name': 'stir (an object)'},
  {'id': 10, 'name': 'wrap (an object)'},
  {'id': 11, 'name': 'roll (an object)'},
  {'id': 12, 'name': 'dip (an object)'}]
2022-04-26 16:21:48,795 alphaction.inference INFO: ==> 0.000403166 seconds to read file data/lfv_robalo/annotations/lfv_robalo_val.csv
2022-04-26 16:21:48,812 alphaction.inference INFO: ==> 0.0166678 seconds to convert groundtruth
2022-04-26 16:21:48,833 alphaction.inference INFO: ==> 0.0207832 seconds to read file /tmp/tmpd0avzi_w
2022-04-26 16:21:49,171 alphaction.inference INFO: ==> 0.337678 seconds to convert detections
2022-04-26 16:21:49,171 alphaction.inference INFO: The following classes have no ground truth examples: [ 2  3 10 11 12]
2022-04-26 16:21:49,174 alphaction.inference INFO: ==> 0.0030129 seconds to run_evaluator
2022-04-26 16:21:49,175 alphaction.inference INFO: { 'PascalBoxes_PerformanceByCategory/AP@0.5IOU/cut (an object)': 0.8200469820035039,
  'PascalBoxes_PerformanceByCategory/AP@0.5IOU/dip (an object)': nan,
  'PascalBoxes_PerformanceByCategory/AP@0.5IOU/handover to (a person)': nan,
  'PascalBoxes_PerformanceByCategory/AP@0.5IOU/heat (an object)': 0.7345900555014849,
  'PascalBoxes_PerformanceByCategory/AP@0.5IOU/holding for (a person)': nan,
  'PascalBoxes_PerformanceByCategory/AP@0.5IOU/pour (an object)': 0.16883116883116883,
  'PascalBoxes_PerformanceByCategory/AP@0.5IOU/roll (an object)': nan,
  'PascalBoxes_PerformanceByCategory/AP@0.5IOU/sprinkle (an object)': 0.05024509803921569,
  'PascalBoxes_PerformanceByCategory/AP@0.5IOU/squeeze (an object)': 0.05752580752580752,
  'PascalBoxes_PerformanceByCategory/AP@0.5IOU/stir (an object)': 0.3544709649694532,
  'PascalBoxes_PerformanceByCategory/AP@0.5IOU/transfer (an object)': 0.47057854896443724,
  'PascalBoxes_PerformanceByCategory/AP@0.5IOU/wrap (an object)': nan,
  'PascalBoxes_Precision/mAP@0.5IOU': 0.37946980369072447}
2022-04-26 16:21:59,281 alphaction.trainer INFO: eta: 5 days, 3:51:30  iter: 3120  loss_pose_action: 0.0014 (0.5074)  loss_object_interaction: 0.0000 (0.0007)  loss_person_interaction: 0.0000 (0.0007)  total_loss: 0.0035 (0.6527)  accuracy_pose_action: 1.0000 (0.7406)  accuracy_object_interaction: 1.0000 (0.9974)  accuracy_person_interaction: 1.0000 (0.9978)  time: 0.5072 (0.5085)  data: 0.0137 (0.0141)  lr: 0.000125  max mem: 2403
2022-04-26 16:22:09,444 alphaction.trainer INFO: eta: 5 days, 3:51:18  iter: 3140  loss_pose_action: 0.0000 (0.5045)  loss_object_interaction: 0.0000 (0.0007)  loss_person_interaction: 0.0000 (0.0007)  total_loss: 0.0012 (0.6489)  accuracy_pose_action: 1.0000 (0.7419)  accuracy_object_interaction: 1.0000 (0.9975)  accuracy_person_interaction: 1.0000 (0.9978)  time: 0.5126 (0.5085)  data: 0.0141 (0.0141)  lr: 0.000125  max mem: 2403
2022-04-26 16:22:19,653 alphaction.trainer INFO: eta: 5 days, 3:51:19  iter: 3160  loss_pose_action: 0.0000 (0.5016)  loss_object_interaction: 0.0000 (0.0006)  loss_person_interaction: 0.0000 (0.0007)  total_loss: 0.0008 (0.6452)  accuracy_pose_action: 1.0000 (0.7433)  accuracy_object_interaction: 1.0000 (0.9975)  accuracy_person_interaction: 1.0000 (0.9978)  time: 0.5124 (0.5085)  data: 0.0141 (0.0141)  lr: 0.000125  max mem: 2403
2022-04-26 16:22:29,889 alphaction.trainer INFO: eta: 5 days, 3:51:27  iter: 3180  loss_pose_action: 0.0000 (0.4993)  loss_object_interaction: 0.0000 (0.0006)  loss_person_interaction: 0.0000 (0.0007)  total_loss: 0.0005 (0.6421)  accuracy_pose_action: 1.0000 (0.7446)  accuracy_object_interaction: 1.0000 (0.9975)  accuracy_person_interaction: 1.0000 (0.9978)  time: 0.5139 (0.5085)  data: 0.0140 (0.0141)  lr: 0.000125  max mem: 2403
2022-04-26 16:22:40,144 alphaction.trainer INFO: eta: 5 days, 3:51:39  iter: 3200  loss_pose_action: 0.0013 (0.4968)  loss_object_interaction: 0.0000 (0.0006)  loss_person_interaction: 0.0000 (0.0007)  total_loss: 0.0045 (0.6389)  accuracy_pose_action: 1.0000 (0.7456)  accuracy_object_interaction: 1.0000 (0.9975)  accuracy_person_interaction: 1.0000 (0.9978)  time: 0.5140 (0.5086)  data: 0.0141 (0.0141)  lr: 0.000125  max mem: 2403
2022-04-26 16:22:40,148 alphaction.utils.checkpoint INFO: Saving checkpoint to data/output/resnet50_4x16f_baseline_robalo/model_0003200.pth
2022-04-26 16:22:40,405 alphaction.inference INFO: Start evaluation on lfv_robalo_val_ava_video dataset(135 videos).
2022-04-26 16:22:55,143 alphaction.inference INFO: Total inference time: 0:00:14.737773 (0.109168690222281 s / video per device, on 1 devices)
2022-04-26 16:22:55,143 alphaction.inference INFO: performing ava evaluation.
2022-04-26 16:22:55,144 alphaction.inference INFO: Preparing results for AVA format
2022-04-26 16:22:55,165 alphaction.inference INFO: Evaluating predictions
2022-04-26 16:22:55,214 alphaction.inference INFO: ==> 0.049432 seconds to write file /tmp/tmpfd_3f2lq
2022-04-26 16:22:55,215 alphaction.inference INFO: CATEGORIES (12):
[ {'id': 1, 'name': 'cut (an object)'},
  {'id': 2, 'name': 'holding for (a person)'},
  {'id': 3, 'name': 'handover to (a person)'},
  {'id': 4, 'name': 'squeeze (an object)'},
  {'id': 5, 'name': 'sprinkle (an object)'},
  {'id': 6, 'name': 'transfer (an object)'},
  {'id': 7, 'name': 'pour (an object)'},
  {'id': 8, 'name': 'heat (an object)'},
  {'id': 9, 'name': 'stir (an object)'},
  {'id': 10, 'name': 'wrap (an object)'},
  {'id': 11, 'name': 'roll (an object)'},
  {'id': 12, 'name': 'dip (an object)'}]
2022-04-26 16:22:55,215 alphaction.inference INFO: ==> 0.000446796 seconds to read file data/lfv_robalo/annotations/lfv_robalo_val.csv
2022-04-26 16:22:55,232 alphaction.inference INFO: ==> 0.0164013 seconds to convert groundtruth
2022-04-26 16:22:55,251 alphaction.inference INFO: ==> 0.0192823 seconds to read file /tmp/tmpfd_3f2lq
2022-04-26 16:22:55,617 alphaction.inference INFO: ==> 0.366083 seconds to convert detections
2022-04-26 16:22:55,617 alphaction.inference INFO: The following classes have no ground truth examples: [ 2  3 10 11 12]
2022-04-26 16:22:55,620 alphaction.inference INFO: ==> 0.00284314 seconds to run_evaluator
2022-04-26 16:22:55,621 alphaction.inference INFO: { 'PascalBoxes_PerformanceByCategory/AP@0.5IOU/cut (an object)': 0.8345957014852236,
  'PascalBoxes_PerformanceByCategory/AP@0.5IOU/dip (an object)': nan,
  'PascalBoxes_PerformanceByCategory/AP@0.5IOU/handover to (a person)': nan,
  'PascalBoxes_PerformanceByCategory/AP@0.5IOU/heat (an object)': 0.7271946280801451,
  'PascalBoxes_PerformanceByCategory/AP@0.5IOU/holding for (a person)': nan,
  'PascalBoxes_PerformanceByCategory/AP@0.5IOU/pour (an object)': 0.35263571665011584,
  'PascalBoxes_PerformanceByCategory/AP@0.5IOU/roll (an object)': nan,
  'PascalBoxes_PerformanceByCategory/AP@0.5IOU/sprinkle (an object)': 0.028169014084507043,
  'PascalBoxes_PerformanceByCategory/AP@0.5IOU/squeeze (an object)': 0.063368521242537,
  'PascalBoxes_PerformanceByCategory/AP@0.5IOU/stir (an object)': 0.4024556931721303,
  'PascalBoxes_PerformanceByCategory/AP@0.5IOU/transfer (an object)': 0.4995788525928383,
  'PascalBoxes_PerformanceByCategory/AP@0.5IOU/wrap (an object)': nan,
  'PascalBoxes_Precision/mAP@0.5IOU': 0.415428303901071}
2022-04-26 16:23:05,700 alphaction.trainer INFO: eta: 5 days, 3:51:04  iter: 3220  loss_pose_action: 0.0001 (0.4938)  loss_object_interaction: 0.0000 (0.0006)  loss_person_interaction: 0.0000 (0.0007)  total_loss: 0.0011 (0.6351)  accuracy_pose_action: 1.0000 (0.7471)  accuracy_object_interaction: 1.0000 (0.9975)  accuracy_person_interaction: 1.0000 (0.9978)  time: 0.5014 (0.5085)  data: 0.0137 (0.0141)  lr: 0.000125  max mem: 2403
2022-04-26 16:23:15,863 alphaction.trainer INFO: eta: 5 days, 3:50:52  iter: 3240  loss_pose_action: 0.0002 (0.4913)  loss_object_interaction: 0.0000 (0.0006)  loss_person_interaction: 0.0000 (0.0007)  total_loss: 0.0015 (0.6318)  accuracy_pose_action: 1.0000 (0.7485)  accuracy_object_interaction: 1.0000 (0.9975)  accuracy_person_interaction: 1.0000 (0.9978)  time: 0.5117 (0.5085)  data: 0.0139 (0.0141)  lr: 0.000125  max mem: 2403
2022-04-26 16:23:26,119 alphaction.trainer INFO: eta: 5 days, 3:51:04  iter: 3260  loss_pose_action: 0.0058 (0.4888)  loss_object_interaction: 0.0000 (0.0006)  loss_person_interaction: 0.0000 (0.0007)  total_loss: 0.0091 (0.6286)  accuracy_pose_action: 1.0000 (0.7496)  accuracy_object_interaction: 1.0000 (0.9975)  accuracy_person_interaction: 1.0000 (0.9979)  time: 0.5146 (0.5085)  data: 0.0139 (0.0141)  lr: 0.000125  max mem: 2403
2022-04-26 16:23:36,355 alphaction.trainer INFO: eta: 5 days, 3:51:11  iter: 3280  loss_pose_action: 0.0002 (0.4864)  loss_object_interaction: 0.0000 (0.0006)  loss_person_interaction: 0.0000 (0.0007)  total_loss: 0.0012 (0.6254)  accuracy_pose_action: 1.0000 (0.7508)  accuracy_object_interaction: 1.0000 (0.9976)  accuracy_person_interaction: 1.0000 (0.9979)  time: 0.5142 (0.5086)  data: 0.0140 (0.0141)  lr: 0.000125  max mem: 2403
2022-04-26 16:23:46,600 alphaction.trainer INFO: eta: 5 days, 3:51:21  iter: 3300  loss_pose_action: 0.0002 (0.4836)  loss_object_interaction: 0.0000 (0.0006)  loss_person_interaction: 0.0000 (0.0006)  total_loss: 0.0026 (0.6218)  accuracy_pose_action: 1.0000 (0.7522)  accuracy_object_interaction: 1.0000 (0.9976)  accuracy_person_interaction: 1.0000 (0.9979)  time: 0.5144 (0.5086)  data: 0.0142 (0.0141)  lr: 0.000125  max mem: 2403
2022-04-26 16:23:46,603 alphaction.utils.checkpoint INFO: Saving checkpoint to data/output/resnet50_4x16f_baseline_robalo/model_0003300.pth
2022-04-26 16:23:46,860 alphaction.inference INFO: Start evaluation on lfv_robalo_val_ava_video dataset(135 videos).
2022-04-26 16:24:01,378 alphaction.inference INFO: Total inference time: 0:00:14.517991 (0.10754067103068034 s / video per device, on 1 devices)
2022-04-26 16:24:01,379 alphaction.inference INFO: performing ava evaluation.
2022-04-26 16:24:01,379 alphaction.inference INFO: Preparing results for AVA format
2022-04-26 16:24:01,395 alphaction.inference INFO: Evaluating predictions
2022-04-26 16:24:01,446 alphaction.inference INFO: ==> 0.0504098 seconds to write file /tmp/tmpcrbrsn93
2022-04-26 16:24:01,446 alphaction.inference INFO: CATEGORIES (12):
[ {'id': 1, 'name': 'cut (an object)'},
  {'id': 2, 'name': 'holding for (a person)'},
  {'id': 3, 'name': 'handover to (a person)'},
  {'id': 4, 'name': 'squeeze (an object)'},
  {'id': 5, 'name': 'sprinkle (an object)'},
  {'id': 6, 'name': 'transfer (an object)'},
  {'id': 7, 'name': 'pour (an object)'},
  {'id': 8, 'name': 'heat (an object)'},
  {'id': 9, 'name': 'stir (an object)'},
  {'id': 10, 'name': 'wrap (an object)'},
  {'id': 11, 'name': 'roll (an object)'},
  {'id': 12, 'name': 'dip (an object)'}]
2022-04-26 16:24:01,447 alphaction.inference INFO: ==> 0.000471592 seconds to read file data/lfv_robalo/annotations/lfv_robalo_val.csv
2022-04-26 16:24:01,464 alphaction.inference INFO: ==> 0.0165453 seconds to convert groundtruth
2022-04-26 16:24:01,483 alphaction.inference INFO: ==> 0.0197854 seconds to read file /tmp/tmpcrbrsn93
2022-04-26 16:24:01,814 alphaction.inference INFO: ==> 0.329965 seconds to convert detections
2022-04-26 16:24:01,814 alphaction.inference INFO: The following classes have no ground truth examples: [ 2  3 10 11 12]
2022-04-26 16:24:01,816 alphaction.inference INFO: ==> 0.0027895 seconds to run_evaluator
2022-04-26 16:24:01,817 alphaction.inference INFO: { 'PascalBoxes_PerformanceByCategory/AP@0.5IOU/cut (an object)': 0.902218904695772,
  'PascalBoxes_PerformanceByCategory/AP@0.5IOU/dip (an object)': nan,
  'PascalBoxes_PerformanceByCategory/AP@0.5IOU/handover to (a person)': nan,
  'PascalBoxes_PerformanceByCategory/AP@0.5IOU/heat (an object)': 0.7014676934511455,
  'PascalBoxes_PerformanceByCategory/AP@0.5IOU/holding for (a person)': nan,
  'PascalBoxes_PerformanceByCategory/AP@0.5IOU/pour (an object)': 0.22380952380952385,
  'PascalBoxes_PerformanceByCategory/AP@0.5IOU/roll (an object)': nan,
  'PascalBoxes_PerformanceByCategory/AP@0.5IOU/sprinkle (an object)': 0.029411764705882353,
  'PascalBoxes_PerformanceByCategory/AP@0.5IOU/squeeze (an object)': 0.07743106422729745,
  'PascalBoxes_PerformanceByCategory/AP@0.5IOU/stir (an object)': 0.4798285240956408,
  'PascalBoxes_PerformanceByCategory/AP@0.5IOU/transfer (an object)': 0.4729584219224067,
  'PascalBoxes_PerformanceByCategory/AP@0.5IOU/wrap (an object)': nan,
  'PascalBoxes_Precision/mAP@0.5IOU': 0.4124465567010956}
2022-04-26 16:24:11,918 alphaction.trainer INFO: eta: 5 days, 3:50:51  iter: 3320  loss_pose_action: 0.0006 (0.4808)  loss_object_interaction: 0.0000 (0.0006)  loss_person_interaction: 0.0000 (0.0006)  total_loss: 0.0020 (0.6182)  accuracy_pose_action: 1.0000 (0.7537)  accuracy_object_interaction: 1.0000 (0.9976)  accuracy_person_interaction: 1.0000 (0.9979)  time: 0.5090 (0.5086)  data: 0.0132 (0.0141)  lr: 0.000125  max mem: 2403
2022-04-26 16:24:22,137 alphaction.trainer INFO: eta: 5 days, 3:50:54  iter: 3340  loss_pose_action: 0.0002 (0.4783)  loss_object_interaction: 0.0000 (0.0006)  loss_person_interaction: 0.0000 (0.0006)  total_loss: 0.0036 (0.6150)  accuracy_pose_action: 1.0000 (0.7546)  accuracy_object_interaction: 1.0000 (0.9976)  accuracy_person_interaction: 1.0000 (0.9979)  time: 0.5151 (0.5086)  data: 0.0141 (0.0141)  lr: 0.000125  max mem: 2403
2022-04-26 16:24:32,363 alphaction.trainer INFO: eta: 5 days, 3:50:58  iter: 3360  loss_pose_action: 0.0003 (0.4756)  loss_object_interaction: 0.0000 (0.0006)  loss_person_interaction: 0.0000 (0.0006)  total_loss: 0.0008 (0.6115)  accuracy_pose_action: 1.0000 (0.7560)  accuracy_object_interaction: 1.0000 (0.9976)  accuracy_person_interaction: 1.0000 (0.9979)  time: 0.5120 (0.5086)  data: 0.0142 (0.0141)  lr: 0.000125  max mem: 2403
2022-04-26 16:24:42,612 alphaction.trainer INFO: eta: 5 days, 3:51:07  iter: 3380  loss_pose_action: 0.0001 (0.4733)  loss_object_interaction: 0.0000 (0.0006)  loss_person_interaction: 0.0000 (0.0006)  total_loss: 0.0005 (0.6085)  accuracy_pose_action: 1.0000 (0.7570)  accuracy_object_interaction: 1.0000 (0.9976)  accuracy_person_interaction: 1.0000 (0.9979)  time: 0.5130 (0.5086)  data: 0.0141 (0.0141)  lr: 0.000125  max mem: 2403
2022-04-26 16:24:52,836 alphaction.trainer INFO: eta: 5 days, 3:51:11  iter: 3400  loss_pose_action: 0.0004 (0.4721)  loss_object_interaction: 0.0000 (0.0006)  loss_person_interaction: 0.0000 (0.0006)  total_loss: 0.0008 (0.6069)  accuracy_pose_action: 1.0000 (0.7577)  accuracy_object_interaction: 1.0000 (0.9976)  accuracy_person_interaction: 1.0000 (0.9979)  time: 0.5152 (0.5086)  data: 0.0141 (0.0141)  lr: 0.000125  max mem: 2403
2022-04-26 16:24:52,839 alphaction.utils.checkpoint INFO: Saving checkpoint to data/output/resnet50_4x16f_baseline_robalo/model_0003400.pth
2022-04-26 16:24:53,103 alphaction.inference INFO: Start evaluation on lfv_robalo_val_ava_video dataset(135 videos).
2022-04-26 16:25:07,872 alphaction.inference INFO: Total inference time: 0:00:14.768814 (0.1093986228660301 s / video per device, on 1 devices)
2022-04-26 16:25:07,872 alphaction.inference INFO: performing ava evaluation.
2022-04-26 16:25:07,872 alphaction.inference INFO: Preparing results for AVA format
2022-04-26 16:25:07,890 alphaction.inference INFO: Evaluating predictions
2022-04-26 16:25:07,942 alphaction.inference INFO: ==> 0.0515773 seconds to write file /tmp/tmpitivqf3g
2022-04-26 16:25:07,942 alphaction.inference INFO: CATEGORIES (12):
[ {'id': 1, 'name': 'cut (an object)'},
  {'id': 2, 'name': 'holding for (a person)'},
  {'id': 3, 'name': 'handover to (a person)'},
  {'id': 4, 'name': 'squeeze (an object)'},
  {'id': 5, 'name': 'sprinkle (an object)'},
  {'id': 6, 'name': 'transfer (an object)'},
  {'id': 7, 'name': 'pour (an object)'},
  {'id': 8, 'name': 'heat (an object)'},
  {'id': 9, 'name': 'stir (an object)'},
  {'id': 10, 'name': 'wrap (an object)'},
  {'id': 11, 'name': 'roll (an object)'},
  {'id': 12, 'name': 'dip (an object)'}]
2022-04-26 16:25:07,943 alphaction.inference INFO: ==> 0.000699997 seconds to read file data/lfv_robalo/annotations/lfv_robalo_val.csv
2022-04-26 16:25:07,961 alphaction.inference INFO: ==> 0.0182841 seconds to convert groundtruth
2022-04-26 16:25:07,981 alphaction.inference INFO: ==> 0.0201304 seconds to read file /tmp/tmpitivqf3g
2022-04-26 16:25:08,320 alphaction.inference INFO: ==> 0.337924 seconds to convert detections
2022-04-26 16:25:08,320 alphaction.inference INFO: The following classes have no ground truth examples: [ 2  3 10 11 12]
2022-04-26 16:25:08,322 alphaction.inference INFO: ==> 0.00272751 seconds to run_evaluator
2022-04-26 16:25:08,323 alphaction.inference INFO: { 'PascalBoxes_PerformanceByCategory/AP@0.5IOU/cut (an object)': 0.7240462435202789,
  'PascalBoxes_PerformanceByCategory/AP@0.5IOU/dip (an object)': nan,
  'PascalBoxes_PerformanceByCategory/AP@0.5IOU/handover to (a person)': nan,
  'PascalBoxes_PerformanceByCategory/AP@0.5IOU/heat (an object)': 0.6818616930477475,
  'PascalBoxes_PerformanceByCategory/AP@0.5IOU/holding for (a person)': nan,
  'PascalBoxes_PerformanceByCategory/AP@0.5IOU/pour (an object)': 0.3097319347319347,
  'PascalBoxes_PerformanceByCategory/AP@0.5IOU/roll (an object)': nan,
  'PascalBoxes_PerformanceByCategory/AP@0.5IOU/sprinkle (an object)': 0.020833333333333332,
  'PascalBoxes_PerformanceByCategory/AP@0.5IOU/squeeze (an object)': 0.06523914875684787,
  'PascalBoxes_PerformanceByCategory/AP@0.5IOU/stir (an object)': 0.223603228496993,
  'PascalBoxes_PerformanceByCategory/AP@0.5IOU/transfer (an object)': 0.46365933720384855,
  'PascalBoxes_PerformanceByCategory/AP@0.5IOU/wrap (an object)': nan,
  'PascalBoxes_Precision/mAP@0.5IOU': 0.3555678455844263}
2022-04-26 16:25:18,408 alphaction.trainer INFO: eta: 5 days, 3:50:37  iter: 3420  loss_pose_action: 0.0006 (0.4697)  loss_object_interaction: 0.0000 (0.0006)  loss_person_interaction: 0.0000 (0.0006)  total_loss: 0.0046 (0.6039)  accuracy_pose_action: 1.0000 (0.7590)  accuracy_object_interaction: 1.0000 (0.9977)  accuracy_person_interaction: 1.0000 (0.9980)  time: 0.5029 (0.5086)  data: 0.0141 (0.0141)  lr: 0.000125  max mem: 2403
2022-04-26 16:25:28,585 alphaction.trainer INFO: eta: 5 days, 3:50:28  iter: 3440  loss_pose_action: 0.0022 (0.4676)  loss_object_interaction: 0.0000 (0.0006)  loss_person_interaction: 0.0000 (0.0006)  total_loss: 0.0155 (0.6011)  accuracy_pose_action: 1.0000 (0.7601)  accuracy_object_interaction: 1.0000 (0.9977)  accuracy_person_interaction: 1.0000 (0.9980)  time: 0.5111 (0.5086)  data: 0.0137 (0.0141)  lr: 0.000125  max mem: 2403
2022-04-26 16:25:38,810 alphaction.trainer INFO: eta: 5 days, 3:50:32  iter: 3460  loss_pose_action: 0.0008 (0.4654)  loss_object_interaction: 0.0000 (0.0006)  loss_person_interaction: 0.0000 (0.0006)  total_loss: 0.0022 (0.5983)  accuracy_pose_action: 1.0000 (0.7609)  accuracy_object_interaction: 1.0000 (0.9977)  accuracy_person_interaction: 1.0000 (0.9980)  time: 0.5120 (0.5086)  data: 0.0138 (0.0141)  lr: 0.000125  max mem: 2403
2022-04-26 16:25:49,063 alphaction.trainer INFO: eta: 5 days, 3:50:42  iter: 3480  loss_pose_action: 0.0062 (0.4630)  loss_object_interaction: 0.0000 (0.0006)  loss_person_interaction: 0.0000 (0.0006)  total_loss: 0.0156 (0.5952)  accuracy_pose_action: 1.0000 (0.7620)  accuracy_object_interaction: 1.0000 (0.9977)  accuracy_person_interaction: 1.0000 (0.9980)  time: 0.5127 (0.5087)  data: 0.0140 (0.0141)  lr: 0.000125  max mem: 2403
2022-04-26 16:25:59,308 alphaction.trainer INFO: eta: 5 days, 3:50:49  iter: 3500  loss_pose_action: 0.0025 (0.4607)  loss_object_interaction: 0.0000 (0.0006)  loss_person_interaction: 0.0000 (0.0006)  total_loss: 0.0064 (0.5922)  accuracy_pose_action: 1.0000 (0.7630)  accuracy_object_interaction: 1.0000 (0.9977)  accuracy_person_interaction: 1.0000 (0.9980)  time: 0.5122 (0.5087)  data: 0.0141 (0.0141)  lr: 0.000125  max mem: 2403
2022-04-26 16:25:59,312 alphaction.utils.checkpoint INFO: Saving checkpoint to data/output/resnet50_4x16f_baseline_robalo/model_0003500.pth
2022-04-26 16:25:59,561 alphaction.inference INFO: Start evaluation on lfv_robalo_val_ava_video dataset(135 videos).
2022-04-26 16:26:14,249 alphaction.inference INFO: Total inference time: 0:00:14.687689 (0.10879769501862703 s / video per device, on 1 devices)
2022-04-26 16:26:14,249 alphaction.inference INFO: performing ava evaluation.
2022-04-26 16:26:14,250 alphaction.inference INFO: Preparing results for AVA format
2022-04-26 16:26:14,266 alphaction.inference INFO: Evaluating predictions
2022-04-26 16:26:14,316 alphaction.inference INFO: ==> 0.0501823 seconds to write file /tmp/tmpa8i9qgu9
2022-04-26 16:26:14,317 alphaction.inference INFO: CATEGORIES (12):
[ {'id': 1, 'name': 'cut (an object)'},
  {'id': 2, 'name': 'holding for (a person)'},
  {'id': 3, 'name': 'handover to (a person)'},
  {'id': 4, 'name': 'squeeze (an object)'},
  {'id': 5, 'name': 'sprinkle (an object)'},
  {'id': 6, 'name': 'transfer (an object)'},
  {'id': 7, 'name': 'pour (an object)'},
  {'id': 8, 'name': 'heat (an object)'},
  {'id': 9, 'name': 'stir (an object)'},
  {'id': 10, 'name': 'wrap (an object)'},
  {'id': 11, 'name': 'roll (an object)'},
  {'id': 12, 'name': 'dip (an object)'}]
2022-04-26 16:26:14,317 alphaction.inference INFO: ==> 0.000500917 seconds to read file data/lfv_robalo/annotations/lfv_robalo_val.csv
2022-04-26 16:26:14,334 alphaction.inference INFO: ==> 0.016535 seconds to convert groundtruth
2022-04-26 16:26:14,355 alphaction.inference INFO: ==> 0.0206592 seconds to read file /tmp/tmpa8i9qgu9
2022-04-26 16:26:14,687 alphaction.inference INFO: ==> 0.331762 seconds to convert detections
2022-04-26 16:26:14,687 alphaction.inference INFO: The following classes have no ground truth examples: [ 2  3 10 11 12]
2022-04-26 16:26:14,690 alphaction.inference INFO: ==> 0.00273442 seconds to run_evaluator
2022-04-26 16:26:14,690 alphaction.inference INFO: { 'PascalBoxes_PerformanceByCategory/AP@0.5IOU/cut (an object)': 0.6867520140997089,
  'PascalBoxes_PerformanceByCategory/AP@0.5IOU/dip (an object)': nan,
  'PascalBoxes_PerformanceByCategory/AP@0.5IOU/handover to (a person)': nan,
  'PascalBoxes_PerformanceByCategory/AP@0.5IOU/heat (an object)': 0.6734801228261903,
  'PascalBoxes_PerformanceByCategory/AP@0.5IOU/holding for (a person)': nan,
  'PascalBoxes_PerformanceByCategory/AP@0.5IOU/pour (an object)': 0.07174898261191269,
  'PascalBoxes_PerformanceByCategory/AP@0.5IOU/roll (an object)': nan,
  'PascalBoxes_PerformanceByCategory/AP@0.5IOU/sprinkle (an object)': 0.029411764705882353,
  'PascalBoxes_PerformanceByCategory/AP@0.5IOU/squeeze (an object)': 0.07500386734731979,
  'PascalBoxes_PerformanceByCategory/AP@0.5IOU/stir (an object)': 0.3385644246525102,
  'PascalBoxes_PerformanceByCategory/AP@0.5IOU/transfer (an object)': 0.42596275138882406,
  'PascalBoxes_PerformanceByCategory/AP@0.5IOU/wrap (an object)': nan,
  'PascalBoxes_Precision/mAP@0.5IOU': 0.3287034182331926}
2022-04-26 16:26:24,744 alphaction.trainer INFO: eta: 5 days, 3:50:09  iter: 3520  loss_pose_action: 0.0036 (0.4588)  loss_object_interaction: 0.0000 (0.0006)  loss_person_interaction: 0.0000 (0.0006)  total_loss: 0.0047 (0.5898)  accuracy_pose_action: 1.0000 (0.7633)  accuracy_object_interaction: 1.0000 (0.9977)  accuracy_person_interaction: 1.0000 (0.9980)  time: 0.5018 (0.5086)  data: 0.0134 (0.0141)  lr: 0.000125  max mem: 2403
2022-04-26 16:26:34,933 alphaction.trainer INFO: eta: 5 days, 3:50:03  iter: 3540  loss_pose_action: 0.0006 (0.4577)  loss_object_interaction: 0.0000 (0.0006)  loss_person_interaction: 0.0000 (0.0006)  total_loss: 0.0043 (0.5881)  accuracy_pose_action: 1.0000 (0.7641)  accuracy_object_interaction: 1.0000 (0.9977)  accuracy_person_interaction: 1.0000 (0.9980)  time: 0.5115 (0.5086)  data: 0.0141 (0.0141)  lr: 0.000125  max mem: 2403
2022-04-26 16:26:45,184 alphaction.trainer INFO: eta: 5 days, 3:50:12  iter: 3560  loss_pose_action: 0.0020 (0.4556)  loss_object_interaction: 0.0001 (0.0006)  loss_person_interaction: 0.0001 (0.0006)  total_loss: 0.0154 (0.5856)  accuracy_pose_action: 1.0000 (0.7652)  accuracy_object_interaction: 1.0000 (0.9978)  accuracy_person_interaction: 1.0000 (0.9980)  time: 0.5131 (0.5087)  data: 0.0144 (0.0141)  lr: 0.000125  max mem: 2403
2022-04-26 16:26:55,366 alphaction.trainer INFO: eta: 5 days, 3:50:04  iter: 3580  loss_pose_action: 0.0027 (0.4555)  loss_object_interaction: 0.0000 (0.0006)  loss_person_interaction: 0.0000 (0.0006)  total_loss: 0.0089 (0.5852)  accuracy_pose_action: 1.0000 (0.7656)  accuracy_object_interaction: 1.0000 (0.9978)  accuracy_person_interaction: 1.0000 (0.9980)  time: 0.5123 (0.5087)  data: 0.0145 (0.0141)  lr: 0.000125  max mem: 2403
2022-04-26 16:27:05,559 alphaction.trainer INFO: eta: 5 days, 3:49:58  iter: 3600  loss_pose_action: 0.0923 (0.4548)  loss_object_interaction: 0.0000 (0.0006)  loss_person_interaction: 0.0001 (0.0006)  total_loss: 0.1146 (0.5842)  accuracy_pose_action: 1.0000 (0.7659)  accuracy_object_interaction: 1.0000 (0.9978)  accuracy_person_interaction: 1.0000 (0.9981)  time: 0.5122 (0.5087)  data: 0.0141 (0.0141)  lr: 0.000125  max mem: 2403
2022-04-26 16:27:05,562 alphaction.utils.checkpoint INFO: Saving checkpoint to data/output/resnet50_4x16f_baseline_robalo/model_0003600.pth
2022-04-26 16:27:05,820 alphaction.inference INFO: Start evaluation on lfv_robalo_val_ava_video dataset(135 videos).
2022-04-26 16:27:20,622 alphaction.inference INFO: Total inference time: 0:00:14.801630 (0.10964170385290076 s / video per device, on 1 devices)
2022-04-26 16:27:20,622 alphaction.inference INFO: performing ava evaluation.
2022-04-26 16:27:20,622 alphaction.inference INFO: Preparing results for AVA format
2022-04-26 16:27:20,638 alphaction.inference INFO: Evaluating predictions
2022-04-26 16:27:20,688 alphaction.inference INFO: ==> 0.0499117 seconds to write file /tmp/tmpiq1mcr3d
2022-04-26 16:27:20,689 alphaction.inference INFO: CATEGORIES (12):
[ {'id': 1, 'name': 'cut (an object)'},
  {'id': 2, 'name': 'holding for (a person)'},
  {'id': 3, 'name': 'handover to (a person)'},
  {'id': 4, 'name': 'squeeze (an object)'},
  {'id': 5, 'name': 'sprinkle (an object)'},
  {'id': 6, 'name': 'transfer (an object)'},
  {'id': 7, 'name': 'pour (an object)'},
  {'id': 8, 'name': 'heat (an object)'},
  {'id': 9, 'name': 'stir (an object)'},
  {'id': 10, 'name': 'wrap (an object)'},
  {'id': 11, 'name': 'roll (an object)'},
  {'id': 12, 'name': 'dip (an object)'}]
2022-04-26 16:27:20,689 alphaction.inference INFO: ==> 0.00047183 seconds to read file data/lfv_robalo/annotations/lfv_robalo_val.csv
2022-04-26 16:27:20,706 alphaction.inference INFO: ==> 0.0163708 seconds to convert groundtruth
2022-04-26 16:27:20,747 alphaction.inference INFO: ==> 0.0416536 seconds to read file /tmp/tmpiq1mcr3d
2022-04-26 16:27:21,087 alphaction.inference INFO: ==> 0.339287 seconds to convert detections
2022-04-26 16:27:21,087 alphaction.inference INFO: The following classes have no ground truth examples: [ 2  3 10 11 12]
2022-04-26 16:27:21,090 alphaction.inference INFO: ==> 0.0026443 seconds to run_evaluator
2022-04-26 16:27:21,091 alphaction.inference INFO: { 'PascalBoxes_PerformanceByCategory/AP@0.5IOU/cut (an object)': 0.534695419345731,
  'PascalBoxes_PerformanceByCategory/AP@0.5IOU/dip (an object)': nan,
  'PascalBoxes_PerformanceByCategory/AP@0.5IOU/handover to (a person)': nan,
  'PascalBoxes_PerformanceByCategory/AP@0.5IOU/heat (an object)': 0.7160925648661223,
  'PascalBoxes_PerformanceByCategory/AP@0.5IOU/holding for (a person)': nan,
  'PascalBoxes_PerformanceByCategory/AP@0.5IOU/pour (an object)': 0.04468864468864469,
  'PascalBoxes_PerformanceByCategory/AP@0.5IOU/roll (an object)': nan,
  'PascalBoxes_PerformanceByCategory/AP@0.5IOU/sprinkle (an object)': 0.02631578947368421,
  'PascalBoxes_PerformanceByCategory/AP@0.5IOU/squeeze (an object)': 0.0900294644047143,
  'PascalBoxes_PerformanceByCategory/AP@0.5IOU/stir (an object)': 0.28999639883453193,
  'PascalBoxes_PerformanceByCategory/AP@0.5IOU/transfer (an object)': 0.38941293319490666,
  'PascalBoxes_PerformanceByCategory/AP@0.5IOU/wrap (an object)': nan,
  'PascalBoxes_Precision/mAP@0.5IOU': 0.29874731640119073}
2022-04-26 16:27:31,185 alphaction.trainer INFO: eta: 5 days, 3:49:29  iter: 3620  loss_pose_action: 0.0020 (0.4535)  loss_object_interaction: 0.0001 (0.0006)  loss_person_interaction: 0.0001 (0.0006)  total_loss: 0.0087 (0.5824)  accuracy_pose_action: 1.0000 (0.7664)  accuracy_object_interaction: 1.0000 (0.9978)  accuracy_person_interaction: 1.0000 (0.9981)  time: 0.5015 (0.5086)  data: 0.0136 (0.0141)  lr: 0.000125  max mem: 2403
2022-04-26 16:27:41,303 alphaction.trainer INFO: eta: 5 days, 3:49:05  iter: 3640  loss_pose_action: 0.0110 (0.4521)  loss_object_interaction: 0.0001 (0.0006)  loss_person_interaction: 0.0001 (0.0006)  total_loss: 0.0207 (0.5806)  accuracy_pose_action: 1.0000 (0.7671)  accuracy_object_interaction: 1.0000 (0.9978)  accuracy_person_interaction: 1.0000 (0.9981)  time: 0.5074 (0.5086)  data: 0.0138 (0.0141)  lr: 0.000125  max mem: 2403
2022-04-26 16:27:51,525 alphaction.trainer INFO: eta: 5 days, 3:49:07  iter: 3660  loss_pose_action: 0.0008 (0.4499)  loss_object_interaction: 0.0000 (0.0006)  loss_person_interaction: 0.0000 (0.0006)  total_loss: 0.0045 (0.5778)  accuracy_pose_action: 1.0000 (0.7680)  accuracy_object_interaction: 1.0000 (0.9978)  accuracy_person_interaction: 1.0000 (0.9981)  time: 0.5143 (0.5086)  data: 0.0139 (0.0141)  lr: 0.000125  max mem: 2403
2022-04-26 16:28:01,765 alphaction.trainer INFO: eta: 5 days, 3:49:13  iter: 3680  loss_pose_action: 0.0094 (0.4493)  loss_object_interaction: 0.0001 (0.0006)  loss_person_interaction: 0.0001 (0.0006)  total_loss: 0.0184 (0.5770)  accuracy_pose_action: 1.0000 (0.7688)  accuracy_object_interaction: 1.0000 (0.9978)  accuracy_person_interaction: 1.0000 (0.9981)  time: 0.5145 (0.5087)  data: 0.0144 (0.0141)  lr: 0.000125  max mem: 2403
2022-04-26 16:28:12,010 alphaction.trainer INFO: eta: 5 days, 3:49:20  iter: 3700  loss_pose_action: 0.0019 (0.4482)  loss_object_interaction: 0.0001 (0.0006)  loss_person_interaction: 0.0001 (0.0006)  total_loss: 0.0161 (0.5754)  accuracy_pose_action: 1.0000 (0.7692)  accuracy_object_interaction: 1.0000 (0.9978)  accuracy_person_interaction: 1.0000 (0.9981)  time: 0.5134 (0.5087)  data: 0.0142 (0.0141)  lr: 0.000125  max mem: 2403
2022-04-26 16:28:12,013 alphaction.utils.checkpoint INFO: Saving checkpoint to data/output/resnet50_4x16f_baseline_robalo/model_0003700.pth
2022-04-26 16:28:12,281 alphaction.inference INFO: Start evaluation on lfv_robalo_val_ava_video dataset(135 videos).
2022-04-26 16:28:27,194 alphaction.inference INFO: Total inference time: 0:00:14.913377 (0.11046945607220685 s / video per device, on 1 devices)
2022-04-26 16:28:27,195 alphaction.inference INFO: performing ava evaluation.
2022-04-26 16:28:27,195 alphaction.inference INFO: Preparing results for AVA format
2022-04-26 16:28:27,212 alphaction.inference INFO: Evaluating predictions
2022-04-26 16:28:27,263 alphaction.inference INFO: ==> 0.0515423 seconds to write file /tmp/tmpx5k6s3he
2022-04-26 16:28:27,264 alphaction.inference INFO: CATEGORIES (12):
[ {'id': 1, 'name': 'cut (an object)'},
  {'id': 2, 'name': 'holding for (a person)'},
  {'id': 3, 'name': 'handover to (a person)'},
  {'id': 4, 'name': 'squeeze (an object)'},
  {'id': 5, 'name': 'sprinkle (an object)'},
  {'id': 6, 'name': 'transfer (an object)'},
  {'id': 7, 'name': 'pour (an object)'},
  {'id': 8, 'name': 'heat (an object)'},
  {'id': 9, 'name': 'stir (an object)'},
  {'id': 10, 'name': 'wrap (an object)'},
  {'id': 11, 'name': 'roll (an object)'},
  {'id': 12, 'name': 'dip (an object)'}]
2022-04-26 16:28:27,264 alphaction.inference INFO: ==> 0.000435114 seconds to read file data/lfv_robalo/annotations/lfv_robalo_val.csv
2022-04-26 16:28:27,281 alphaction.inference INFO: ==> 0.0164077 seconds to convert groundtruth
2022-04-26 16:28:27,300 alphaction.inference INFO: ==> 0.019166 seconds to read file /tmp/tmpx5k6s3he
2022-04-26 16:28:27,643 alphaction.inference INFO: ==> 0.342586 seconds to convert detections
2022-04-26 16:28:27,643 alphaction.inference INFO: The following classes have no ground truth examples: [ 2  3 10 11 12]
2022-04-26 16:28:27,646 alphaction.inference INFO: ==> 0.00277519 seconds to run_evaluator
2022-04-26 16:28:27,646 alphaction.inference INFO: { 'PascalBoxes_PerformanceByCategory/AP@0.5IOU/cut (an object)': 0.6044519308105617,
  'PascalBoxes_PerformanceByCategory/AP@0.5IOU/dip (an object)': nan,
  'PascalBoxes_PerformanceByCategory/AP@0.5IOU/handover to (a person)': nan,
  'PascalBoxes_PerformanceByCategory/AP@0.5IOU/heat (an object)': 0.6567127434233029,
  'PascalBoxes_PerformanceByCategory/AP@0.5IOU/holding for (a person)': nan,
  'PascalBoxes_PerformanceByCategory/AP@0.5IOU/pour (an object)': 0.22634606534744595,
  'PascalBoxes_PerformanceByCategory/AP@0.5IOU/roll (an object)': nan,
  'PascalBoxes_PerformanceByCategory/AP@0.5IOU/sprinkle (an object)': 0.034482758620689655,
  'PascalBoxes_PerformanceByCategory/AP@0.5IOU/squeeze (an object)': 0.09294293746120988,
  'PascalBoxes_PerformanceByCategory/AP@0.5IOU/stir (an object)': 0.28208018070488167,
  'PascalBoxes_PerformanceByCategory/AP@0.5IOU/transfer (an object)': 0.4197412998102879,
  'PascalBoxes_PerformanceByCategory/AP@0.5IOU/wrap (an object)': nan,
  'PascalBoxes_Precision/mAP@0.5IOU': 0.3309654165969114}
2022-04-26 16:28:37,706 alphaction.trainer INFO: eta: 5 days, 3:48:42  iter: 3720  loss_pose_action: 0.0026 (0.4460)  loss_object_interaction: 0.0002 (0.0006)  loss_person_interaction: 0.0002 (0.0006)  total_loss: 0.0294 (0.5727)  accuracy_pose_action: 1.0000 (0.7704)  accuracy_object_interaction: 1.0000 (0.9978)  accuracy_person_interaction: 1.0000 (0.9981)  time: 0.4997 (0.5087)  data: 0.0139 (0.0141)  lr: 0.000125  max mem: 2403
2022-04-26 16:28:47,862 alphaction.trainer INFO: eta: 5 days, 3:48:28  iter: 3740  loss_pose_action: 0.0003 (0.4437)  loss_object_interaction: 0.0000 (0.0006)  loss_person_interaction: 0.0000 (0.0006)  total_loss: 0.0033 (0.5698)  accuracy_pose_action: 1.0000 (0.7713)  accuracy_object_interaction: 1.0000 (0.9979)  accuracy_person_interaction: 1.0000 (0.9981)  time: 0.5090 (0.5086)  data: 0.0142 (0.0141)  lr: 0.000125  max mem: 2403
2022-04-26 16:28:58,091 alphaction.trainer INFO: eta: 5 days, 3:48:31  iter: 3760  loss_pose_action: 0.0001 (0.4415)  loss_object_interaction: 0.0000 (0.0006)  loss_person_interaction: 0.0000 (0.0006)  total_loss: 0.0017 (0.5669)  accuracy_pose_action: 1.0000 (0.7725)  accuracy_object_interaction: 1.0000 (0.9979)  accuracy_person_interaction: 1.0000 (0.9981)  time: 0.5145 (0.5087)  data: 0.0136 (0.0141)  lr: 0.000125  max mem: 2403
2022-04-26 16:29:08,330 alphaction.trainer INFO: eta: 5 days, 3:48:36  iter: 3780  loss_pose_action: 0.0001 (0.4392)  loss_object_interaction: 0.0000 (0.0006)  loss_person_interaction: 0.0000 (0.0006)  total_loss: 0.0012 (0.5641)  accuracy_pose_action: 1.0000 (0.7734)  accuracy_object_interaction: 1.0000 (0.9979)  accuracy_person_interaction: 1.0000 (0.9981)  time: 0.5138 (0.5087)  data: 0.0141 (0.0141)  lr: 0.000125  max mem: 2403
2022-04-26 16:29:18,575 alphaction.trainer INFO: eta: 5 days, 3:48:42  iter: 3800  loss_pose_action: 0.0000 (0.4369)  loss_object_interaction: 0.0000 (0.0006)  loss_person_interaction: 0.0000 (0.0006)  total_loss: 0.0003 (0.5611)  accuracy_pose_action: 1.0000 (0.7746)  accuracy_object_interaction: 1.0000 (0.9979)  accuracy_person_interaction: 1.0000 (0.9982)  time: 0.5135 (0.5087)  data: 0.0143 (0.0141)  lr: 0.000125  max mem: 2403
2022-04-26 16:29:18,579 alphaction.utils.checkpoint INFO: Saving checkpoint to data/output/resnet50_4x16f_baseline_robalo/model_0003800.pth
2022-04-26 16:29:18,837 alphaction.inference INFO: Start evaluation on lfv_robalo_val_ava_video dataset(135 videos).
2022-04-26 16:29:33,608 alphaction.inference INFO: Total inference time: 0:00:14.770831 (0.10941356552971734 s / video per device, on 1 devices)
2022-04-26 16:29:33,608 alphaction.inference INFO: performing ava evaluation.
2022-04-26 16:29:33,609 alphaction.inference INFO: Preparing results for AVA format
2022-04-26 16:29:33,625 alphaction.inference INFO: Evaluating predictions
2022-04-26 16:29:33,680 alphaction.inference INFO: ==> 0.0545824 seconds to write file /tmp/tmp_fok24_g
2022-04-26 16:29:33,681 alphaction.inference INFO: CATEGORIES (12):
[ {'id': 1, 'name': 'cut (an object)'},
  {'id': 2, 'name': 'holding for (a person)'},
  {'id': 3, 'name': 'handover to (a person)'},
  {'id': 4, 'name': 'squeeze (an object)'},
  {'id': 5, 'name': 'sprinkle (an object)'},
  {'id': 6, 'name': 'transfer (an object)'},
  {'id': 7, 'name': 'pour (an object)'},
  {'id': 8, 'name': 'heat (an object)'},
  {'id': 9, 'name': 'stir (an object)'},
  {'id': 10, 'name': 'wrap (an object)'},
  {'id': 11, 'name': 'roll (an object)'},
  {'id': 12, 'name': 'dip (an object)'}]
2022-04-26 16:29:33,681 alphaction.inference INFO: ==> 0.000695229 seconds to read file data/lfv_robalo/annotations/lfv_robalo_val.csv
2022-04-26 16:29:33,699 alphaction.inference INFO: ==> 0.0172765 seconds to convert groundtruth
2022-04-26 16:29:33,722 alphaction.inference INFO: ==> 0.0227447 seconds to read file /tmp/tmp_fok24_g
2022-04-26 16:29:34,066 alphaction.inference INFO: ==> 0.344435 seconds to convert detections
2022-04-26 16:29:34,066 alphaction.inference INFO: The following classes have no ground truth examples: [ 2  3 10 11 12]
2022-04-26 16:29:34,069 alphaction.inference INFO: ==> 0.00278878 seconds to run_evaluator
2022-04-26 16:29:34,070 alphaction.inference INFO: { 'PascalBoxes_PerformanceByCategory/AP@0.5IOU/cut (an object)': 0.8432734788629652,
  'PascalBoxes_PerformanceByCategory/AP@0.5IOU/dip (an object)': nan,
  'PascalBoxes_PerformanceByCategory/AP@0.5IOU/handover to (a person)': nan,
  'PascalBoxes_PerformanceByCategory/AP@0.5IOU/heat (an object)': 0.7087743459678395,
  'PascalBoxes_PerformanceByCategory/AP@0.5IOU/holding for (a person)': nan,
  'PascalBoxes_PerformanceByCategory/AP@0.5IOU/pour (an object)': 0.15315256875973016,
  'PascalBoxes_PerformanceByCategory/AP@0.5IOU/roll (an object)': nan,
  'PascalBoxes_PerformanceByCategory/AP@0.5IOU/sprinkle (an object)': 0.06666666666666667,
  'PascalBoxes_PerformanceByCategory/AP@0.5IOU/squeeze (an object)': 0.07553736118953511,
  'PascalBoxes_PerformanceByCategory/AP@0.5IOU/stir (an object)': 0.23873145170999638,
  'PascalBoxes_PerformanceByCategory/AP@0.5IOU/transfer (an object)': 0.5387847958380874,
  'PascalBoxes_PerformanceByCategory/AP@0.5IOU/wrap (an object)': nan,
  'PascalBoxes_Precision/mAP@0.5IOU': 0.37498866699926003}
2022-04-26 16:29:44,171 alphaction.trainer INFO: eta: 5 days, 3:48:15  iter: 3820  loss_pose_action: 0.0004 (0.4352)  loss_object_interaction: 0.0000 (0.0005)  loss_person_interaction: 0.0000 (0.0006)  total_loss: 0.0024 (0.5588)  accuracy_pose_action: 1.0000 (0.7754)  accuracy_object_interaction: 1.0000 (0.9979)  accuracy_person_interaction: 1.0000 (0.9982)  time: 0.5033 (0.5087)  data: 0.0142 (0.0141)  lr: 0.000125  max mem: 2403
2022-04-26 16:29:54,313 alphaction.trainer INFO: eta: 5 days, 3:47:57  iter: 3840  loss_pose_action: 0.0000 (0.4329)  loss_object_interaction: 0.0000 (0.0005)  loss_person_interaction: 0.0000 (0.0006)  total_loss: 0.0009 (0.5559)  accuracy_pose_action: 1.0000 (0.7766)  accuracy_object_interaction: 1.0000 (0.9979)  accuracy_person_interaction: 1.0000 (0.9982)  time: 0.5084 (0.5087)  data: 0.0135 (0.0141)  lr: 0.000125  max mem: 2403
2022-04-26 16:30:04,552 alphaction.trainer INFO: eta: 5 days, 3:48:02  iter: 3860  loss_pose_action: 0.0006 (0.4317)  loss_object_interaction: 0.0000 (0.0005)  loss_person_interaction: 0.0000 (0.0006)  total_loss: 0.0027 (0.5543)  accuracy_pose_action: 1.0000 (0.7774)  accuracy_object_interaction: 1.0000 (0.9979)  accuracy_person_interaction: 1.0000 (0.9982)  time: 0.5128 (0.5087)  data: 0.0137 (0.0141)  lr: 0.000125  max mem: 2403
2022-04-26 16:30:14,793 alphaction.trainer INFO: eta: 5 days, 3:48:07  iter: 3880  loss_pose_action: 0.0000 (0.4298)  loss_object_interaction: 0.0000 (0.0005)  loss_person_interaction: 0.0000 (0.0006)  total_loss: 0.0009 (0.5519)  accuracy_pose_action: 1.0000 (0.7782)  accuracy_object_interaction: 1.0000 (0.9979)  accuracy_person_interaction: 1.0000 (0.9982)  time: 0.5123 (0.5087)  data: 0.0143 (0.0141)  lr: 0.000125  max mem: 2403
2022-04-26 16:30:25,011 alphaction.trainer INFO: eta: 5 days, 3:48:07  iter: 3900  loss_pose_action: 0.0002 (0.4281)  loss_object_interaction: 0.0000 (0.0005)  loss_person_interaction: 0.0000 (0.0006)  total_loss: 0.0019 (0.5496)  accuracy_pose_action: 1.0000 (0.7791)  accuracy_object_interaction: 1.0000 (0.9979)  accuracy_person_interaction: 1.0000 (0.9982)  time: 0.5113 (0.5087)  data: 0.0140 (0.0141)  lr: 0.000125  max mem: 2403
2022-04-26 16:30:25,014 alphaction.utils.checkpoint INFO: Saving checkpoint to data/output/resnet50_4x16f_baseline_robalo/model_0003900.pth
2022-04-26 16:30:25,284 alphaction.inference INFO: Start evaluation on lfv_robalo_val_ava_video dataset(135 videos).
2022-04-26 16:30:40,052 alphaction.inference INFO: Total inference time: 0:00:14.767516 (0.10938901018213343 s / video per device, on 1 devices)
2022-04-26 16:30:40,052 alphaction.inference INFO: performing ava evaluation.
2022-04-26 16:30:40,052 alphaction.inference INFO: Preparing results for AVA format
2022-04-26 16:30:40,068 alphaction.inference INFO: Evaluating predictions
2022-04-26 16:30:40,117 alphaction.inference INFO: ==> 0.0485253 seconds to write file /tmp/tmps_2nvo4r
2022-04-26 16:30:40,117 alphaction.inference INFO: CATEGORIES (12):
[ {'id': 1, 'name': 'cut (an object)'},
  {'id': 2, 'name': 'holding for (a person)'},
  {'id': 3, 'name': 'handover to (a person)'},
  {'id': 4, 'name': 'squeeze (an object)'},
  {'id': 5, 'name': 'sprinkle (an object)'},
  {'id': 6, 'name': 'transfer (an object)'},
  {'id': 7, 'name': 'pour (an object)'},
  {'id': 8, 'name': 'heat (an object)'},
  {'id': 9, 'name': 'stir (an object)'},
  {'id': 10, 'name': 'wrap (an object)'},
  {'id': 11, 'name': 'roll (an object)'},
  {'id': 12, 'name': 'dip (an object)'}]
2022-04-26 16:30:40,118 alphaction.inference INFO: ==> 0.000420094 seconds to read file data/lfv_robalo/annotations/lfv_robalo_val.csv
2022-04-26 16:30:40,136 alphaction.inference INFO: ==> 0.0179319 seconds to convert groundtruth
2022-04-26 16:30:40,155 alphaction.inference INFO: ==> 0.0188525 seconds to read file /tmp/tmps_2nvo4r
2022-04-26 16:30:40,486 alphaction.inference INFO: ==> 0.331121 seconds to convert detections
2022-04-26 16:30:40,486 alphaction.inference INFO: The following classes have no ground truth examples: [ 2  3 10 11 12]
2022-04-26 16:30:40,490 alphaction.inference INFO: ==> 0.00409818 seconds to run_evaluator
2022-04-26 16:30:40,491 alphaction.inference INFO: { 'PascalBoxes_PerformanceByCategory/AP@0.5IOU/cut (an object)': 0.7202741902978157,
  'PascalBoxes_PerformanceByCategory/AP@0.5IOU/dip (an object)': nan,
  'PascalBoxes_PerformanceByCategory/AP@0.5IOU/handover to (a person)': nan,
  'PascalBoxes_PerformanceByCategory/AP@0.5IOU/heat (an object)': 0.6957388788787419,
  'PascalBoxes_PerformanceByCategory/AP@0.5IOU/holding for (a person)': nan,
  'PascalBoxes_PerformanceByCategory/AP@0.5IOU/pour (an object)': 0.09108159392789374,
  'PascalBoxes_PerformanceByCategory/AP@0.5IOU/roll (an object)': nan,
  'PascalBoxes_PerformanceByCategory/AP@0.5IOU/sprinkle (an object)': 0.0392156862745098,
  'PascalBoxes_PerformanceByCategory/AP@0.5IOU/squeeze (an object)': 0.08074605561036262,
  'PascalBoxes_PerformanceByCategory/AP@0.5IOU/stir (an object)': 0.2079317093348718,
  'PascalBoxes_PerformanceByCategory/AP@0.5IOU/transfer (an object)': 0.457422041264491,
  'PascalBoxes_PerformanceByCategory/AP@0.5IOU/wrap (an object)': nan,
  'PascalBoxes_Precision/mAP@0.5IOU': 0.3274871650840981}
2022-04-26 16:30:50,525 alphaction.trainer INFO: eta: 5 days, 3:47:25  iter: 3920  loss_pose_action: 0.0026 (0.4261)  loss_object_interaction: 0.0000 (0.0005)  loss_person_interaction: 0.0000 (0.0006)  total_loss: 0.0084 (0.5471)  accuracy_pose_action: 1.0000 (0.7801)  accuracy_object_interaction: 1.0000 (0.9980)  accuracy_person_interaction: 1.0000 (0.9982)  time: 0.4964 (0.5087)  data: 0.0141 (0.0141)  lr: 0.000125  max mem: 2403
2022-04-26 16:31:00,745 alphaction.trainer INFO: eta: 5 days, 3:47:25  iter: 3940  loss_pose_action: 0.0004 (0.4249)  loss_object_interaction: 0.0000 (0.0005)  loss_person_interaction: 0.0000 (0.0006)  total_loss: 0.0046 (0.5454)  accuracy_pose_action: 1.0000 (0.7809)  accuracy_object_interaction: 1.0000 (0.9980)  accuracy_person_interaction: 1.0000 (0.9982)  time: 0.5126 (0.5087)  data: 0.0141 (0.0141)  lr: 0.000125  max mem: 2403
2022-04-26 16:31:10,914 alphaction.trainer INFO: eta: 5 days, 3:47:14  iter: 3960  loss_pose_action: 0.0001 (0.4233)  loss_object_interaction: 0.0000 (0.0005)  loss_person_interaction: 0.0000 (0.0006)  total_loss: 0.0027 (0.5433)  accuracy_pose_action: 1.0000 (0.7814)  accuracy_object_interaction: 1.0000 (0.9980)  accuracy_person_interaction: 1.0000 (0.9982)  time: 0.5036 (0.5087)  data: 0.0142 (0.0141)  lr: 0.000125  max mem: 2403
2022-04-26 16:31:21,145 alphaction.trainer INFO: eta: 5 days, 3:47:16  iter: 3980  loss_pose_action: 0.0151 (0.4217)  loss_object_interaction: 0.0000 (0.0005)  loss_person_interaction: 0.0000 (0.0006)  total_loss: 0.0194 (0.5413)  accuracy_pose_action: 1.0000 (0.7821)  accuracy_object_interaction: 1.0000 (0.9980)  accuracy_person_interaction: 1.0000 (0.9982)  time: 0.5125 (0.5087)  data: 0.0141 (0.0141)  lr: 0.000125  max mem: 2403
2022-04-26 16:31:31,381 alphaction.trainer INFO: eta: 5 days, 3:47:19  iter: 4000  loss_pose_action: 0.0009 (0.4202)  loss_object_interaction: 0.0000 (0.0005)  loss_person_interaction: 0.0000 (0.0005)  total_loss: 0.0085 (0.5393)  accuracy_pose_action: 1.0000 (0.7828)  accuracy_object_interaction: 1.0000 (0.9980)  accuracy_person_interaction: 1.0000 (0.9982)  time: 0.5119 (0.5087)  data: 0.0138 (0.0141)  lr: 0.000125  max mem: 2403
2022-04-26 16:31:31,384 alphaction.utils.checkpoint INFO: Saving checkpoint to data/output/resnet50_4x16f_baseline_robalo/model_0004000.pth
2022-04-26 16:31:31,636 alphaction.inference INFO: Start evaluation on lfv_robalo_val_ava_video dataset(135 videos).
2022-04-26 16:31:46,281 alphaction.inference INFO: Total inference time: 0:00:14.645019 (0.10848161909315321 s / video per device, on 1 devices)
2022-04-26 16:31:46,281 alphaction.inference INFO: performing ava evaluation.
2022-04-26 16:31:46,281 alphaction.inference INFO: Preparing results for AVA format
2022-04-26 16:31:46,307 alphaction.inference INFO: Evaluating predictions
2022-04-26 16:31:46,356 alphaction.inference INFO: ==> 0.0490999 seconds to write file /tmp/tmp2nkuxv6z
2022-04-26 16:31:46,356 alphaction.inference INFO: CATEGORIES (12):
[ {'id': 1, 'name': 'cut (an object)'},
  {'id': 2, 'name': 'holding for (a person)'},
  {'id': 3, 'name': 'handover to (a person)'},
  {'id': 4, 'name': 'squeeze (an object)'},
  {'id': 5, 'name': 'sprinkle (an object)'},
  {'id': 6, 'name': 'transfer (an object)'},
  {'id': 7, 'name': 'pour (an object)'},
  {'id': 8, 'name': 'heat (an object)'},
  {'id': 9, 'name': 'stir (an object)'},
  {'id': 10, 'name': 'wrap (an object)'},
  {'id': 11, 'name': 'roll (an object)'},
  {'id': 12, 'name': 'dip (an object)'}]
2022-04-26 16:31:46,357 alphaction.inference INFO: ==> 0.000432014 seconds to read file data/lfv_robalo/annotations/lfv_robalo_val.csv
2022-04-26 16:31:46,373 alphaction.inference INFO: ==> 0.0161445 seconds to convert groundtruth
2022-04-26 16:31:46,394 alphaction.inference INFO: ==> 0.0204303 seconds to read file /tmp/tmp2nkuxv6z
2022-04-26 16:31:46,727 alphaction.inference INFO: ==> 0.33322 seconds to convert detections
2022-04-26 16:31:46,727 alphaction.inference INFO: The following classes have no ground truth examples: [ 2  3 10 11 12]
2022-04-26 16:31:46,730 alphaction.inference INFO: ==> 0.00263286 seconds to run_evaluator
2022-04-26 16:31:46,731 alphaction.inference INFO: { 'PascalBoxes_PerformanceByCategory/AP@0.5IOU/cut (an object)': 0.6779000632607973,
  'PascalBoxes_PerformanceByCategory/AP@0.5IOU/dip (an object)': nan,
  'PascalBoxes_PerformanceByCategory/AP@0.5IOU/handover to (a person)': nan,
  'PascalBoxes_PerformanceByCategory/AP@0.5IOU/heat (an object)': 0.633066426058393,
  'PascalBoxes_PerformanceByCategory/AP@0.5IOU/holding for (a person)': nan,
  'PascalBoxes_PerformanceByCategory/AP@0.5IOU/pour (an object)': 0.29306147291539864,
  'PascalBoxes_PerformanceByCategory/AP@0.5IOU/roll (an object)': nan,
  'PascalBoxes_PerformanceByCategory/AP@0.5IOU/sprinkle (an object)': 0.0273972602739726,
  'PascalBoxes_PerformanceByCategory/AP@0.5IOU/squeeze (an object)': 0.06341538832828031,
  'PascalBoxes_PerformanceByCategory/AP@0.5IOU/stir (an object)': 0.21890973902323208,
  'PascalBoxes_PerformanceByCategory/AP@0.5IOU/transfer (an object)': 0.42284639097835075,
  'PascalBoxes_PerformanceByCategory/AP@0.5IOU/wrap (an object)': nan,
  'PascalBoxes_Precision/mAP@0.5IOU': 0.3337995344054892}
2022-04-26 16:31:56,806 alphaction.trainer INFO: eta: 5 days, 3:46:47  iter: 4020  loss_pose_action: 0.0003 (0.4192)  loss_object_interaction: 0.0000 (0.0005)  loss_person_interaction: 0.0000 (0.0005)  total_loss: 0.0011 (0.5380)  accuracy_pose_action: 1.0000 (0.7836)  accuracy_object_interaction: 1.0000 (0.9980)  accuracy_person_interaction: 1.0000 (0.9983)  time: 0.5022 (0.5087)  data: 0.0141 (0.0141)  lr: 0.000125  max mem: 2403
2022-04-26 16:32:06,959 alphaction.trainer INFO: eta: 5 days, 3:46:32  iter: 4040  loss_pose_action: 0.0029 (0.4176)  loss_object_interaction: 0.0000 (0.0005)  loss_person_interaction: 0.0000 (0.0005)  total_loss: 0.0050 (0.5360)  accuracy_pose_action: 1.0000 (0.7843)  accuracy_object_interaction: 1.0000 (0.9980)  accuracy_person_interaction: 1.0000 (0.9983)  time: 0.5100 (0.5087)  data: 0.0138 (0.0141)  lr: 0.000125  max mem: 2403
2022-04-26 16:32:17,154 alphaction.trainer INFO: eta: 5 days, 3:46:27  iter: 4060  loss_pose_action: 0.0007 (0.4161)  loss_object_interaction: 0.0000 (0.0005)  loss_person_interaction: 0.0000 (0.0005)  total_loss: 0.0021 (0.5339)  accuracy_pose_action: 1.0000 (0.7850)  accuracy_object_interaction: 1.0000 (0.9980)  accuracy_person_interaction: 1.0000 (0.9983)  time: 0.5114 (0.5087)  data: 0.0141 (0.0141)  lr: 0.000125  max mem: 2403
2022-04-26 16:32:27,397 alphaction.trainer INFO: eta: 5 days, 3:46:31  iter: 4080  loss_pose_action: 0.0016 (0.4147)  loss_object_interaction: 0.0000 (0.0005)  loss_person_interaction: 0.0000 (0.0005)  total_loss: 0.0030 (0.5322)  accuracy_pose_action: 1.0000 (0.7856)  accuracy_object_interaction: 1.0000 (0.9980)  accuracy_person_interaction: 1.0000 (0.9983)  time: 0.5134 (0.5087)  data: 0.0140 (0.0141)  lr: 0.000125  max mem: 2403
2022-04-26 16:32:37,659 alphaction.trainer INFO: eta: 5 days, 3:46:40  iter: 4100  loss_pose_action: 0.0003 (0.4139)  loss_object_interaction: 0.0000 (0.0005)  loss_person_interaction: 0.0000 (0.0005)  total_loss: 0.0014 (0.5310)  accuracy_pose_action: 1.0000 (0.7860)  accuracy_object_interaction: 1.0000 (0.9980)  accuracy_person_interaction: 1.0000 (0.9983)  time: 0.5144 (0.5087)  data: 0.0138 (0.0141)  lr: 0.000125  max mem: 2403
2022-04-26 16:32:37,664 alphaction.utils.checkpoint INFO: Saving checkpoint to data/output/resnet50_4x16f_baseline_robalo/model_0004100.pth
2022-04-26 16:32:37,933 alphaction.inference INFO: Start evaluation on lfv_robalo_val_ava_video dataset(135 videos).
2022-04-26 16:32:52,396 alphaction.inference INFO: Total inference time: 0:00:14.462645 (0.10713070233662923 s / video per device, on 1 devices)
2022-04-26 16:32:52,396 alphaction.inference INFO: performing ava evaluation.
2022-04-26 16:32:52,396 alphaction.inference INFO: Preparing results for AVA format
2022-04-26 16:32:52,419 alphaction.inference INFO: Evaluating predictions
2022-04-26 16:32:52,487 alphaction.inference INFO: ==> 0.0680027 seconds to write file /tmp/tmpra1fr7vz
2022-04-26 16:32:52,488 alphaction.inference INFO: CATEGORIES (12):
[ {'id': 1, 'name': 'cut (an object)'},
  {'id': 2, 'name': 'holding for (a person)'},
  {'id': 3, 'name': 'handover to (a person)'},
  {'id': 4, 'name': 'squeeze (an object)'},
  {'id': 5, 'name': 'sprinkle (an object)'},
  {'id': 6, 'name': 'transfer (an object)'},
  {'id': 7, 'name': 'pour (an object)'},
  {'id': 8, 'name': 'heat (an object)'},
  {'id': 9, 'name': 'stir (an object)'},
  {'id': 10, 'name': 'wrap (an object)'},
  {'id': 11, 'name': 'roll (an object)'},
  {'id': 12, 'name': 'dip (an object)'}]
2022-04-26 16:32:52,489 alphaction.inference INFO: ==> 0.000787973 seconds to read file data/lfv_robalo/annotations/lfv_robalo_val.csv
2022-04-26 16:32:52,505 alphaction.inference INFO: ==> 0.0163395 seconds to convert groundtruth
2022-04-26 16:32:52,524 alphaction.inference INFO: ==> 0.0190275 seconds to read file /tmp/tmpra1fr7vz
2022-04-26 16:32:52,862 alphaction.inference INFO: ==> 0.338124 seconds to convert detections
2022-04-26 16:32:52,862 alphaction.inference INFO: The following classes have no ground truth examples: [ 2  3 10 11 12]
2022-04-26 16:32:52,865 alphaction.inference INFO: ==> 0.00275421 seconds to run_evaluator
2022-04-26 16:32:52,866 alphaction.inference INFO: { 'PascalBoxes_PerformanceByCategory/AP@0.5IOU/cut (an object)': 0.7039788852155145,
  'PascalBoxes_PerformanceByCategory/AP@0.5IOU/dip (an object)': nan,
  'PascalBoxes_PerformanceByCategory/AP@0.5IOU/handover to (a person)': nan,
  'PascalBoxes_PerformanceByCategory/AP@0.5IOU/heat (an object)': 0.5827383525672697,
  'PascalBoxes_PerformanceByCategory/AP@0.5IOU/holding for (a person)': nan,
  'PascalBoxes_PerformanceByCategory/AP@0.5IOU/pour (an object)': 0.19946236559139785,
  'PascalBoxes_PerformanceByCategory/AP@0.5IOU/roll (an object)': nan,
  'PascalBoxes_PerformanceByCategory/AP@0.5IOU/sprinkle (an object)': 0.04,
  'PascalBoxes_PerformanceByCategory/AP@0.5IOU/squeeze (an object)': 0.06934568699274582,
  'PascalBoxes_PerformanceByCategory/AP@0.5IOU/stir (an object)': 0.1845238095238095,
  'PascalBoxes_PerformanceByCategory/AP@0.5IOU/transfer (an object)': 0.4216091847606884,
  'PascalBoxes_PerformanceByCategory/AP@0.5IOU/wrap (an object)': nan,
  'PascalBoxes_Precision/mAP@0.5IOU': 0.3145226120930608}
2022-04-26 16:33:02,935 alphaction.trainer INFO: eta: 5 days, 3:46:07  iter: 4120  loss_pose_action: 0.0066 (0.4129)  loss_object_interaction: 0.0000 (0.0005)  loss_person_interaction: 0.0000 (0.0005)  total_loss: 0.0125 (0.5297)  accuracy_pose_action: 1.0000 (0.7865)  accuracy_object_interaction: 1.0000 (0.9981)  accuracy_person_interaction: 1.0000 (0.9983)  time: 0.5025 (0.5087)  data: 0.0138 (0.0141)  lr: 0.000125  max mem: 2403
2022-04-26 16:33:13,073 alphaction.trainer INFO: eta: 5 days, 3:45:49  iter: 4140  loss_pose_action: 0.0028 (0.4117)  loss_object_interaction: 0.0001 (0.0005)  loss_person_interaction: 0.0001 (0.0005)  total_loss: 0.0233 (0.5282)  accuracy_pose_action: 1.0000 (0.7871)  accuracy_object_interaction: 1.0000 (0.9981)  accuracy_person_interaction: 1.0000 (0.9983)  time: 0.5105 (0.5087)  data: 0.0138 (0.0141)  lr: 0.000125  max mem: 2403
2022-04-26 16:33:23,303 alphaction.trainer INFO: eta: 5 days, 3:45:51  iter: 4160  loss_pose_action: 0.0314 (0.4110)  loss_object_interaction: 0.0001 (0.0005)  loss_person_interaction: 0.0001 (0.0005)  total_loss: 0.0468 (0.5273)  accuracy_pose_action: 1.0000 (0.7873)  accuracy_object_interaction: 1.0000 (0.9981)  accuracy_person_interaction: 1.0000 (0.9983)  time: 0.5133 (0.5087)  data: 0.0144 (0.0141)  lr: 0.000125  max mem: 2403
2022-04-26 16:33:33,475 alphaction.trainer INFO: eta: 5 days, 3:45:40  iter: 4180  loss_pose_action: 0.0036 (0.4098)  loss_object_interaction: 0.0000 (0.0005)  loss_person_interaction: 0.0001 (0.0005)  total_loss: 0.0103 (0.5257)  accuracy_pose_action: 1.0000 (0.7880)  accuracy_object_interaction: 1.0000 (0.9981)  accuracy_person_interaction: 1.0000 (0.9983)  time: 0.5127 (0.5087)  data: 0.0140 (0.0141)  lr: 0.000125  max mem: 2403
2022-04-26 16:33:43,685 alphaction.trainer INFO: eta: 5 days, 3:45:37  iter: 4200  loss_pose_action: 0.0017 (0.4081)  loss_object_interaction: 0.0000 (0.0005)  loss_person_interaction: 0.0000 (0.0005)  total_loss: 0.0057 (0.5236)  accuracy_pose_action: 1.0000 (0.7890)  accuracy_object_interaction: 1.0000 (0.9981)  accuracy_person_interaction: 1.0000 (0.9983)  time: 0.5131 (0.5087)  data: 0.0144 (0.0141)  lr: 0.000125  max mem: 2403
2022-04-26 16:33:43,689 alphaction.utils.checkpoint INFO: Saving checkpoint to data/output/resnet50_4x16f_baseline_robalo/model_0004200.pth
2022-04-26 16:33:43,948 alphaction.inference INFO: Start evaluation on lfv_robalo_val_ava_video dataset(135 videos).
2022-04-26 16:33:58,627 alphaction.inference INFO: Total inference time: 0:00:14.679486 (0.10873693536829065 s / video per device, on 1 devices)
2022-04-26 16:33:58,628 alphaction.inference INFO: performing ava evaluation.
2022-04-26 16:33:58,628 alphaction.inference INFO: Preparing results for AVA format
2022-04-26 16:33:58,644 alphaction.inference INFO: Evaluating predictions
2022-04-26 16:33:58,694 alphaction.inference INFO: ==> 0.0495625 seconds to write file /tmp/tmpqmchk0os
2022-04-26 16:33:58,694 alphaction.inference INFO: CATEGORIES (12):
[ {'id': 1, 'name': 'cut (an object)'},
  {'id': 2, 'name': 'holding for (a person)'},
  {'id': 3, 'name': 'handover to (a person)'},
  {'id': 4, 'name': 'squeeze (an object)'},
  {'id': 5, 'name': 'sprinkle (an object)'},
  {'id': 6, 'name': 'transfer (an object)'},
  {'id': 7, 'name': 'pour (an object)'},
  {'id': 8, 'name': 'heat (an object)'},
  {'id': 9, 'name': 'stir (an object)'},
  {'id': 10, 'name': 'wrap (an object)'},
  {'id': 11, 'name': 'roll (an object)'},
  {'id': 12, 'name': 'dip (an object)'}]
2022-04-26 16:33:58,695 alphaction.inference INFO: ==> 0.000468016 seconds to read file data/lfv_robalo/annotations/lfv_robalo_val.csv
2022-04-26 16:33:58,713 alphaction.inference INFO: ==> 0.0183094 seconds to convert groundtruth
2022-04-26 16:33:58,733 alphaction.inference INFO: ==> 0.0192163 seconds to read file /tmp/tmpqmchk0os
2022-04-26 16:33:59,064 alphaction.inference INFO: ==> 0.331115 seconds to convert detections
2022-04-26 16:33:59,064 alphaction.inference INFO: The following classes have no ground truth examples: [ 2  3 10 11 12]
2022-04-26 16:33:59,067 alphaction.inference INFO: ==> 0.00266504 seconds to run_evaluator
2022-04-26 16:33:59,068 alphaction.inference INFO: { 'PascalBoxes_PerformanceByCategory/AP@0.5IOU/cut (an object)': 0.8656085398102773,
  'PascalBoxes_PerformanceByCategory/AP@0.5IOU/dip (an object)': nan,
  'PascalBoxes_PerformanceByCategory/AP@0.5IOU/handover to (a person)': nan,
  'PascalBoxes_PerformanceByCategory/AP@0.5IOU/heat (an object)': 0.6345602287194787,
  'PascalBoxes_PerformanceByCategory/AP@0.5IOU/holding for (a person)': nan,
  'PascalBoxes_PerformanceByCategory/AP@0.5IOU/pour (an object)': 0.15089285714285716,
  'PascalBoxes_PerformanceByCategory/AP@0.5IOU/roll (an object)': nan,
  'PascalBoxes_PerformanceByCategory/AP@0.5IOU/sprinkle (an object)': 0.02564102564102564,
  'PascalBoxes_PerformanceByCategory/AP@0.5IOU/squeeze (an object)': 0.06347772416114913,
  'PascalBoxes_PerformanceByCategory/AP@0.5IOU/stir (an object)': 0.1651607251835565,
  'PascalBoxes_PerformanceByCategory/AP@0.5IOU/transfer (an object)': 0.47134889634690236,
  'PascalBoxes_PerformanceByCategory/AP@0.5IOU/wrap (an object)': nan,
  'PascalBoxes_Precision/mAP@0.5IOU': 0.33952714242932097}
2022-04-26 16:34:09,136 alphaction.trainer INFO: eta: 5 days, 3:45:05  iter: 4220  loss_pose_action: 0.0002 (0.4063)  loss_object_interaction: 0.0000 (0.0005)  loss_person_interaction: 0.0000 (0.0005)  total_loss: 0.0006 (0.5213)  accuracy_pose_action: 1.0000 (0.7899)  accuracy_object_interaction: 1.0000 (0.9981)  accuracy_person_interaction: 1.0000 (0.9983)  time: 0.5043 (0.5087)  data: 0.0135 (0.0141)  lr: 0.000125  max mem: 2403
2022-04-26 16:34:19,347 alphaction.trainer INFO: eta: 5 days, 3:45:02  iter: 4240  loss_pose_action: 0.0001 (0.4047)  loss_object_interaction: 0.0000 (0.0005)  loss_person_interaction: 0.0000 (0.0005)  total_loss: 0.0013 (0.5192)  accuracy_pose_action: 1.0000 (0.7907)  accuracy_object_interaction: 1.0000 (0.9981)  accuracy_person_interaction: 1.0000 (0.9983)  time: 0.5133 (0.5087)  data: 0.0144 (0.0141)  lr: 0.000125  max mem: 2403
2022-04-26 16:34:29,565 alphaction.trainer INFO: eta: 5 days, 3:45:01  iter: 4260  loss_pose_action: 0.0013 (0.4032)  loss_object_interaction: 0.0000 (0.0005)  loss_person_interaction: 0.0000 (0.0005)  total_loss: 0.0026 (0.5173)  accuracy_pose_action: 1.0000 (0.7913)  accuracy_object_interaction: 1.0000 (0.9981)  accuracy_person_interaction: 1.0000 (0.9984)  time: 0.5126 (0.5087)  data: 0.0143 (0.0141)  lr: 0.000125  max mem: 2403
2022-04-26 16:34:39,801 alphaction.trainer INFO: eta: 5 days, 3:45:04  iter: 4280  loss_pose_action: 0.0003 (0.4017)  loss_object_interaction: 0.0000 (0.0005)  loss_person_interaction: 0.0000 (0.0005)  total_loss: 0.0022 (0.5153)  accuracy_pose_action: 1.0000 (0.7921)  accuracy_object_interaction: 1.0000 (0.9981)  accuracy_person_interaction: 1.0000 (0.9984)  time: 0.5124 (0.5087)  data: 0.0143 (0.0141)  lr: 0.000125  max mem: 2403
2022-04-26 16:34:50,033 alphaction.trainer INFO: eta: 5 days, 3:45:05  iter: 4300  loss_pose_action: 0.0000 (0.4002)  loss_object_interaction: 0.0000 (0.0005)  loss_person_interaction: 0.0000 (0.0005)  total_loss: 0.0016 (0.5133)  accuracy_pose_action: 1.0000 (0.7928)  accuracy_object_interaction: 1.0000 (0.9981)  accuracy_person_interaction: 1.0000 (0.9984)  time: 0.5134 (0.5087)  data: 0.0143 (0.0141)  lr: 0.000125  max mem: 2403
2022-04-26 16:34:50,037 alphaction.utils.checkpoint INFO: Saving checkpoint to data/output/resnet50_4x16f_baseline_robalo/model_0004300.pth
2022-04-26 16:34:50,293 alphaction.inference INFO: Start evaluation on lfv_robalo_val_ava_video dataset(135 videos).
2022-04-26 16:35:05,068 alphaction.inference INFO: Total inference time: 0:00:14.774635 (0.10944174307364005 s / video per device, on 1 devices)
2022-04-26 16:35:05,068 alphaction.inference INFO: performing ava evaluation.
2022-04-26 16:35:05,068 alphaction.inference INFO: Preparing results for AVA format
2022-04-26 16:35:05,085 alphaction.inference INFO: Evaluating predictions
2022-04-26 16:35:05,137 alphaction.inference INFO: ==> 0.0516422 seconds to write file /tmp/tmpjtju_ddv
2022-04-26 16:35:05,138 alphaction.inference INFO: CATEGORIES (12):
[ {'id': 1, 'name': 'cut (an object)'},
  {'id': 2, 'name': 'holding for (a person)'},
  {'id': 3, 'name': 'handover to (a person)'},
  {'id': 4, 'name': 'squeeze (an object)'},
  {'id': 5, 'name': 'sprinkle (an object)'},
  {'id': 6, 'name': 'transfer (an object)'},
  {'id': 7, 'name': 'pour (an object)'},
  {'id': 8, 'name': 'heat (an object)'},
  {'id': 9, 'name': 'stir (an object)'},
  {'id': 10, 'name': 'wrap (an object)'},
  {'id': 11, 'name': 'roll (an object)'},
  {'id': 12, 'name': 'dip (an object)'}]
2022-04-26 16:35:05,138 alphaction.inference INFO: ==> 0.000526428 seconds to read file data/lfv_robalo/annotations/lfv_robalo_val.csv
2022-04-26 16:35:05,156 alphaction.inference INFO: ==> 0.0177414 seconds to convert groundtruth
2022-04-26 16:35:05,176 alphaction.inference INFO: ==> 0.0197206 seconds to read file /tmp/tmpjtju_ddv
2022-04-26 16:35:05,528 alphaction.inference INFO: ==> 0.351241 seconds to convert detections
2022-04-26 16:35:05,528 alphaction.inference INFO: The following classes have no ground truth examples: [ 2  3 10 11 12]
2022-04-26 16:35:05,530 alphaction.inference INFO: ==> 0.00270581 seconds to run_evaluator
2022-04-26 16:35:05,533 alphaction.inference INFO: { 'PascalBoxes_PerformanceByCategory/AP@0.5IOU/cut (an object)': 0.8110592415972684,
  'PascalBoxes_PerformanceByCategory/AP@0.5IOU/dip (an object)': nan,
  'PascalBoxes_PerformanceByCategory/AP@0.5IOU/handover to (a person)': nan,
  'PascalBoxes_PerformanceByCategory/AP@0.5IOU/heat (an object)': 0.6895076910446883,
  'PascalBoxes_PerformanceByCategory/AP@0.5IOU/holding for (a person)': nan,
  'PascalBoxes_PerformanceByCategory/AP@0.5IOU/pour (an object)': 0.15641711229946526,
  'PascalBoxes_PerformanceByCategory/AP@0.5IOU/roll (an object)': nan,
  'PascalBoxes_PerformanceByCategory/AP@0.5IOU/sprinkle (an object)': 0.03076923076923077,
  'PascalBoxes_PerformanceByCategory/AP@0.5IOU/squeeze (an object)': 0.07463965427727291,
  'PascalBoxes_PerformanceByCategory/AP@0.5IOU/stir (an object)': 0.17505557598928428,
  'PascalBoxes_PerformanceByCategory/AP@0.5IOU/transfer (an object)': 0.4733112341161318,
  'PascalBoxes_PerformanceByCategory/AP@0.5IOU/wrap (an object)': nan,
  'PascalBoxes_Precision/mAP@0.5IOU': 0.34439424858476314}
2022-04-26 16:35:15,679 alphaction.trainer INFO: eta: 5 days, 3:44:49  iter: 4320  loss_pose_action: 0.0002 (0.3991)  loss_object_interaction: 0.0000 (0.0005)  loss_person_interaction: 0.0000 (0.0005)  total_loss: 0.0010 (0.5119)  accuracy_pose_action: 1.0000 (0.7933)  accuracy_object_interaction: 1.0000 (0.9981)  accuracy_person_interaction: 1.0000 (0.9984)  time: 0.5081 (0.5087)  data: 0.0138 (0.0141)  lr: 0.000125  max mem: 2403
2022-04-26 16:35:25,856 alphaction.trainer INFO: eta: 5 days, 3:44:39  iter: 4340  loss_pose_action: 0.0005 (0.3980)  loss_object_interaction: 0.0000 (0.0005)  loss_person_interaction: 0.0001 (0.0005)  total_loss: 0.0058 (0.5105)  accuracy_pose_action: 1.0000 (0.7938)  accuracy_object_interaction: 1.0000 (0.9982)  accuracy_person_interaction: 1.0000 (0.9984)  time: 0.5121 (0.5087)  data: 0.0142 (0.0141)  lr: 0.000125  max mem: 2403
2022-04-26 16:35:36,024 alphaction.trainer INFO: eta: 5 days, 3:44:28  iter: 4360  loss_pose_action: 0.0006 (0.3965)  loss_object_interaction: 0.0000 (0.0005)  loss_person_interaction: 0.0000 (0.0005)  total_loss: 0.0034 (0.5085)  accuracy_pose_action: 1.0000 (0.7946)  accuracy_object_interaction: 1.0000 (0.9982)  accuracy_person_interaction: 1.0000 (0.9984)  time: 0.5118 (0.5087)  data: 0.0141 (0.0141)  lr: 0.000125  max mem: 2403
2022-04-26 16:35:46,260 alphaction.trainer INFO: eta: 5 days, 3:44:30  iter: 4380  loss_pose_action: 0.0001 (0.3949)  loss_object_interaction: 0.0000 (0.0005)  loss_person_interaction: 0.0000 (0.0005)  total_loss: 0.0031 (0.5065)  accuracy_pose_action: 1.0000 (0.7953)  accuracy_object_interaction: 1.0000 (0.9982)  accuracy_person_interaction: 1.0000 (0.9984)  time: 0.5141 (0.5087)  data: 0.0141 (0.0141)  lr: 0.000125  max mem: 2403
2022-04-26 16:35:56,501 alphaction.trainer INFO: eta: 5 days, 3:44:33  iter: 4400  loss_pose_action: 0.0002 (0.3941)  loss_object_interaction: 0.0000 (0.0005)  loss_person_interaction: 0.0000 (0.0005)  total_loss: 0.0047 (0.5054)  accuracy_pose_action: 1.0000 (0.7956)  accuracy_object_interaction: 1.0000 (0.9982)  accuracy_person_interaction: 1.0000 (0.9984)  time: 0.5137 (0.5088)  data: 0.0142 (0.0141)  lr: 0.000125  max mem: 2403
2022-04-26 16:35:56,505 alphaction.utils.checkpoint INFO: Saving checkpoint to data/output/resnet50_4x16f_baseline_robalo/model_0004400.pth
2022-04-26 16:35:56,772 alphaction.inference INFO: Start evaluation on lfv_robalo_val_ava_video dataset(135 videos).
2022-04-26 16:36:12,031 alphaction.inference INFO: Total inference time: 0:00:15.258593 (0.11302661189326534 s / video per device, on 1 devices)
2022-04-26 16:36:12,031 alphaction.inference INFO: performing ava evaluation.
2022-04-26 16:36:12,031 alphaction.inference INFO: Preparing results for AVA format
2022-04-26 16:36:12,052 alphaction.inference INFO: Evaluating predictions
2022-04-26 16:36:12,123 alphaction.inference INFO: ==> 0.0705774 seconds to write file /tmp/tmpqd37si9u
2022-04-26 16:36:12,124 alphaction.inference INFO: CATEGORIES (12):
[ {'id': 1, 'name': 'cut (an object)'},
  {'id': 2, 'name': 'holding for (a person)'},
  {'id': 3, 'name': 'handover to (a person)'},
  {'id': 4, 'name': 'squeeze (an object)'},
  {'id': 5, 'name': 'sprinkle (an object)'},
  {'id': 6, 'name': 'transfer (an object)'},
  {'id': 7, 'name': 'pour (an object)'},
  {'id': 8, 'name': 'heat (an object)'},
  {'id': 9, 'name': 'stir (an object)'},
  {'id': 10, 'name': 'wrap (an object)'},
  {'id': 11, 'name': 'roll (an object)'},
  {'id': 12, 'name': 'dip (an object)'}]
2022-04-26 16:36:12,124 alphaction.inference INFO: ==> 0.000423193 seconds to read file data/lfv_robalo/annotations/lfv_robalo_val.csv
2022-04-26 16:36:12,141 alphaction.inference INFO: ==> 0.0163388 seconds to convert groundtruth
2022-04-26 16:36:12,160 alphaction.inference INFO: ==> 0.0191395 seconds to read file /tmp/tmpqd37si9u
2022-04-26 16:36:12,498 alphaction.inference INFO: ==> 0.338063 seconds to convert detections
2022-04-26 16:36:12,498 alphaction.inference INFO: The following classes have no ground truth examples: [ 2  3 10 11 12]
2022-04-26 16:36:12,501 alphaction.inference INFO: ==> 0.00270438 seconds to run_evaluator
2022-04-26 16:36:12,502 alphaction.inference INFO: { 'PascalBoxes_PerformanceByCategory/AP@0.5IOU/cut (an object)': 0.6929901707606424,
  'PascalBoxes_PerformanceByCategory/AP@0.5IOU/dip (an object)': nan,
  'PascalBoxes_PerformanceByCategory/AP@0.5IOU/handover to (a person)': nan,
  'PascalBoxes_PerformanceByCategory/AP@0.5IOU/heat (an object)': 0.7011320430443457,
  'PascalBoxes_PerformanceByCategory/AP@0.5IOU/holding for (a person)': nan,
  'PascalBoxes_PerformanceByCategory/AP@0.5IOU/pour (an object)': 0.1855646630236794,
  'PascalBoxes_PerformanceByCategory/AP@0.5IOU/roll (an object)': nan,
  'PascalBoxes_PerformanceByCategory/AP@0.5IOU/sprinkle (an object)': 0.020202020202020204,
  'PascalBoxes_PerformanceByCategory/AP@0.5IOU/squeeze (an object)': 0.07892467411854456,
  'PascalBoxes_PerformanceByCategory/AP@0.5IOU/stir (an object)': 0.43588764537475266,
  'PascalBoxes_PerformanceByCategory/AP@0.5IOU/transfer (an object)': 0.4676343247015319,
  'PascalBoxes_PerformanceByCategory/AP@0.5IOU/wrap (an object)': nan,
  'PascalBoxes_Precision/mAP@0.5IOU': 0.36890507731793093}
2022-04-26 16:36:22,550 alphaction.trainer INFO: eta: 5 days, 3:43:57  iter: 4420  loss_pose_action: 0.0107 (0.3930)  loss_object_interaction: 0.0000 (0.0005)  loss_person_interaction: 0.0000 (0.0005)  total_loss: 0.0174 (0.5040)  accuracy_pose_action: 1.0000 (0.7961)  accuracy_object_interaction: 1.0000 (0.9982)  accuracy_person_interaction: 1.0000 (0.9984)  time: 0.5009 (0.5087)  data: 0.0139 (0.0141)  lr: 0.000125  max mem: 2403
2022-04-26 16:36:32,745 alphaction.trainer INFO: eta: 5 days, 3:43:51  iter: 4440  loss_pose_action: 0.0002 (0.3917)  loss_object_interaction: 0.0000 (0.0005)  loss_person_interaction: 0.0000 (0.0005)  total_loss: 0.0052 (0.5024)  accuracy_pose_action: 1.0000 (0.7969)  accuracy_object_interaction: 1.0000 (0.9982)  accuracy_person_interaction: 1.0000 (0.9984)  time: 0.5114 (0.5087)  data: 0.0143 (0.0141)  lr: 0.000125  max mem: 2403
2022-04-26 16:36:42,927 alphaction.trainer INFO: eta: 5 days, 3:43:42  iter: 4460  loss_pose_action: 0.0011 (0.3903)  loss_object_interaction: 0.0001 (0.0005)  loss_person_interaction: 0.0001 (0.0005)  total_loss: 0.0116 (0.5006)  accuracy_pose_action: 1.0000 (0.7976)  accuracy_object_interaction: 1.0000 (0.9982)  accuracy_person_interaction: 1.0000 (0.9984)  time: 0.5143 (0.5087)  data: 0.0143 (0.0141)  lr: 0.000125  max mem: 2403
2022-04-26 16:36:53,121 alphaction.trainer INFO: eta: 5 days, 3:43:36  iter: 4480  loss_pose_action: 0.0014 (0.3888)  loss_object_interaction: 0.0000 (0.0005)  loss_person_interaction: 0.0000 (0.0005)  total_loss: 0.0026 (0.4986)  accuracy_pose_action: 1.0000 (0.7980)  accuracy_object_interaction: 1.0000 (0.9982)  accuracy_person_interaction: 1.0000 (0.9984)  time: 0.5133 (0.5087)  data: 0.0134 (0.0141)  lr: 0.000125  max mem: 2403
2022-04-26 16:37:03,368 alphaction.trainer INFO: eta: 5 days, 3:43:39  iter: 4500  loss_pose_action: 0.0000 (0.3875)  loss_object_interaction: 0.0000 (0.0005)  loss_person_interaction: 0.0000 (0.0005)  total_loss: 0.0005 (0.4970)  accuracy_pose_action: 1.0000 (0.7987)  accuracy_object_interaction: 1.0000 (0.9982)  accuracy_person_interaction: 1.0000 (0.9984)  time: 0.5147 (0.5088)  data: 0.0144 (0.0141)  lr: 0.000125  max mem: 2403
2022-04-26 16:37:03,372 alphaction.utils.checkpoint INFO: Saving checkpoint to data/output/resnet50_4x16f_baseline_robalo/model_0004500.pth
2022-04-26 16:37:03,640 alphaction.inference INFO: Start evaluation on lfv_robalo_val_ava_video dataset(135 videos).
2022-04-26 16:37:18,476 alphaction.inference INFO: Total inference time: 0:00:14.836374 (0.10989906876175493 s / video per device, on 1 devices)
2022-04-26 16:37:18,477 alphaction.inference INFO: performing ava evaluation.
2022-04-26 16:37:18,477 alphaction.inference INFO: Preparing results for AVA format
2022-04-26 16:37:18,493 alphaction.inference INFO: Evaluating predictions
2022-04-26 16:37:18,544 alphaction.inference INFO: ==> 0.0501883 seconds to write file /tmp/tmpg6af3r63
2022-04-26 16:37:18,544 alphaction.inference INFO: CATEGORIES (12):
[ {'id': 1, 'name': 'cut (an object)'},
  {'id': 2, 'name': 'holding for (a person)'},
  {'id': 3, 'name': 'handover to (a person)'},
  {'id': 4, 'name': 'squeeze (an object)'},
  {'id': 5, 'name': 'sprinkle (an object)'},
  {'id': 6, 'name': 'transfer (an object)'},
  {'id': 7, 'name': 'pour (an object)'},
  {'id': 8, 'name': 'heat (an object)'},
  {'id': 9, 'name': 'stir (an object)'},
  {'id': 10, 'name': 'wrap (an object)'},
  {'id': 11, 'name': 'roll (an object)'},
  {'id': 12, 'name': 'dip (an object)'}]
2022-04-26 16:37:18,545 alphaction.inference INFO: ==> 0.000504971 seconds to read file data/lfv_robalo/annotations/lfv_robalo_val.csv
2022-04-26 16:37:18,562 alphaction.inference INFO: ==> 0.0165122 seconds to convert groundtruth
2022-04-26 16:37:18,581 alphaction.inference INFO: ==> 0.0191555 seconds to read file /tmp/tmpg6af3r63
2022-04-26 16:37:18,922 alphaction.inference INFO: ==> 0.340952 seconds to convert detections
2022-04-26 16:37:18,922 alphaction.inference INFO: The following classes have no ground truth examples: [ 2  3 10 11 12]
2022-04-26 16:37:18,925 alphaction.inference INFO: ==> 0.00282288 seconds to run_evaluator
2022-04-26 16:37:18,926 alphaction.inference INFO: { 'PascalBoxes_PerformanceByCategory/AP@0.5IOU/cut (an object)': 0.6520481096362168,
  'PascalBoxes_PerformanceByCategory/AP@0.5IOU/dip (an object)': nan,
  'PascalBoxes_PerformanceByCategory/AP@0.5IOU/handover to (a person)': nan,
  'PascalBoxes_PerformanceByCategory/AP@0.5IOU/heat (an object)': 0.6994220243278869,
  'PascalBoxes_PerformanceByCategory/AP@0.5IOU/holding for (a person)': nan,
  'PascalBoxes_PerformanceByCategory/AP@0.5IOU/pour (an object)': 0.09610472541507024,
  'PascalBoxes_PerformanceByCategory/AP@0.5IOU/roll (an object)': nan,
  'PascalBoxes_PerformanceByCategory/AP@0.5IOU/sprinkle (an object)': 0.03773584905660377,
  'PascalBoxes_PerformanceByCategory/AP@0.5IOU/squeeze (an object)': 0.11552795031055901,
  'PascalBoxes_PerformanceByCategory/AP@0.5IOU/stir (an object)': 0.391030776077505,
  'PascalBoxes_PerformanceByCategory/AP@0.5IOU/transfer (an object)': 0.4575381122228271,
  'PascalBoxes_PerformanceByCategory/AP@0.5IOU/wrap (an object)': nan,
  'PascalBoxes_Precision/mAP@0.5IOU': 0.3499153638638099}
2022-04-26 16:37:29,005 alphaction.trainer INFO: eta: 5 days, 3:43:10  iter: 4520  loss_pose_action: 0.0039 (0.3867)  loss_object_interaction: 0.0000 (0.0005)  loss_person_interaction: 0.0000 (0.0005)  total_loss: 0.0085 (0.4959)  accuracy_pose_action: 1.0000 (0.7993)  accuracy_object_interaction: 1.0000 (0.9982)  accuracy_person_interaction: 1.0000 (0.9985)  time: 0.5047 (0.5087)  data: 0.0142 (0.0141)  lr: 0.000125  max mem: 2403
2022-04-26 16:37:39,196 alphaction.trainer INFO: eta: 5 days, 3:43:03  iter: 4540  loss_pose_action: 0.0005 (0.3853)  loss_object_interaction: 0.0000 (0.0005)  loss_person_interaction: 0.0000 (0.0005)  total_loss: 0.0021 (0.4941)  accuracy_pose_action: 1.0000 (0.8001)  accuracy_object_interaction: 1.0000 (0.9982)  accuracy_person_interaction: 1.0000 (0.9985)  time: 0.5104 (0.5087)  data: 0.0144 (0.0141)  lr: 0.000125  max mem: 2403
2022-04-26 16:37:49,330 alphaction.trainer INFO: eta: 5 days, 3:42:45  iter: 4560  loss_pose_action: 0.0005 (0.3836)  loss_object_interaction: 0.0000 (0.0005)  loss_person_interaction: 0.0000 (0.0005)  total_loss: 0.0023 (0.4919)  accuracy_pose_action: 1.0000 (0.8010)  accuracy_object_interaction: 1.0000 (0.9982)  accuracy_person_interaction: 1.0000 (0.9985)  time: 0.5066 (0.5087)  data: 0.0141 (0.0141)  lr: 0.000125  max mem: 2403
2022-04-26 16:37:59,585 alphaction.trainer INFO: eta: 5 days, 3:42:50  iter: 4580  loss_pose_action: 0.0001 (0.3820)  loss_object_interaction: 0.0000 (0.0005)  loss_person_interaction: 0.0000 (0.0005)  total_loss: 0.0008 (0.4898)  accuracy_pose_action: 1.0000 (0.8018)  accuracy_object_interaction: 1.0000 (0.9983)  accuracy_person_interaction: 1.0000 (0.9985)  time: 0.5128 (0.5088)  data: 0.0144 (0.0141)  lr: 0.000125  max mem: 2403
2022-04-26 16:38:09,823 alphaction.trainer INFO: eta: 5 days, 3:42:52  iter: 4600  loss_pose_action: 0.0001 (0.3805)  loss_object_interaction: 0.0000 (0.0005)  loss_person_interaction: 0.0000 (0.0005)  total_loss: 0.0008 (0.4879)  accuracy_pose_action: 1.0000 (0.8025)  accuracy_object_interaction: 1.0000 (0.9983)  accuracy_person_interaction: 1.0000 (0.9985)  time: 0.5135 (0.5088)  data: 0.0136 (0.0141)  lr: 0.000125  max mem: 2403
2022-04-26 16:38:09,826 alphaction.utils.checkpoint INFO: Saving checkpoint to data/output/resnet50_4x16f_baseline_robalo/model_0004600.pth
2022-04-26 16:38:10,084 alphaction.inference INFO: Start evaluation on lfv_robalo_val_ava_video dataset(135 videos).
2022-04-26 16:38:24,705 alphaction.inference INFO: Total inference time: 0:00:14.621182 (0.10830505159166125 s / video per device, on 1 devices)
2022-04-26 16:38:24,705 alphaction.inference INFO: performing ava evaluation.
2022-04-26 16:38:24,705 alphaction.inference INFO: Preparing results for AVA format
2022-04-26 16:38:24,722 alphaction.inference INFO: Evaluating predictions
2022-04-26 16:38:24,775 alphaction.inference INFO: ==> 0.0521393 seconds to write file /tmp/tmpewyhukbo
2022-04-26 16:38:24,775 alphaction.inference INFO: CATEGORIES (12):
[ {'id': 1, 'name': 'cut (an object)'},
  {'id': 2, 'name': 'holding for (a person)'},
  {'id': 3, 'name': 'handover to (a person)'},
  {'id': 4, 'name': 'squeeze (an object)'},
  {'id': 5, 'name': 'sprinkle (an object)'},
  {'id': 6, 'name': 'transfer (an object)'},
  {'id': 7, 'name': 'pour (an object)'},
  {'id': 8, 'name': 'heat (an object)'},
  {'id': 9, 'name': 'stir (an object)'},
  {'id': 10, 'name': 'wrap (an object)'},
  {'id': 11, 'name': 'roll (an object)'},
  {'id': 12, 'name': 'dip (an object)'}]
2022-04-26 16:38:24,776 alphaction.inference INFO: ==> 0.000471354 seconds to read file data/lfv_robalo/annotations/lfv_robalo_val.csv
2022-04-26 16:38:24,792 alphaction.inference INFO: ==> 0.0164461 seconds to convert groundtruth
2022-04-26 16:38:24,813 alphaction.inference INFO: ==> 0.020438 seconds to read file /tmp/tmpewyhukbo
2022-04-26 16:38:25,151 alphaction.inference INFO: ==> 0.337991 seconds to convert detections
2022-04-26 16:38:25,151 alphaction.inference INFO: The following classes have no ground truth examples: [ 2  3 10 11 12]
2022-04-26 16:38:25,155 alphaction.inference INFO: ==> 0.00405121 seconds to run_evaluator
2022-04-26 16:38:25,156 alphaction.inference INFO: { 'PascalBoxes_PerformanceByCategory/AP@0.5IOU/cut (an object)': 0.8118878972139842,
  'PascalBoxes_PerformanceByCategory/AP@0.5IOU/dip (an object)': nan,
  'PascalBoxes_PerformanceByCategory/AP@0.5IOU/handover to (a person)': nan,
  'PascalBoxes_PerformanceByCategory/AP@0.5IOU/heat (an object)': 0.7382417879367524,
  'PascalBoxes_PerformanceByCategory/AP@0.5IOU/holding for (a person)': nan,
  'PascalBoxes_PerformanceByCategory/AP@0.5IOU/pour (an object)': 0.1249831834375545,
  'PascalBoxes_PerformanceByCategory/AP@0.5IOU/roll (an object)': nan,
  'PascalBoxes_PerformanceByCategory/AP@0.5IOU/sprinkle (an object)': 0.034482758620689655,
  'PascalBoxes_PerformanceByCategory/AP@0.5IOU/squeeze (an object)': 0.07509157509157507,
  'PascalBoxes_PerformanceByCategory/AP@0.5IOU/stir (an object)': 0.4177155854481436,
  'PascalBoxes_PerformanceByCategory/AP@0.5IOU/transfer (an object)': 0.507786363565129,
  'PascalBoxes_PerformanceByCategory/AP@0.5IOU/wrap (an object)': nan,
  'PascalBoxes_Precision/mAP@0.5IOU': 0.38716987875911835}
2022-04-26 16:38:35,217 alphaction.trainer INFO: eta: 5 days, 3:42:20  iter: 4620  loss_pose_action: 0.0003 (0.3791)  loss_object_interaction: 0.0000 (0.0005)  loss_person_interaction: 0.0000 (0.0005)  total_loss: 0.0018 (0.4860)  accuracy_pose_action: 1.0000 (0.8030)  accuracy_object_interaction: 1.0000 (0.9983)  accuracy_person_interaction: 1.0000 (0.9985)  time: 0.5030 (0.5087)  data: 0.0139 (0.0141)  lr: 0.000125  max mem: 2403
2022-04-26 16:38:45,353 alphaction.trainer INFO: eta: 5 days, 3:42:02  iter: 4640  loss_pose_action: 0.0002 (0.3780)  loss_object_interaction: 0.0000 (0.0005)  loss_person_interaction: 0.0000 (0.0005)  total_loss: 0.0005 (0.4846)  accuracy_pose_action: 1.0000 (0.8034)  accuracy_object_interaction: 1.0000 (0.9983)  accuracy_person_interaction: 1.0000 (0.9985)  time: 0.5062 (0.5087)  data: 0.0143 (0.0141)  lr: 0.000125  max mem: 2403
2022-04-26 16:38:55,597 alphaction.trainer INFO: eta: 5 days, 3:42:05  iter: 4660  loss_pose_action: 0.0023 (0.3771)  loss_object_interaction: 0.0000 (0.0005)  loss_person_interaction: 0.0000 (0.0005)  total_loss: 0.0046 (0.4834)  accuracy_pose_action: 1.0000 (0.8038)  accuracy_object_interaction: 1.0000 (0.9983)  accuracy_person_interaction: 1.0000 (0.9985)  time: 0.5130 (0.5087)  data: 0.0140 (0.0141)  lr: 0.000125  max mem: 2403
2022-04-26 16:39:05,837 alphaction.trainer INFO: eta: 5 days, 3:42:07  iter: 4680  loss_pose_action: 0.0058 (0.3760)  loss_object_interaction: 0.0000 (0.0005)  loss_person_interaction: 0.0000 (0.0005)  total_loss: 0.0161 (0.4820)  accuracy_pose_action: 1.0000 (0.8044)  accuracy_object_interaction: 1.0000 (0.9983)  accuracy_person_interaction: 1.0000 (0.9985)  time: 0.5125 (0.5088)  data: 0.0144 (0.0141)  lr: 0.000125  max mem: 2403
2022-04-26 16:39:16,073 alphaction.trainer INFO: eta: 5 days, 3:42:08  iter: 4700  loss_pose_action: 0.0002 (0.3753)  loss_object_interaction: 0.0000 (0.0005)  loss_person_interaction: 0.0000 (0.0005)  total_loss: 0.0023 (0.4811)  accuracy_pose_action: 1.0000 (0.8049)  accuracy_object_interaction: 1.0000 (0.9983)  accuracy_person_interaction: 1.0000 (0.9985)  time: 0.5136 (0.5088)  data: 0.0142 (0.0141)  lr: 0.000125  max mem: 2403
2022-04-26 16:39:16,076 alphaction.utils.checkpoint INFO: Saving checkpoint to data/output/resnet50_4x16f_baseline_robalo/model_0004700.pth
2022-04-26 16:39:16,350 alphaction.inference INFO: Start evaluation on lfv_robalo_val_ava_video dataset(135 videos).
2022-04-26 16:39:31,241 alphaction.inference INFO: Total inference time: 0:00:14.891356 (0.11030634420889396 s / video per device, on 1 devices)
2022-04-26 16:39:31,241 alphaction.inference INFO: performing ava evaluation.
2022-04-26 16:39:31,241 alphaction.inference INFO: Preparing results for AVA format
2022-04-26 16:39:31,259 alphaction.inference INFO: Evaluating predictions
2022-04-26 16:39:31,310 alphaction.inference INFO: ==> 0.0508773 seconds to write file /tmp/tmpg9frq0_2
2022-04-26 16:39:31,310 alphaction.inference INFO: CATEGORIES (12):
[ {'id': 1, 'name': 'cut (an object)'},
  {'id': 2, 'name': 'holding for (a person)'},
  {'id': 3, 'name': 'handover to (a person)'},
  {'id': 4, 'name': 'squeeze (an object)'},
  {'id': 5, 'name': 'sprinkle (an object)'},
  {'id': 6, 'name': 'transfer (an object)'},
  {'id': 7, 'name': 'pour (an object)'},
  {'id': 8, 'name': 'heat (an object)'},
  {'id': 9, 'name': 'stir (an object)'},
  {'id': 10, 'name': 'wrap (an object)'},
  {'id': 11, 'name': 'roll (an object)'},
  {'id': 12, 'name': 'dip (an object)'}]
2022-04-26 16:39:31,311 alphaction.inference INFO: ==> 0.00049305 seconds to read file data/lfv_robalo/annotations/lfv_robalo_val.csv
2022-04-26 16:39:31,330 alphaction.inference INFO: ==> 0.0186877 seconds to convert groundtruth
2022-04-26 16:39:31,350 alphaction.inference INFO: ==> 0.0203452 seconds to read file /tmp/tmpg9frq0_2
2022-04-26 16:39:31,686 alphaction.inference INFO: ==> 0.334952 seconds to convert detections
2022-04-26 16:39:31,686 alphaction.inference INFO: The following classes have no ground truth examples: [ 2  3 10 11 12]
2022-04-26 16:39:31,688 alphaction.inference INFO: ==> 0.00275922 seconds to run_evaluator
2022-04-26 16:39:31,689 alphaction.inference INFO: { 'PascalBoxes_PerformanceByCategory/AP@0.5IOU/cut (an object)': 0.7129220497943334,
  'PascalBoxes_PerformanceByCategory/AP@0.5IOU/dip (an object)': nan,
  'PascalBoxes_PerformanceByCategory/AP@0.5IOU/handover to (a person)': nan,
  'PascalBoxes_PerformanceByCategory/AP@0.5IOU/heat (an object)': 0.7073471532139106,
  'PascalBoxes_PerformanceByCategory/AP@0.5IOU/holding for (a person)': nan,
  'PascalBoxes_PerformanceByCategory/AP@0.5IOU/pour (an object)': 0.15819964349376114,
  'PascalBoxes_PerformanceByCategory/AP@0.5IOU/roll (an object)': nan,
  'PascalBoxes_PerformanceByCategory/AP@0.5IOU/sprinkle (an object)': 0.0273972602739726,
  'PascalBoxes_PerformanceByCategory/AP@0.5IOU/squeeze (an object)': 0.08429931467757962,
  'PascalBoxes_PerformanceByCategory/AP@0.5IOU/stir (an object)': 0.6583024997493994,
  'PascalBoxes_PerformanceByCategory/AP@0.5IOU/transfer (an object)': 0.5485940759235847,
  'PascalBoxes_PerformanceByCategory/AP@0.5IOU/wrap (an object)': nan,
  'PascalBoxes_Precision/mAP@0.5IOU': 0.4138659995895059}
2022-04-26 16:39:41,703 alphaction.trainer INFO: eta: 5 days, 3:41:28  iter: 4720  loss_pose_action: 0.0011 (0.3739)  loss_object_interaction: 0.0000 (0.0005)  loss_person_interaction: 0.0000 (0.0005)  total_loss: 0.0094 (0.4794)  accuracy_pose_action: 1.0000 (0.8054)  accuracy_object_interaction: 1.0000 (0.9983)  accuracy_person_interaction: 1.0000 (0.9985)  time: 0.4975 (0.5087)  data: 0.0139 (0.0141)  lr: 0.000125  max mem: 2403
2022-04-26 16:39:51,848 alphaction.trainer INFO: eta: 5 days, 3:41:12  iter: 4740  loss_pose_action: 0.0002 (0.3725)  loss_object_interaction: 0.0000 (0.0005)  loss_person_interaction: 0.0000 (0.0005)  total_loss: 0.0040 (0.4775)  accuracy_pose_action: 1.0000 (0.8062)  accuracy_object_interaction: 1.0000 (0.9983)  accuracy_person_interaction: 1.0000 (0.9985)  time: 0.5049 (0.5087)  data: 0.0143 (0.0141)  lr: 0.000125  max mem: 2403
2022-04-26 16:40:02,055 alphaction.trainer INFO: eta: 5 days, 3:41:08  iter: 4760  loss_pose_action: 0.0010 (0.3710)  loss_object_interaction: 0.0000 (0.0005)  loss_person_interaction: 0.0000 (0.0005)  total_loss: 0.0052 (0.4756)  accuracy_pose_action: 1.0000 (0.8069)  accuracy_object_interaction: 1.0000 (0.9983)  accuracy_person_interaction: 1.0000 (0.9985)  time: 0.5129 (0.5087)  data: 0.0140 (0.0141)  lr: 0.000125  max mem: 2403
2022-04-26 16:40:12,291 alphaction.trainer INFO: eta: 5 days, 3:41:09  iter: 4780  loss_pose_action: 0.0000 (0.3698)  loss_object_interaction: 0.0000 (0.0005)  loss_person_interaction: 0.0000 (0.0005)  total_loss: 0.0007 (0.4740)  accuracy_pose_action: 1.0000 (0.8075)  accuracy_object_interaction: 1.0000 (0.9983)  accuracy_person_interaction: 1.0000 (0.9985)  time: 0.5150 (0.5088)  data: 0.0141 (0.0141)  lr: 0.000125  max mem: 2403
2022-04-26 16:40:22,548 alphaction.trainer INFO: eta: 5 days, 3:41:14  iter: 4800  loss_pose_action: 0.0001 (0.3686)  loss_object_interaction: 0.0000 (0.0005)  loss_person_interaction: 0.0000 (0.0005)  total_loss: 0.0049 (0.4726)  accuracy_pose_action: 1.0000 (0.8078)  accuracy_object_interaction: 1.0000 (0.9983)  accuracy_person_interaction: 1.0000 (0.9985)  time: 0.5135 (0.5088)  data: 0.0140 (0.0141)  lr: 0.000125  max mem: 2403
2022-04-26 16:40:22,551 alphaction.utils.checkpoint INFO: Saving checkpoint to data/output/resnet50_4x16f_baseline_robalo/model_0004800.pth
2022-04-26 16:40:22,818 alphaction.inference INFO: Start evaluation on lfv_robalo_val_ava_video dataset(135 videos).
2022-04-26 16:40:37,587 alphaction.inference INFO: Total inference time: 0:00:14.769182 (0.10940134790208604 s / video per device, on 1 devices)
2022-04-26 16:40:37,587 alphaction.inference INFO: performing ava evaluation.
2022-04-26 16:40:37,589 alphaction.inference INFO: Preparing results for AVA format
2022-04-26 16:40:37,610 alphaction.inference INFO: Evaluating predictions
2022-04-26 16:40:37,678 alphaction.inference INFO: ==> 0.0674729 seconds to write file /tmp/tmpk0zslsp6
2022-04-26 16:40:37,678 alphaction.inference INFO: CATEGORIES (12):
[ {'id': 1, 'name': 'cut (an object)'},
  {'id': 2, 'name': 'holding for (a person)'},
  {'id': 3, 'name': 'handover to (a person)'},
  {'id': 4, 'name': 'squeeze (an object)'},
  {'id': 5, 'name': 'sprinkle (an object)'},
  {'id': 6, 'name': 'transfer (an object)'},
  {'id': 7, 'name': 'pour (an object)'},
  {'id': 8, 'name': 'heat (an object)'},
  {'id': 9, 'name': 'stir (an object)'},
  {'id': 10, 'name': 'wrap (an object)'},
  {'id': 11, 'name': 'roll (an object)'},
  {'id': 12, 'name': 'dip (an object)'}]
2022-04-26 16:40:37,678 alphaction.inference INFO: ==> 0.000461102 seconds to read file data/lfv_robalo/annotations/lfv_robalo_val.csv
2022-04-26 16:40:37,695 alphaction.inference INFO: ==> 0.016593 seconds to convert groundtruth
2022-04-26 16:40:37,715 alphaction.inference INFO: ==> 0.0193617 seconds to read file /tmp/tmpk0zslsp6
2022-04-26 16:40:38,056 alphaction.inference INFO: ==> 0.340822 seconds to convert detections
2022-04-26 16:40:38,056 alphaction.inference INFO: The following classes have no ground truth examples: [ 2  3 10 11 12]
2022-04-26 16:40:38,058 alphaction.inference INFO: ==> 0.00274563 seconds to run_evaluator
2022-04-26 16:40:38,059 alphaction.inference INFO: { 'PascalBoxes_PerformanceByCategory/AP@0.5IOU/cut (an object)': 0.5475001233050042,
  'PascalBoxes_PerformanceByCategory/AP@0.5IOU/dip (an object)': nan,
  'PascalBoxes_PerformanceByCategory/AP@0.5IOU/handover to (a person)': nan,
  'PascalBoxes_PerformanceByCategory/AP@0.5IOU/heat (an object)': 0.6665611858381274,
  'PascalBoxes_PerformanceByCategory/AP@0.5IOU/holding for (a person)': nan,
  'PascalBoxes_PerformanceByCategory/AP@0.5IOU/pour (an object)': 0.0851063829787234,
  'PascalBoxes_PerformanceByCategory/AP@0.5IOU/roll (an object)': nan,
  'PascalBoxes_PerformanceByCategory/AP@0.5IOU/sprinkle (an object)': 0.043478260869565216,
  'PascalBoxes_PerformanceByCategory/AP@0.5IOU/squeeze (an object)': 0.14452174809317664,
  'PascalBoxes_PerformanceByCategory/AP@0.5IOU/stir (an object)': 0.5600239383258251,
  'PascalBoxes_PerformanceByCategory/AP@0.5IOU/transfer (an object)': 0.4293123985684843,
  'PascalBoxes_PerformanceByCategory/AP@0.5IOU/wrap (an object)': nan,
  'PascalBoxes_Precision/mAP@0.5IOU': 0.3537862911398438}
2022-04-26 16:40:48,112 alphaction.trainer INFO: eta: 5 days, 3:40:41  iter: 4820  loss_pose_action: 0.0005 (0.3677)  loss_object_interaction: 0.0000 (0.0005)  loss_person_interaction: 0.0000 (0.0005)  total_loss: 0.0030 (0.4713)  accuracy_pose_action: 1.0000 (0.8082)  accuracy_object_interaction: 1.0000 (0.9983)  accuracy_person_interaction: 1.0000 (0.9985)  time: 0.5014 (0.5087)  data: 0.0137 (0.0141)  lr: 0.000125  max mem: 2403
2022-04-26 16:40:58,267 alphaction.trainer INFO: eta: 5 days, 3:40:27  iter: 4840  loss_pose_action: 0.0000 (0.3663)  loss_object_interaction: 0.0000 (0.0004)  loss_person_interaction: 0.0000 (0.0005)  total_loss: 0.0015 (0.4695)  accuracy_pose_action: 1.0000 (0.8090)  accuracy_object_interaction: 1.0000 (0.9983)  accuracy_person_interaction: 1.0000 (0.9986)  time: 0.5108 (0.5087)  data: 0.0144 (0.0141)  lr: 0.000125  max mem: 2403
2022-04-26 16:41:08,498 alphaction.trainer INFO: eta: 5 days, 3:40:27  iter: 4860  loss_pose_action: 0.0000 (0.3650)  loss_object_interaction: 0.0000 (0.0004)  loss_person_interaction: 0.0000 (0.0005)  total_loss: 0.0014 (0.4678)  accuracy_pose_action: 1.0000 (0.8097)  accuracy_object_interaction: 1.0000 (0.9984)  accuracy_person_interaction: 1.0000 (0.9986)  time: 0.5128 (0.5088)  data: 0.0141 (0.0141)  lr: 0.000125  max mem: 2403
2022-04-26 16:41:18,748 alphaction.trainer INFO: eta: 5 days, 3:40:30  iter: 4880  loss_pose_action: 0.0001 (0.3637)  loss_object_interaction: 0.0000 (0.0004)  loss_person_interaction: 0.0000 (0.0005)  total_loss: 0.0018 (0.4662)  accuracy_pose_action: 1.0000 (0.8102)  accuracy_object_interaction: 1.0000 (0.9984)  accuracy_person_interaction: 1.0000 (0.9986)  time: 0.5125 (0.5088)  data: 0.0144 (0.0141)  lr: 0.000125  max mem: 2403
2022-04-26 16:41:28,994 alphaction.trainer INFO: eta: 5 days, 3:40:33  iter: 4900  loss_pose_action: 0.0028 (0.3626)  loss_object_interaction: 0.0000 (0.0004)  loss_person_interaction: 0.0000 (0.0005)  total_loss: 0.0131 (0.4647)  accuracy_pose_action: 1.0000 (0.8106)  accuracy_object_interaction: 1.0000 (0.9984)  accuracy_person_interaction: 1.0000 (0.9986)  time: 0.5119 (0.5088)  data: 0.0142 (0.0141)  lr: 0.000125  max mem: 2403
2022-04-26 16:41:28,997 alphaction.utils.checkpoint INFO: Saving checkpoint to data/output/resnet50_4x16f_baseline_robalo/model_0004900.pth
2022-04-26 16:41:29,278 alphaction.inference INFO: Start evaluation on lfv_robalo_val_ava_video dataset(135 videos).
2022-04-26 16:41:44,049 alphaction.inference INFO: Total inference time: 0:00:14.770748 (0.10941294564141167 s / video per device, on 1 devices)
2022-04-26 16:41:44,050 alphaction.inference INFO: performing ava evaluation.
2022-04-26 16:41:44,050 alphaction.inference INFO: Preparing results for AVA format
2022-04-26 16:41:44,071 alphaction.inference INFO: Evaluating predictions
2022-04-26 16:41:44,128 alphaction.inference INFO: ==> 0.0570526 seconds to write file /tmp/tmpriwzg_q7
2022-04-26 16:41:44,128 alphaction.inference INFO: CATEGORIES (12):
[ {'id': 1, 'name': 'cut (an object)'},
  {'id': 2, 'name': 'holding for (a person)'},
  {'id': 3, 'name': 'handover to (a person)'},
  {'id': 4, 'name': 'squeeze (an object)'},
  {'id': 5, 'name': 'sprinkle (an object)'},
  {'id': 6, 'name': 'transfer (an object)'},
  {'id': 7, 'name': 'pour (an object)'},
  {'id': 8, 'name': 'heat (an object)'},
  {'id': 9, 'name': 'stir (an object)'},
  {'id': 10, 'name': 'wrap (an object)'},
  {'id': 11, 'name': 'roll (an object)'},
  {'id': 12, 'name': 'dip (an object)'}]
2022-04-26 16:41:44,129 alphaction.inference INFO: ==> 0.00046277 seconds to read file data/lfv_robalo/annotations/lfv_robalo_val.csv
2022-04-26 16:41:44,146 alphaction.inference INFO: ==> 0.0170038 seconds to convert groundtruth
2022-04-26 16:41:44,166 alphaction.inference INFO: ==> 0.0200415 seconds to read file /tmp/tmpriwzg_q7
2022-04-26 16:41:44,503 alphaction.inference INFO: ==> 0.336543 seconds to convert detections
2022-04-26 16:41:44,503 alphaction.inference INFO: The following classes have no ground truth examples: [ 2  3 10 11 12]
2022-04-26 16:41:44,506 alphaction.inference INFO: ==> 0.00280213 seconds to run_evaluator
2022-04-26 16:41:44,507 alphaction.inference INFO: { 'PascalBoxes_PerformanceByCategory/AP@0.5IOU/cut (an object)': 0.6481022075296241,
  'PascalBoxes_PerformanceByCategory/AP@0.5IOU/dip (an object)': nan,
  'PascalBoxes_PerformanceByCategory/AP@0.5IOU/handover to (a person)': nan,
  'PascalBoxes_PerformanceByCategory/AP@0.5IOU/heat (an object)': 0.7140840425070685,
  'PascalBoxes_PerformanceByCategory/AP@0.5IOU/holding for (a person)': nan,
  'PascalBoxes_PerformanceByCategory/AP@0.5IOU/pour (an object)': 0.13834586466165413,
  'PascalBoxes_PerformanceByCategory/AP@0.5IOU/roll (an object)': nan,
  'PascalBoxes_PerformanceByCategory/AP@0.5IOU/sprinkle (an object)': 0.024691358024691357,
  'PascalBoxes_PerformanceByCategory/AP@0.5IOU/squeeze (an object)': 0.06387301587301587,
  'PascalBoxes_PerformanceByCategory/AP@0.5IOU/stir (an object)': 0.5365800865800866,
  'PascalBoxes_PerformanceByCategory/AP@0.5IOU/transfer (an object)': 0.425180469400144,
  'PascalBoxes_PerformanceByCategory/AP@0.5IOU/wrap (an object)': nan,
  'PascalBoxes_Precision/mAP@0.5IOU': 0.36440814922518344}
2022-04-26 16:41:54,568 alphaction.trainer INFO: eta: 5 days, 3:40:02  iter: 4920  loss_pose_action: 0.0001 (0.3615)  loss_object_interaction: 0.0000 (0.0004)  loss_person_interaction: 0.0000 (0.0005)  total_loss: 0.0020 (0.4634)  accuracy_pose_action: 1.0000 (0.8111)  accuracy_object_interaction: 1.0000 (0.9984)  accuracy_person_interaction: 1.0000 (0.9986)  time: 0.5009 (0.5088)  data: 0.0137 (0.0141)  lr: 0.000125  max mem: 2403
2022-04-26 16:42:04,735 alphaction.trainer INFO: eta: 5 days, 3:39:50  iter: 4940  loss_pose_action: 0.0014 (0.3608)  loss_object_interaction: 0.0000 (0.0004)  loss_person_interaction: 0.0000 (0.0005)  total_loss: 0.0082 (0.4623)  accuracy_pose_action: 1.0000 (0.8114)  accuracy_object_interaction: 1.0000 (0.9984)  accuracy_person_interaction: 1.0000 (0.9986)  time: 0.5124 (0.5088)  data: 0.0143 (0.0141)  lr: 0.000125  max mem: 2403
2022-04-26 16:42:14,918 alphaction.trainer INFO: eta: 5 days, 3:39:42  iter: 4960  loss_pose_action: 0.0037 (0.3596)  loss_object_interaction: 0.0000 (0.0004)  loss_person_interaction: 0.0000 (0.0005)  total_loss: 0.0139 (0.4608)  accuracy_pose_action: 1.0000 (0.8117)  accuracy_object_interaction: 1.0000 (0.9984)  accuracy_person_interaction: 1.0000 (0.9986)  time: 0.5112 (0.5088)  data: 0.0144 (0.0141)  lr: 0.000125  max mem: 2403
2022-04-26 16:42:25,145 alphaction.trainer INFO: eta: 5 days, 3:39:41  iter: 4980  loss_pose_action: 0.0003 (0.3583)  loss_object_interaction: 0.0000 (0.0004)  loss_person_interaction: 0.0000 (0.0005)  total_loss: 0.0018 (0.4592)  accuracy_pose_action: 1.0000 (0.8124)  accuracy_object_interaction: 1.0000 (0.9984)  accuracy_person_interaction: 1.0000 (0.9986)  time: 0.5165 (0.5088)  data: 0.0138 (0.0141)  lr: 0.000125  max mem: 2403
2022-04-26 16:42:35,337 alphaction.trainer INFO: eta: 5 days, 3:39:33  iter: 5000  loss_pose_action: 0.0001 (0.3570)  loss_object_interaction: 0.0000 (0.0004)  loss_person_interaction: 0.0000 (0.0005)  total_loss: 0.0020 (0.4574)  accuracy_pose_action: 1.0000 (0.8131)  accuracy_object_interaction: 1.0000 (0.9984)  accuracy_person_interaction: 1.0000 (0.9986)  time: 0.5140 (0.5088)  data: 0.0149 (0.0141)  lr: 0.000125  max mem: 2403
2022-04-26 16:42:35,340 alphaction.utils.checkpoint INFO: Saving checkpoint to data/output/resnet50_4x16f_baseline_robalo/model_0005000.pth
2022-04-26 16:42:35,613 alphaction.inference INFO: Start evaluation on lfv_robalo_val_ava_video dataset(135 videos).
2022-04-26 16:42:50,345 alphaction.inference INFO: Total inference time: 0:00:14.732198 (0.10912739435831706 s / video per device, on 1 devices)
2022-04-26 16:42:50,345 alphaction.inference INFO: performing ava evaluation.
2022-04-26 16:42:50,345 alphaction.inference INFO: Preparing results for AVA format
2022-04-26 16:42:50,362 alphaction.inference INFO: Evaluating predictions
2022-04-26 16:42:50,412 alphaction.inference INFO: ==> 0.0495973 seconds to write file /tmp/tmpikcpefio
2022-04-26 16:42:50,412 alphaction.inference INFO: CATEGORIES (12):
[ {'id': 1, 'name': 'cut (an object)'},
  {'id': 2, 'name': 'holding for (a person)'},
  {'id': 3, 'name': 'handover to (a person)'},
  {'id': 4, 'name': 'squeeze (an object)'},
  {'id': 5, 'name': 'sprinkle (an object)'},
  {'id': 6, 'name': 'transfer (an object)'},
  {'id': 7, 'name': 'pour (an object)'},
  {'id': 8, 'name': 'heat (an object)'},
  {'id': 9, 'name': 'stir (an object)'},
  {'id': 10, 'name': 'wrap (an object)'},
  {'id': 11, 'name': 'roll (an object)'},
  {'id': 12, 'name': 'dip (an object)'}]
2022-04-26 16:42:50,413 alphaction.inference INFO: ==> 0.000519037 seconds to read file data/lfv_robalo/annotations/lfv_robalo_val.csv
2022-04-26 16:42:50,430 alphaction.inference INFO: ==> 0.0173073 seconds to convert groundtruth
2022-04-26 16:42:50,449 alphaction.inference INFO: ==> 0.0191765 seconds to read file /tmp/tmpikcpefio
2022-04-26 16:42:50,787 alphaction.inference INFO: ==> 0.337543 seconds to convert detections
2022-04-26 16:42:50,787 alphaction.inference INFO: The following classes have no ground truth examples: [ 2  3 10 11 12]
2022-04-26 16:42:50,790 alphaction.inference INFO: ==> 0.00285506 seconds to run_evaluator
2022-04-26 16:42:50,791 alphaction.inference INFO: { 'PascalBoxes_PerformanceByCategory/AP@0.5IOU/cut (an object)': 0.7037798405061831,
  'PascalBoxes_PerformanceByCategory/AP@0.5IOU/dip (an object)': nan,
  'PascalBoxes_PerformanceByCategory/AP@0.5IOU/handover to (a person)': nan,
  'PascalBoxes_PerformanceByCategory/AP@0.5IOU/heat (an object)': 0.7240479378215591,
  'PascalBoxes_PerformanceByCategory/AP@0.5IOU/holding for (a person)': nan,
  'PascalBoxes_PerformanceByCategory/AP@0.5IOU/pour (an object)': 0.06674082313681869,
  'PascalBoxes_PerformanceByCategory/AP@0.5IOU/roll (an object)': nan,
  'PascalBoxes_PerformanceByCategory/AP@0.5IOU/sprinkle (an object)': 0.046511627906976744,
  'PascalBoxes_PerformanceByCategory/AP@0.5IOU/squeeze (an object)': 0.20108225108225108,
  'PascalBoxes_PerformanceByCategory/AP@0.5IOU/stir (an object)': 0.46616092618814947,
  'PascalBoxes_PerformanceByCategory/AP@0.5IOU/transfer (an object)': 0.42498236252296145,
  'PascalBoxes_PerformanceByCategory/AP@0.5IOU/wrap (an object)': nan,
  'PascalBoxes_Precision/mAP@0.5IOU': 0.3761865384521285}
2022-04-26 16:43:00,915 alphaction.trainer INFO: eta: 5 days, 3:39:14  iter: 5020  loss_pose_action: 0.0001 (0.3557)  loss_object_interaction: 0.0000 (0.0004)  loss_person_interaction: 0.0000 (0.0005)  total_loss: 0.0008 (0.4559)  accuracy_pose_action: 1.0000 (0.8136)  accuracy_object_interaction: 1.0000 (0.9984)  accuracy_person_interaction: 1.0000 (0.9986)  time: 0.5041 (0.5088)  data: 0.0140 (0.0141)  lr: 0.000125  max mem: 2403
2022-04-26 16:43:11,084 alphaction.trainer INFO: eta: 5 days, 3:39:02  iter: 5040  loss_pose_action: 0.0001 (0.3544)  loss_object_interaction: 0.0000 (0.0004)  loss_person_interaction: 0.0000 (0.0005)  total_loss: 0.0011 (0.4541)  accuracy_pose_action: 1.0000 (0.8143)  accuracy_object_interaction: 1.0000 (0.9984)  accuracy_person_interaction: 1.0000 (0.9986)  time: 0.5132 (0.5088)  data: 0.0136 (0.0141)  lr: 0.000125  max mem: 2403
2022-04-26 16:43:21,326 alphaction.trainer INFO: eta: 5 days, 3:39:04  iter: 5060  loss_pose_action: 0.0000 (0.3530)  loss_object_interaction: 0.0000 (0.0004)  loss_person_interaction: 0.0000 (0.0004)  total_loss: 0.0011 (0.4524)  accuracy_pose_action: 1.0000 (0.8150)  accuracy_object_interaction: 1.0000 (0.9984)  accuracy_person_interaction: 1.0000 (0.9986)  time: 0.5119 (0.5088)  data: 0.0141 (0.0141)  lr: 0.000125  max mem: 2403
2022-04-26 16:43:31,554 alphaction.trainer INFO: eta: 5 days, 3:39:03  iter: 5080  loss_pose_action: 0.0000 (0.3517)  loss_object_interaction: 0.0000 (0.0004)  loss_person_interaction: 0.0000 (0.0004)  total_loss: 0.0004 (0.4507)  accuracy_pose_action: 1.0000 (0.8157)  accuracy_object_interaction: 1.0000 (0.9984)  accuracy_person_interaction: 1.0000 (0.9986)  time: 0.5130 (0.5088)  data: 0.0144 (0.0141)  lr: 0.000125  max mem: 2403
2022-04-26 16:43:41,792 alphaction.trainer INFO: eta: 5 days, 3:39:03  iter: 5100  loss_pose_action: 0.0000 (0.3504)  loss_object_interaction: 0.0000 (0.0004)  loss_person_interaction: 0.0000 (0.0004)  total_loss: 0.0002 (0.4491)  accuracy_pose_action: 1.0000 (0.8164)  accuracy_object_interaction: 1.0000 (0.9984)  accuracy_person_interaction: 1.0000 (0.9986)  time: 0.5136 (0.5088)  data: 0.0144 (0.0141)  lr: 0.000125  max mem: 2403
2022-04-26 16:43:41,796 alphaction.utils.checkpoint INFO: Saving checkpoint to data/output/resnet50_4x16f_baseline_robalo/model_0005100.pth
2022-04-26 16:43:42,056 alphaction.inference INFO: Start evaluation on lfv_robalo_val_ava_video dataset(135 videos).
2022-04-26 16:43:56,590 alphaction.inference INFO: Total inference time: 0:00:14.533422 (0.10765497596175583 s / video per device, on 1 devices)
2022-04-26 16:43:56,590 alphaction.inference INFO: performing ava evaluation.
2022-04-26 16:43:56,590 alphaction.inference INFO: Preparing results for AVA format
2022-04-26 16:43:56,607 alphaction.inference INFO: Evaluating predictions
2022-04-26 16:43:56,656 alphaction.inference INFO: ==> 0.0491261 seconds to write file /tmp/tmpbjroqlfg
2022-04-26 16:43:56,656 alphaction.inference INFO: CATEGORIES (12):
[ {'id': 1, 'name': 'cut (an object)'},
  {'id': 2, 'name': 'holding for (a person)'},
  {'id': 3, 'name': 'handover to (a person)'},
  {'id': 4, 'name': 'squeeze (an object)'},
  {'id': 5, 'name': 'sprinkle (an object)'},
  {'id': 6, 'name': 'transfer (an object)'},
  {'id': 7, 'name': 'pour (an object)'},
  {'id': 8, 'name': 'heat (an object)'},
  {'id': 9, 'name': 'stir (an object)'},
  {'id': 10, 'name': 'wrap (an object)'},
  {'id': 11, 'name': 'roll (an object)'},
  {'id': 12, 'name': 'dip (an object)'}]
2022-04-26 16:43:56,657 alphaction.inference INFO: ==> 0.000812531 seconds to read file data/lfv_robalo/annotations/lfv_robalo_val.csv
2022-04-26 16:43:56,675 alphaction.inference INFO: ==> 0.0173452 seconds to convert groundtruth
2022-04-26 16:43:56,694 alphaction.inference INFO: ==> 0.0192556 seconds to read file /tmp/tmpbjroqlfg
2022-04-26 16:43:57,028 alphaction.inference INFO: ==> 0.333156 seconds to convert detections
2022-04-26 16:43:57,028 alphaction.inference INFO: The following classes have no ground truth examples: [ 2  3 10 11 12]
2022-04-26 16:43:57,030 alphaction.inference INFO: ==> 0.00276184 seconds to run_evaluator
2022-04-26 16:43:57,031 alphaction.inference INFO: { 'PascalBoxes_PerformanceByCategory/AP@0.5IOU/cut (an object)': 0.783585341433255,
  'PascalBoxes_PerformanceByCategory/AP@0.5IOU/dip (an object)': nan,
  'PascalBoxes_PerformanceByCategory/AP@0.5IOU/handover to (a person)': nan,
  'PascalBoxes_PerformanceByCategory/AP@0.5IOU/heat (an object)': 0.6726567192553302,
  'PascalBoxes_PerformanceByCategory/AP@0.5IOU/holding for (a person)': nan,
  'PascalBoxes_PerformanceByCategory/AP@0.5IOU/pour (an object)': 0.13376193259302552,
  'PascalBoxes_PerformanceByCategory/AP@0.5IOU/roll (an object)': nan,
  'PascalBoxes_PerformanceByCategory/AP@0.5IOU/sprinkle (an object)': 0.05128205128205128,
  'PascalBoxes_PerformanceByCategory/AP@0.5IOU/squeeze (an object)': 0.10598089060851315,
  'PascalBoxes_PerformanceByCategory/AP@0.5IOU/stir (an object)': 0.357962216909214,
  'PascalBoxes_PerformanceByCategory/AP@0.5IOU/transfer (an object)': 0.5210284495148918,
  'PascalBoxes_PerformanceByCategory/AP@0.5IOU/wrap (an object)': nan,
  'PascalBoxes_Precision/mAP@0.5IOU': 0.3751796573708973}
2022-04-26 16:44:07,105 alphaction.trainer INFO: eta: 5 days, 3:38:35  iter: 5120  loss_pose_action: 0.0005 (0.3492)  loss_object_interaction: 0.0000 (0.0004)  loss_person_interaction: 0.0000 (0.0004)  total_loss: 0.0018 (0.4476)  accuracy_pose_action: 1.0000 (0.8170)  accuracy_object_interaction: 1.0000 (0.9984)  accuracy_person_interaction: 1.0000 (0.9986)  time: 0.5001 (0.5088)  data: 0.0138 (0.0141)  lr: 0.000125  max mem: 2403
2022-04-26 16:44:17,247 alphaction.trainer INFO: eta: 5 days, 3:38:19  iter: 5140  loss_pose_action: 0.0000 (0.3479)  loss_object_interaction: 0.0000 (0.0004)  loss_person_interaction: 0.0000 (0.0004)  total_loss: 0.0002 (0.4458)  accuracy_pose_action: 1.0000 (0.8177)  accuracy_object_interaction: 1.0000 (0.9984)  accuracy_person_interaction: 1.0000 (0.9986)  time: 0.5118 (0.5088)  data: 0.0141 (0.0141)  lr: 0.000125  max mem: 2403
2022-04-26 16:44:27,472 alphaction.trainer INFO: eta: 5 days, 3:38:18  iter: 5160  loss_pose_action: 0.0001 (0.3466)  loss_object_interaction: 0.0000 (0.0004)  loss_person_interaction: 0.0000 (0.0004)  total_loss: 0.0006 (0.4442)  accuracy_pose_action: 1.0000 (0.8184)  accuracy_object_interaction: 1.0000 (0.9984)  accuracy_person_interaction: 1.0000 (0.9986)  time: 0.5113 (0.5088)  data: 0.0137 (0.0141)  lr: 0.000125  max mem: 2403
2022-04-26 16:44:37,713 alphaction.trainer INFO: eta: 5 days, 3:38:19  iter: 5180  loss_pose_action: 0.0000 (0.3453)  loss_object_interaction: 0.0000 (0.0004)  loss_person_interaction: 0.0000 (0.0004)  total_loss: 0.0001 (0.4425)  accuracy_pose_action: 1.0000 (0.8191)  accuracy_object_interaction: 1.0000 (0.9985)  accuracy_person_interaction: 1.0000 (0.9986)  time: 0.5123 (0.5088)  data: 0.0141 (0.0141)  lr: 0.000125  max mem: 2403
2022-04-26 16:44:47,952 alphaction.trainer INFO: eta: 5 days, 3:38:19  iter: 5200  loss_pose_action: 0.0000 (0.3441)  loss_object_interaction: 0.0000 (0.0004)  loss_person_interaction: 0.0000 (0.0004)  total_loss: 0.0003 (0.4410)  accuracy_pose_action: 1.0000 (0.8197)  accuracy_object_interaction: 1.0000 (0.9985)  accuracy_person_interaction: 1.0000 (0.9987)  time: 0.5114 (0.5088)  data: 0.0141 (0.0141)  lr: 0.000125  max mem: 2403
2022-04-26 16:44:47,956 alphaction.utils.checkpoint INFO: Saving checkpoint to data/output/resnet50_4x16f_baseline_robalo/model_0005200.pth
2022-04-26 16:44:48,224 alphaction.inference INFO: Start evaluation on lfv_robalo_val_ava_video dataset(135 videos).
2022-04-26 16:45:02,917 alphaction.inference INFO: Total inference time: 0:00:14.692871 (0.10883608040986238 s / video per device, on 1 devices)
2022-04-26 16:45:02,917 alphaction.inference INFO: performing ava evaluation.
2022-04-26 16:45:02,917 alphaction.inference INFO: Preparing results for AVA format
2022-04-26 16:45:02,934 alphaction.inference INFO: Evaluating predictions
2022-04-26 16:45:02,983 alphaction.inference INFO: ==> 0.0494294 seconds to write file /tmp/tmprubb7ma9
2022-04-26 16:45:02,984 alphaction.inference INFO: CATEGORIES (12):
[ {'id': 1, 'name': 'cut (an object)'},
  {'id': 2, 'name': 'holding for (a person)'},
  {'id': 3, 'name': 'handover to (a person)'},
  {'id': 4, 'name': 'squeeze (an object)'},
  {'id': 5, 'name': 'sprinkle (an object)'},
  {'id': 6, 'name': 'transfer (an object)'},
  {'id': 7, 'name': 'pour (an object)'},
  {'id': 8, 'name': 'heat (an object)'},
  {'id': 9, 'name': 'stir (an object)'},
  {'id': 10, 'name': 'wrap (an object)'},
  {'id': 11, 'name': 'roll (an object)'},
  {'id': 12, 'name': 'dip (an object)'}]
2022-04-26 16:45:02,984 alphaction.inference INFO: ==> 0.000417948 seconds to read file data/lfv_robalo/annotations/lfv_robalo_val.csv
2022-04-26 16:45:03,002 alphaction.inference INFO: ==> 0.0180011 seconds to convert groundtruth
2022-04-26 16:45:03,022 alphaction.inference INFO: ==> 0.0193713 seconds to read file /tmp/tmprubb7ma9
2022-04-26 16:45:03,360 alphaction.inference INFO: ==> 0.338183 seconds to convert detections
2022-04-26 16:45:03,360 alphaction.inference INFO: The following classes have no ground truth examples: [ 2  3 10 11 12]
2022-04-26 16:45:03,363 alphaction.inference INFO: ==> 0.00281262 seconds to run_evaluator
2022-04-26 16:45:03,364 alphaction.inference INFO: { 'PascalBoxes_PerformanceByCategory/AP@0.5IOU/cut (an object)': 0.7541555334034807,
  'PascalBoxes_PerformanceByCategory/AP@0.5IOU/dip (an object)': nan,
  'PascalBoxes_PerformanceByCategory/AP@0.5IOU/handover to (a person)': nan,
  'PascalBoxes_PerformanceByCategory/AP@0.5IOU/heat (an object)': 0.7077288358946081,
  'PascalBoxes_PerformanceByCategory/AP@0.5IOU/holding for (a person)': nan,
  'PascalBoxes_PerformanceByCategory/AP@0.5IOU/pour (an object)': 0.1228030303030303,
  'PascalBoxes_PerformanceByCategory/AP@0.5IOU/roll (an object)': nan,
  'PascalBoxes_PerformanceByCategory/AP@0.5IOU/sprinkle (an object)': 0.038461538461538464,
  'PascalBoxes_PerformanceByCategory/AP@0.5IOU/squeeze (an object)': 0.09539371304077185,
  'PascalBoxes_PerformanceByCategory/AP@0.5IOU/stir (an object)': 0.4811464211464212,
  'PascalBoxes_PerformanceByCategory/AP@0.5IOU/transfer (an object)': 0.4277733835344829,
  'PascalBoxes_PerformanceByCategory/AP@0.5IOU/wrap (an object)': nan,
  'PascalBoxes_Precision/mAP@0.5IOU': 0.37535177939776193}
2022-04-26 16:45:13,441 alphaction.trainer INFO: eta: 5 days, 3:37:52  iter: 5220  loss_pose_action: 0.0000 (0.3432)  loss_object_interaction: 0.0000 (0.0004)  loss_person_interaction: 0.0000 (0.0004)  total_loss: 0.0007 (0.4398)  accuracy_pose_action: 1.0000 (0.8201)  accuracy_object_interaction: 1.0000 (0.9985)  accuracy_person_interaction: 1.0000 (0.9987)  time: 0.5028 (0.5088)  data: 0.0141 (0.0141)  lr: 0.000125  max mem: 2403
2022-04-26 16:45:23,608 alphaction.trainer INFO: eta: 5 days, 3:37:40  iter: 5240  loss_pose_action: 0.0003 (0.3420)  loss_object_interaction: 0.0000 (0.0004)  loss_person_interaction: 0.0000 (0.0004)  total_loss: 0.0010 (0.4382)  accuracy_pose_action: 1.0000 (0.8208)  accuracy_object_interaction: 1.0000 (0.9985)  accuracy_person_interaction: 1.0000 (0.9987)  time: 0.5105 (0.5088)  data: 0.0140 (0.0141)  lr: 0.000125  max mem: 2403
2022-04-26 16:45:33,832 alphaction.trainer INFO: eta: 5 days, 3:37:38  iter: 5260  loss_pose_action: 0.0000 (0.3410)  loss_object_interaction: 0.0000 (0.0004)  loss_person_interaction: 0.0000 (0.0004)  total_loss: 0.0002 (0.4369)  accuracy_pose_action: 1.0000 (0.8213)  accuracy_object_interaction: 1.0000 (0.9985)  accuracy_person_interaction: 1.0000 (0.9987)  time: 0.5126 (0.5088)  data: 0.0142 (0.0141)  lr: 0.000125  max mem: 2403
2022-04-26 16:45:44,065 alphaction.trainer INFO: eta: 5 days, 3:37:37  iter: 5280  loss_pose_action: 0.0001 (0.3399)  loss_object_interaction: 0.0000 (0.0004)  loss_person_interaction: 0.0000 (0.0004)  total_loss: 0.0008 (0.4355)  accuracy_pose_action: 1.0000 (0.8219)  accuracy_object_interaction: 1.0000 (0.9985)  accuracy_person_interaction: 1.0000 (0.9987)  time: 0.5130 (0.5088)  data: 0.0143 (0.0141)  lr: 0.000125  max mem: 2403
2022-04-26 16:45:54,303 alphaction.trainer INFO: eta: 5 days, 3:37:37  iter: 5300  loss_pose_action: 0.0000 (0.3390)  loss_object_interaction: 0.0000 (0.0004)  loss_person_interaction: 0.0000 (0.0004)  total_loss: 0.0011 (0.4344)  accuracy_pose_action: 1.0000 (0.8224)  accuracy_object_interaction: 1.0000 (0.9985)  accuracy_person_interaction: 1.0000 (0.9987)  time: 0.5124 (0.5088)  data: 0.0146 (0.0141)  lr: 0.000125  max mem: 2403
2022-04-26 16:45:54,306 alphaction.utils.checkpoint INFO: Saving checkpoint to data/output/resnet50_4x16f_baseline_robalo/model_0005300.pth
2022-04-26 16:45:54,571 alphaction.inference INFO: Start evaluation on lfv_robalo_val_ava_video dataset(135 videos).
2022-04-26 16:46:09,545 alphaction.inference INFO: Total inference time: 0:00:14.973615 (0.11091566615634495 s / video per device, on 1 devices)
2022-04-26 16:46:09,545 alphaction.inference INFO: performing ava evaluation.
2022-04-26 16:46:09,545 alphaction.inference INFO: Preparing results for AVA format
2022-04-26 16:46:09,564 alphaction.inference INFO: Evaluating predictions
2022-04-26 16:46:09,638 alphaction.inference INFO: ==> 0.0739286 seconds to write file /tmp/tmpxkvq49o8
2022-04-26 16:46:09,638 alphaction.inference INFO: CATEGORIES (12):
[ {'id': 1, 'name': 'cut (an object)'},
  {'id': 2, 'name': 'holding for (a person)'},
  {'id': 3, 'name': 'handover to (a person)'},
  {'id': 4, 'name': 'squeeze (an object)'},
  {'id': 5, 'name': 'sprinkle (an object)'},
  {'id': 6, 'name': 'transfer (an object)'},
  {'id': 7, 'name': 'pour (an object)'},
  {'id': 8, 'name': 'heat (an object)'},
  {'id': 9, 'name': 'stir (an object)'},
  {'id': 10, 'name': 'wrap (an object)'},
  {'id': 11, 'name': 'roll (an object)'},
  {'id': 12, 'name': 'dip (an object)'}]
2022-04-26 16:46:09,639 alphaction.inference INFO: ==> 0.000590086 seconds to read file data/lfv_robalo/annotations/lfv_robalo_val.csv
2022-04-26 16:46:09,656 alphaction.inference INFO: ==> 0.0165493 seconds to convert groundtruth
2022-04-26 16:46:09,675 alphaction.inference INFO: ==> 0.0189474 seconds to read file /tmp/tmpxkvq49o8
2022-04-26 16:46:10,007 alphaction.inference INFO: ==> 0.331786 seconds to convert detections
2022-04-26 16:46:10,007 alphaction.inference INFO: The following classes have no ground truth examples: [ 2  3 10 11 12]
2022-04-26 16:46:10,010 alphaction.inference INFO: ==> 0.00275183 seconds to run_evaluator
2022-04-26 16:46:10,012 alphaction.inference INFO: { 'PascalBoxes_PerformanceByCategory/AP@0.5IOU/cut (an object)': 0.4906254265366997,
  'PascalBoxes_PerformanceByCategory/AP@0.5IOU/dip (an object)': nan,
  'PascalBoxes_PerformanceByCategory/AP@0.5IOU/handover to (a person)': nan,
  'PascalBoxes_PerformanceByCategory/AP@0.5IOU/heat (an object)': 0.7401802564486835,
  'PascalBoxes_PerformanceByCategory/AP@0.5IOU/holding for (a person)': nan,
  'PascalBoxes_PerformanceByCategory/AP@0.5IOU/pour (an object)': 0.13443223443223443,
  'PascalBoxes_PerformanceByCategory/AP@0.5IOU/roll (an object)': nan,
  'PascalBoxes_PerformanceByCategory/AP@0.5IOU/sprinkle (an object)': 0.027777777777777776,
  'PascalBoxes_PerformanceByCategory/AP@0.5IOU/squeeze (an object)': 0.0748917748917749,
  'PascalBoxes_PerformanceByCategory/AP@0.5IOU/stir (an object)': 0.2608891424214005,
  'PascalBoxes_PerformanceByCategory/AP@0.5IOU/transfer (an object)': 0.3423012173012174,
  'PascalBoxes_PerformanceByCategory/AP@0.5IOU/wrap (an object)': nan,
  'PascalBoxes_Precision/mAP@0.5IOU': 0.2958711185442554}
2022-04-26 16:46:20,049 alphaction.trainer INFO: eta: 5 days, 3:37:04  iter: 5320  loss_pose_action: 0.0004 (0.3378)  loss_object_interaction: 0.0000 (0.0004)  loss_person_interaction: 0.0000 (0.0004)  total_loss: 0.0022 (0.4329)  accuracy_pose_action: 1.0000 (0.8229)  accuracy_object_interaction: 1.0000 (0.9985)  accuracy_person_interaction: 1.0000 (0.9987)  time: 0.4991 (0.5088)  data: 0.0135 (0.0141)  lr: 0.000125  max mem: 2403
2022-04-26 16:46:30,244 alphaction.trainer INFO: eta: 5 days, 3:36:57  iter: 5340  loss_pose_action: 0.0023 (0.3369)  loss_object_interaction: 0.0000 (0.0004)  loss_person_interaction: 0.0000 (0.0004)  total_loss: 0.0101 (0.4317)  accuracy_pose_action: 1.0000 (0.8235)  accuracy_object_interaction: 1.0000 (0.9985)  accuracy_person_interaction: 1.0000 (0.9987)  time: 0.5121 (0.5088)  data: 0.0142 (0.0141)  lr: 0.000125  max mem: 2403
2022-04-26 16:46:40,392 alphaction.trainer INFO: eta: 5 days, 3:36:42  iter: 5360  loss_pose_action: 0.0000 (0.3360)  loss_object_interaction: 0.0000 (0.0004)  loss_person_interaction: 0.0000 (0.0004)  total_loss: 0.0020 (0.4305)  accuracy_pose_action: 1.0000 (0.8239)  accuracy_object_interaction: 1.0000 (0.9985)  accuracy_person_interaction: 1.0000 (0.9987)  time: 0.5142 (0.5088)  data: 0.0143 (0.0141)  lr: 0.000125  max mem: 2403
2022-04-26 16:46:50,623 alphaction.trainer INFO: eta: 5 days, 3:36:41  iter: 5380  loss_pose_action: 0.0003 (0.3348)  loss_object_interaction: 0.0000 (0.0004)  loss_person_interaction: 0.0000 (0.0004)  total_loss: 0.0028 (0.4290)  accuracy_pose_action: 1.0000 (0.8245)  accuracy_object_interaction: 1.0000 (0.9985)  accuracy_person_interaction: 1.0000 (0.9987)  time: 0.5123 (0.5088)  data: 0.0139 (0.0141)  lr: 0.000125  max mem: 2403
2022-04-26 16:47:00,860 alphaction.trainer INFO: eta: 5 days, 3:36:41  iter: 5400  loss_pose_action: 0.0002 (0.3338)  loss_object_interaction: 0.0000 (0.0004)  loss_person_interaction: 0.0000 (0.0004)  total_loss: 0.0010 (0.4276)  accuracy_pose_action: 1.0000 (0.8250)  accuracy_object_interaction: 1.0000 (0.9985)  accuracy_person_interaction: 1.0000 (0.9987)  time: 0.5126 (0.5088)  data: 0.0136 (0.0141)  lr: 0.000125  max mem: 2403
2022-04-26 16:47:00,863 alphaction.utils.checkpoint INFO: Saving checkpoint to data/output/resnet50_4x16f_baseline_robalo/model_0005400.pth
2022-04-26 16:47:01,124 alphaction.inference INFO: Start evaluation on lfv_robalo_val_ava_video dataset(135 videos).
2022-04-26 16:47:15,683 alphaction.inference INFO: Total inference time: 0:00:14.559104 (0.10784521809330692 s / video per device, on 1 devices)
2022-04-26 16:47:15,683 alphaction.inference INFO: performing ava evaluation.
2022-04-26 16:47:15,683 alphaction.inference INFO: Preparing results for AVA format
2022-04-26 16:47:15,700 alphaction.inference INFO: Evaluating predictions
2022-04-26 16:47:15,750 alphaction.inference INFO: ==> 0.0498762 seconds to write file /tmp/tmpcwfs6vlt
2022-04-26 16:47:15,750 alphaction.inference INFO: CATEGORIES (12):
[ {'id': 1, 'name': 'cut (an object)'},
  {'id': 2, 'name': 'holding for (a person)'},
  {'id': 3, 'name': 'handover to (a person)'},
  {'id': 4, 'name': 'squeeze (an object)'},
  {'id': 5, 'name': 'sprinkle (an object)'},
  {'id': 6, 'name': 'transfer (an object)'},
  {'id': 7, 'name': 'pour (an object)'},
  {'id': 8, 'name': 'heat (an object)'},
  {'id': 9, 'name': 'stir (an object)'},
  {'id': 10, 'name': 'wrap (an object)'},
  {'id': 11, 'name': 'roll (an object)'},
  {'id': 12, 'name': 'dip (an object)'}]
2022-04-26 16:47:15,751 alphaction.inference INFO: ==> 0.00050354 seconds to read file data/lfv_robalo/annotations/lfv_robalo_val.csv
2022-04-26 16:47:15,768 alphaction.inference INFO: ==> 0.0168865 seconds to convert groundtruth
2022-04-26 16:47:15,789 alphaction.inference INFO: ==> 0.0213861 seconds to read file /tmp/tmpcwfs6vlt
2022-04-26 16:47:16,126 alphaction.inference INFO: ==> 0.336312 seconds to convert detections
2022-04-26 16:47:16,126 alphaction.inference INFO: The following classes have no ground truth examples: [ 2  3 10 11 12]
2022-04-26 16:47:16,129 alphaction.inference INFO: ==> 0.00268817 seconds to run_evaluator
2022-04-26 16:47:16,129 alphaction.inference INFO: { 'PascalBoxes_PerformanceByCategory/AP@0.5IOU/cut (an object)': 0.4908578493599886,
  'PascalBoxes_PerformanceByCategory/AP@0.5IOU/dip (an object)': nan,
  'PascalBoxes_PerformanceByCategory/AP@0.5IOU/handover to (a person)': nan,
  'PascalBoxes_PerformanceByCategory/AP@0.5IOU/heat (an object)': 0.6964412631982655,
  'PascalBoxes_PerformanceByCategory/AP@0.5IOU/holding for (a person)': nan,
  'PascalBoxes_PerformanceByCategory/AP@0.5IOU/pour (an object)': 0.09999999999999999,
  'PascalBoxes_PerformanceByCategory/AP@0.5IOU/roll (an object)': nan,
  'PascalBoxes_PerformanceByCategory/AP@0.5IOU/sprinkle (an object)': 0.022727272727272728,
  'PascalBoxes_PerformanceByCategory/AP@0.5IOU/squeeze (an object)': 0.07649913718723036,
  'PascalBoxes_PerformanceByCategory/AP@0.5IOU/stir (an object)': 0.297156578093033,
  'PascalBoxes_PerformanceByCategory/AP@0.5IOU/transfer (an object)': 0.36747927238644473,
  'PascalBoxes_PerformanceByCategory/AP@0.5IOU/wrap (an object)': nan,
  'PascalBoxes_Precision/mAP@0.5IOU': 0.2930230532788907}
2022-04-26 16:47:26,182 alphaction.trainer INFO: eta: 5 days, 3:36:10  iter: 5420  loss_pose_action: 0.0000 (0.3326)  loss_object_interaction: 0.0000 (0.0004)  loss_person_interaction: 0.0000 (0.0004)  total_loss: 0.0013 (0.4261)  accuracy_pose_action: 1.0000 (0.8257)  accuracy_object_interaction: 1.0000 (0.9985)  accuracy_person_interaction: 1.0000 (0.9987)  time: 0.4996 (0.5088)  data: 0.0139 (0.0141)  lr: 0.000125  max mem: 2403
2022-04-26 16:47:36,323 alphaction.trainer INFO: eta: 5 days, 3:35:55  iter: 5440  loss_pose_action: 0.0000 (0.3314)  loss_object_interaction: 0.0000 (0.0004)  loss_person_interaction: 0.0000 (0.0004)  total_loss: 0.0005 (0.4246)  accuracy_pose_action: 1.0000 (0.8263)  accuracy_object_interaction: 1.0000 (0.9985)  accuracy_person_interaction: 1.0000 (0.9987)  time: 0.5063 (0.5088)  data: 0.0137 (0.0141)  lr: 0.000125  max mem: 2403
2022-04-26 16:47:46,534 alphaction.trainer INFO: eta: 5 days, 3:35:50  iter: 5460  loss_pose_action: 0.0000 (0.3302)  loss_object_interaction: 0.0000 (0.0004)  loss_person_interaction: 0.0000 (0.0004)  total_loss: 0.0004 (0.4230)  accuracy_pose_action: 1.0000 (0.8270)  accuracy_object_interaction: 1.0000 (0.9985)  accuracy_person_interaction: 1.0000 (0.9987)  time: 0.5130 (0.5088)  data: 0.0146 (0.0141)  lr: 0.000125  max mem: 2403
2022-04-26 16:47:56,787 alphaction.trainer INFO: eta: 5 days, 3:35:52  iter: 5480  loss_pose_action: 0.0000 (0.3292)  loss_object_interaction: 0.0000 (0.0004)  loss_person_interaction: 0.0000 (0.0004)  total_loss: 0.0003 (0.4218)  accuracy_pose_action: 1.0000 (0.8275)  accuracy_object_interaction: 1.0000 (0.9985)  accuracy_person_interaction: 1.0000 (0.9987)  time: 0.5127 (0.5088)  data: 0.0141 (0.0141)  lr: 0.000125  max mem: 2403
2022-04-26 16:48:07,005 alphaction.trainer INFO: eta: 5 days, 3:35:49  iter: 5500  loss_pose_action: 0.0000 (0.3281)  loss_object_interaction: 0.0000 (0.0004)  loss_person_interaction: 0.0000 (0.0004)  total_loss: 0.0005 (0.4203)  accuracy_pose_action: 1.0000 (0.8280)  accuracy_object_interaction: 1.0000 (0.9985)  accuracy_person_interaction: 1.0000 (0.9987)  time: 0.5140 (0.5088)  data: 0.0146 (0.0141)  lr: 0.000125  max mem: 2403
2022-04-26 16:48:07,008 alphaction.utils.checkpoint INFO: Saving checkpoint to data/output/resnet50_4x16f_baseline_robalo/model_0005500.pth
2022-04-26 16:48:07,277 alphaction.inference INFO: Start evaluation on lfv_robalo_val_ava_video dataset(135 videos).
2022-04-26 16:48:22,354 alphaction.inference INFO: Total inference time: 0:00:15.076817 (0.1116801279562491 s / video per device, on 1 devices)
2022-04-26 16:48:22,354 alphaction.inference INFO: performing ava evaluation.
2022-04-26 16:48:22,354 alphaction.inference INFO: Preparing results for AVA format
2022-04-26 16:48:22,371 alphaction.inference INFO: Evaluating predictions
2022-04-26 16:48:22,424 alphaction.inference INFO: ==> 0.0523603 seconds to write file /tmp/tmp47isti_k
2022-04-26 16:48:22,424 alphaction.inference INFO: CATEGORIES (12):
[ {'id': 1, 'name': 'cut (an object)'},
  {'id': 2, 'name': 'holding for (a person)'},
  {'id': 3, 'name': 'handover to (a person)'},
  {'id': 4, 'name': 'squeeze (an object)'},
  {'id': 5, 'name': 'sprinkle (an object)'},
  {'id': 6, 'name': 'transfer (an object)'},
  {'id': 7, 'name': 'pour (an object)'},
  {'id': 8, 'name': 'heat (an object)'},
  {'id': 9, 'name': 'stir (an object)'},
  {'id': 10, 'name': 'wrap (an object)'},
  {'id': 11, 'name': 'roll (an object)'},
  {'id': 12, 'name': 'dip (an object)'}]
2022-04-26 16:48:22,425 alphaction.inference INFO: ==> 0.000497818 seconds to read file data/lfv_robalo/annotations/lfv_robalo_val.csv
2022-04-26 16:48:22,444 alphaction.inference INFO: ==> 0.0184834 seconds to convert groundtruth
2022-04-26 16:48:22,464 alphaction.inference INFO: ==> 0.0204244 seconds to read file /tmp/tmp47isti_k
2022-04-26 16:48:22,802 alphaction.inference INFO: ==> 0.337584 seconds to convert detections
2022-04-26 16:48:22,802 alphaction.inference INFO: The following classes have no ground truth examples: [ 2  3 10 11 12]
2022-04-26 16:48:22,805 alphaction.inference INFO: ==> 0.00270247 seconds to run_evaluator
2022-04-26 16:48:22,806 alphaction.inference INFO: { 'PascalBoxes_PerformanceByCategory/AP@0.5IOU/cut (an object)': 0.5343841092203496,
  'PascalBoxes_PerformanceByCategory/AP@0.5IOU/dip (an object)': nan,
  'PascalBoxes_PerformanceByCategory/AP@0.5IOU/handover to (a person)': nan,
  'PascalBoxes_PerformanceByCategory/AP@0.5IOU/heat (an object)': 0.6789084766466101,
  'PascalBoxes_PerformanceByCategory/AP@0.5IOU/holding for (a person)': nan,
  'PascalBoxes_PerformanceByCategory/AP@0.5IOU/pour (an object)': 0.047683185423702194,
  'PascalBoxes_PerformanceByCategory/AP@0.5IOU/roll (an object)': nan,
  'PascalBoxes_PerformanceByCategory/AP@0.5IOU/sprinkle (an object)': 0.037037037037037035,
  'PascalBoxes_PerformanceByCategory/AP@0.5IOU/squeeze (an object)': 0.10828005901155642,
  'PascalBoxes_PerformanceByCategory/AP@0.5IOU/stir (an object)': 0.2987630648920972,
  'PascalBoxes_PerformanceByCategory/AP@0.5IOU/transfer (an object)': 0.37464997829283786,
  'PascalBoxes_PerformanceByCategory/AP@0.5IOU/wrap (an object)': nan,
  'PascalBoxes_Precision/mAP@0.5IOU': 0.29710084436059864}
2022-04-26 16:48:32,818 alphaction.trainer INFO: eta: 5 days, 3:35:12  iter: 5520  loss_pose_action: 0.0001 (0.3270)  loss_object_interaction: 0.0000 (0.0004)  loss_person_interaction: 0.0000 (0.0004)  total_loss: 0.0005 (0.4189)  accuracy_pose_action: 1.0000 (0.8286)  accuracy_object_interaction: 1.0000 (0.9986)  accuracy_person_interaction: 1.0000 (0.9987)  time: 0.4965 (0.5088)  data: 0.0133 (0.0141)  lr: 0.000125  max mem: 2403
2022-04-26 16:48:42,957 alphaction.trainer INFO: eta: 5 days, 3:34:57  iter: 5540  loss_pose_action: 0.0001 (0.3261)  loss_object_interaction: 0.0000 (0.0004)  loss_person_interaction: 0.0000 (0.0004)  total_loss: 0.0003 (0.4177)  accuracy_pose_action: 1.0000 (0.8290)  accuracy_object_interaction: 1.0000 (0.9986)  accuracy_person_interaction: 1.0000 (0.9987)  time: 0.5103 (0.5088)  data: 0.0141 (0.0141)  lr: 0.000125  max mem: 2403
2022-04-26 16:48:53,195 alphaction.trainer INFO: eta: 5 days, 3:34:56  iter: 5560  loss_pose_action: 0.0000 (0.3250)  loss_object_interaction: 0.0000 (0.0004)  loss_person_interaction: 0.0000 (0.0004)  total_loss: 0.0017 (0.4164)  accuracy_pose_action: 1.0000 (0.8295)  accuracy_object_interaction: 1.0000 (0.9986)  accuracy_person_interaction: 1.0000 (0.9987)  time: 0.5121 (0.5088)  data: 0.0138 (0.0141)  lr: 0.000125  max mem: 2403
2022-04-26 16:49:03,433 alphaction.trainer INFO: eta: 5 days, 3:34:56  iter: 5580  loss_pose_action: 0.0000 (0.3240)  loss_object_interaction: 0.0000 (0.0004)  loss_person_interaction: 0.0000 (0.0004)  total_loss: 0.0009 (0.4151)  accuracy_pose_action: 1.0000 (0.8299)  accuracy_object_interaction: 1.0000 (0.9986)  accuracy_person_interaction: 1.0000 (0.9987)  time: 0.5114 (0.5088)  data: 0.0142 (0.0141)  lr: 0.000125  max mem: 2403
2022-04-26 16:49:13,618 alphaction.trainer INFO: eta: 5 days, 3:34:47  iter: 5600  loss_pose_action: 0.0000 (0.3230)  loss_object_interaction: 0.0000 (0.0004)  loss_person_interaction: 0.0000 (0.0004)  total_loss: 0.0011 (0.4138)  accuracy_pose_action: 1.0000 (0.8303)  accuracy_object_interaction: 1.0000 (0.9986)  accuracy_person_interaction: 1.0000 (0.9988)  time: 0.5114 (0.5088)  data: 0.0140 (0.0141)  lr: 0.000125  max mem: 2403
2022-04-26 16:49:13,622 alphaction.utils.checkpoint INFO: Saving checkpoint to data/output/resnet50_4x16f_baseline_robalo/model_0005600.pth
2022-04-26 16:49:13,897 alphaction.inference INFO: Start evaluation on lfv_robalo_val_ava_video dataset(135 videos).
2022-04-26 16:49:28,696 alphaction.inference INFO: Total inference time: 0:00:14.798997 (0.10962220121313024 s / video per device, on 1 devices)
2022-04-26 16:49:28,696 alphaction.inference INFO: performing ava evaluation.
2022-04-26 16:49:28,696 alphaction.inference INFO: Preparing results for AVA format
2022-04-26 16:49:28,713 alphaction.inference INFO: Evaluating predictions
2022-04-26 16:49:28,762 alphaction.inference INFO: ==> 0.0487566 seconds to write file /tmp/tmpsuws8m70
2022-04-26 16:49:28,762 alphaction.inference INFO: CATEGORIES (12):
[ {'id': 1, 'name': 'cut (an object)'},
  {'id': 2, 'name': 'holding for (a person)'},
  {'id': 3, 'name': 'handover to (a person)'},
  {'id': 4, 'name': 'squeeze (an object)'},
  {'id': 5, 'name': 'sprinkle (an object)'},
  {'id': 6, 'name': 'transfer (an object)'},
  {'id': 7, 'name': 'pour (an object)'},
  {'id': 8, 'name': 'heat (an object)'},
  {'id': 9, 'name': 'stir (an object)'},
  {'id': 10, 'name': 'wrap (an object)'},
  {'id': 11, 'name': 'roll (an object)'},
  {'id': 12, 'name': 'dip (an object)'}]
2022-04-26 16:49:28,763 alphaction.inference INFO: ==> 0.000447035 seconds to read file data/lfv_robalo/annotations/lfv_robalo_val.csv
2022-04-26 16:49:28,780 alphaction.inference INFO: ==> 0.0169151 seconds to convert groundtruth
2022-04-26 16:49:28,801 alphaction.inference INFO: ==> 0.0217495 seconds to read file /tmp/tmpsuws8m70
2022-04-26 16:49:29,135 alphaction.inference INFO: ==> 0.333585 seconds to convert detections
2022-04-26 16:49:29,135 alphaction.inference INFO: The following classes have no ground truth examples: [ 2  3 10 11 12]
2022-04-26 16:49:29,139 alphaction.inference INFO: ==> 0.00318694 seconds to run_evaluator
2022-04-26 16:49:29,140 alphaction.inference INFO: { 'PascalBoxes_PerformanceByCategory/AP@0.5IOU/cut (an object)': 0.5900804403160651,
  'PascalBoxes_PerformanceByCategory/AP@0.5IOU/dip (an object)': nan,
  'PascalBoxes_PerformanceByCategory/AP@0.5IOU/handover to (a person)': nan,
  'PascalBoxes_PerformanceByCategory/AP@0.5IOU/heat (an object)': 0.6960846397284686,
  'PascalBoxes_PerformanceByCategory/AP@0.5IOU/holding for (a person)': nan,
  'PascalBoxes_PerformanceByCategory/AP@0.5IOU/pour (an object)': 0.13018575851393188,
  'PascalBoxes_PerformanceByCategory/AP@0.5IOU/roll (an object)': nan,
  'PascalBoxes_PerformanceByCategory/AP@0.5IOU/sprinkle (an object)': 0.05405405405405406,
  'PascalBoxes_PerformanceByCategory/AP@0.5IOU/squeeze (an object)': 0.11300057372346528,
  'PascalBoxes_PerformanceByCategory/AP@0.5IOU/stir (an object)': 0.3390164896282805,
  'PascalBoxes_PerformanceByCategory/AP@0.5IOU/transfer (an object)': 0.4425477720932267,
  'PascalBoxes_PerformanceByCategory/AP@0.5IOU/wrap (an object)': nan,
  'PascalBoxes_Precision/mAP@0.5IOU': 0.3378528182939275}
2022-04-26 16:49:39,217 alphaction.trainer INFO: eta: 5 days, 3:34:21  iter: 5620  loss_pose_action: 0.0003 (0.3221)  loss_object_interaction: 0.0000 (0.0004)  loss_person_interaction: 0.0000 (0.0004)  total_loss: 0.0023 (0.4126)  accuracy_pose_action: 1.0000 (0.8308)  accuracy_object_interaction: 1.0000 (0.9986)  accuracy_person_interaction: 1.0000 (0.9988)  time: 0.5026 (0.5088)  data: 0.0142 (0.0142)  lr: 0.000125  max mem: 2403
2022-04-26 16:49:49,342 alphaction.trainer INFO: eta: 5 days, 3:34:03  iter: 5640  loss_pose_action: 0.0002 (0.3210)  loss_object_interaction: 0.0000 (0.0004)  loss_person_interaction: 0.0000 (0.0004)  total_loss: 0.0014 (0.4112)  accuracy_pose_action: 1.0000 (0.8314)  accuracy_object_interaction: 1.0000 (0.9986)  accuracy_person_interaction: 1.0000 (0.9988)  time: 0.5079 (0.5088)  data: 0.0140 (0.0142)  lr: 0.000125  max mem: 2403
2022-04-26 16:49:59,548 alphaction.trainer INFO: eta: 5 days, 3:33:58  iter: 5660  loss_pose_action: 0.0000 (0.3198)  loss_object_interaction: 0.0000 (0.0004)  loss_person_interaction: 0.0000 (0.0004)  total_loss: 0.0009 (0.4097)  accuracy_pose_action: 1.0000 (0.8320)  accuracy_object_interaction: 1.0000 (0.9986)  accuracy_person_interaction: 1.0000 (0.9988)  time: 0.5119 (0.5088)  data: 0.0140 (0.0141)  lr: 0.000125  max mem: 2403
2022-04-26 16:50:09,789 alphaction.trainer INFO: eta: 5 days, 3:33:57  iter: 5680  loss_pose_action: 0.0000 (0.3187)  loss_object_interaction: 0.0000 (0.0004)  loss_person_interaction: 0.0000 (0.0004)  total_loss: 0.0002 (0.4083)  accuracy_pose_action: 1.0000 (0.8326)  accuracy_object_interaction: 1.0000 (0.9986)  accuracy_person_interaction: 1.0000 (0.9988)  time: 0.5113 (0.5088)  data: 0.0143 (0.0141)  lr: 0.000125  max mem: 2403
2022-04-26 16:50:20,000 alphaction.trainer INFO: eta: 5 days, 3:33:53  iter: 5700  loss_pose_action: 0.0000 (0.3176)  loss_object_interaction: 0.0000 (0.0004)  loss_person_interaction: 0.0000 (0.0004)  total_loss: 0.0009 (0.4069)  accuracy_pose_action: 1.0000 (0.8332)  accuracy_object_interaction: 1.0000 (0.9986)  accuracy_person_interaction: 1.0000 (0.9988)  time: 0.5137 (0.5088)  data: 0.0143 (0.0142)  lr: 0.000125  max mem: 2403
2022-04-26 16:50:20,003 alphaction.utils.checkpoint INFO: Saving checkpoint to data/output/resnet50_4x16f_baseline_robalo/model_0005700.pth
2022-04-26 16:50:20,261 alphaction.inference INFO: Start evaluation on lfv_robalo_val_ava_video dataset(135 videos).
2022-04-26 16:50:35,248 alphaction.inference INFO: Total inference time: 0:00:14.986710 (0.1110126671967683 s / video per device, on 1 devices)
2022-04-26 16:50:35,249 alphaction.inference INFO: performing ava evaluation.
2022-04-26 16:50:35,249 alphaction.inference INFO: Preparing results for AVA format
2022-04-26 16:50:35,265 alphaction.inference INFO: Evaluating predictions
2022-04-26 16:50:35,316 alphaction.inference INFO: ==> 0.0501025 seconds to write file /tmp/tmpfhnzbwjn
2022-04-26 16:50:35,316 alphaction.inference INFO: CATEGORIES (12):
[ {'id': 1, 'name': 'cut (an object)'},
  {'id': 2, 'name': 'holding for (a person)'},
  {'id': 3, 'name': 'handover to (a person)'},
  {'id': 4, 'name': 'squeeze (an object)'},
  {'id': 5, 'name': 'sprinkle (an object)'},
  {'id': 6, 'name': 'transfer (an object)'},
  {'id': 7, 'name': 'pour (an object)'},
  {'id': 8, 'name': 'heat (an object)'},
  {'id': 9, 'name': 'stir (an object)'},
  {'id': 10, 'name': 'wrap (an object)'},
  {'id': 11, 'name': 'roll (an object)'},
  {'id': 12, 'name': 'dip (an object)'}]
2022-04-26 16:50:35,317 alphaction.inference INFO: ==> 0.00052619 seconds to read file data/lfv_robalo/annotations/lfv_robalo_val.csv
2022-04-26 16:50:35,333 alphaction.inference INFO: ==> 0.0167871 seconds to convert groundtruth
2022-04-26 16:50:35,353 alphaction.inference INFO: ==> 0.02001 seconds to read file /tmp/tmpfhnzbwjn
2022-04-26 16:50:35,686 alphaction.inference INFO: ==> 0.332565 seconds to convert detections
2022-04-26 16:50:35,686 alphaction.inference INFO: The following classes have no ground truth examples: [ 2  3 10 11 12]
2022-04-26 16:50:35,689 alphaction.inference INFO: ==> 0.00261617 seconds to run_evaluator
2022-04-26 16:50:35,690 alphaction.inference INFO: { 'PascalBoxes_PerformanceByCategory/AP@0.5IOU/cut (an object)': 0.6379079616036138,
  'PascalBoxes_PerformanceByCategory/AP@0.5IOU/dip (an object)': nan,
  'PascalBoxes_PerformanceByCategory/AP@0.5IOU/handover to (a person)': nan,
  'PascalBoxes_PerformanceByCategory/AP@0.5IOU/heat (an object)': 0.6435254325338541,
  'PascalBoxes_PerformanceByCategory/AP@0.5IOU/holding for (a person)': nan,
  'PascalBoxes_PerformanceByCategory/AP@0.5IOU/pour (an object)': 0.17564102564102566,
  'PascalBoxes_PerformanceByCategory/AP@0.5IOU/roll (an object)': nan,
  'PascalBoxes_PerformanceByCategory/AP@0.5IOU/sprinkle (an object)': 0.03785714285714285,
  'PascalBoxes_PerformanceByCategory/AP@0.5IOU/squeeze (an object)': 0.08131543821198993,
  'PascalBoxes_PerformanceByCategory/AP@0.5IOU/stir (an object)': 0.28577030845866463,
  'PascalBoxes_PerformanceByCategory/AP@0.5IOU/transfer (an object)': 0.45145980268955616,
  'PascalBoxes_PerformanceByCategory/AP@0.5IOU/wrap (an object)': nan,
  'PascalBoxes_Precision/mAP@0.5IOU': 0.330496730285121}
2022-04-26 16:50:45,770 alphaction.trainer INFO: eta: 5 days, 3:33:28  iter: 5720  loss_pose_action: 0.0000 (0.3165)  loss_object_interaction: 0.0000 (0.0004)  loss_person_interaction: 0.0000 (0.0004)  total_loss: 0.0006 (0.4055)  accuracy_pose_action: 1.0000 (0.8337)  accuracy_object_interaction: 1.0000 (0.9986)  accuracy_person_interaction: 1.0000 (0.9988)  time: 0.5021 (0.5088)  data: 0.0143 (0.0142)  lr: 0.000125  max mem: 2403
2022-04-26 16:50:55,928 alphaction.trainer INFO: eta: 5 days, 3:33:15  iter: 5740  loss_pose_action: 0.0000 (0.3157)  loss_object_interaction: 0.0000 (0.0004)  loss_person_interaction: 0.0000 (0.0004)  total_loss: 0.0005 (0.4045)  accuracy_pose_action: 1.0000 (0.8341)  accuracy_object_interaction: 1.0000 (0.9986)  accuracy_person_interaction: 1.0000 (0.9988)  time: 0.5125 (0.5088)  data: 0.0143 (0.0142)  lr: 0.000125  max mem: 2403
2022-04-26 16:51:06,152 alphaction.trainer INFO: eta: 5 days, 3:33:12  iter: 5760  loss_pose_action: 0.0000 (0.3147)  loss_object_interaction: 0.0000 (0.0004)  loss_person_interaction: 0.0000 (0.0004)  total_loss: 0.0006 (0.4032)  accuracy_pose_action: 1.0000 (0.8345)  accuracy_object_interaction: 1.0000 (0.9986)  accuracy_person_interaction: 1.0000 (0.9988)  time: 0.5131 (0.5088)  data: 0.0144 (0.0142)  lr: 0.000125  max mem: 2403
2022-04-26 16:51:16,338 alphaction.trainer INFO: eta: 5 days, 3:33:03  iter: 5780  loss_pose_action: 0.0000 (0.3138)  loss_object_interaction: 0.0000 (0.0004)  loss_person_interaction: 0.0000 (0.0004)  total_loss: 0.0003 (0.4020)  accuracy_pose_action: 1.0000 (0.8349)  accuracy_object_interaction: 1.0000 (0.9986)  accuracy_person_interaction: 1.0000 (0.9988)  time: 0.5119 (0.5088)  data: 0.0141 (0.0142)  lr: 0.000125  max mem: 2403
2022-04-26 16:51:26,592 alphaction.trainer INFO: eta: 5 days, 3:33:05  iter: 5800  loss_pose_action: 0.0000 (0.3128)  loss_object_interaction: 0.0000 (0.0004)  loss_person_interaction: 0.0000 (0.0004)  total_loss: 0.0003 (0.4006)  accuracy_pose_action: 1.0000 (0.8354)  accuracy_object_interaction: 1.0000 (0.9986)  accuracy_person_interaction: 1.0000 (0.9988)  time: 0.5123 (0.5088)  data: 0.0140 (0.0142)  lr: 0.000125  max mem: 2403
2022-04-26 16:51:26,595 alphaction.utils.checkpoint INFO: Saving checkpoint to data/output/resnet50_4x16f_baseline_robalo/model_0005800.pth
2022-04-26 16:51:26,853 alphaction.inference INFO: Start evaluation on lfv_robalo_val_ava_video dataset(135 videos).
2022-04-26 16:51:41,423 alphaction.inference INFO: Total inference time: 0:00:14.569578 (0.10792279949894658 s / video per device, on 1 devices)
2022-04-26 16:51:41,423 alphaction.inference INFO: performing ava evaluation.
2022-04-26 16:51:41,423 alphaction.inference INFO: Preparing results for AVA format
2022-04-26 16:51:41,440 alphaction.inference INFO: Evaluating predictions
2022-04-26 16:51:41,490 alphaction.inference INFO: ==> 0.0497146 seconds to write file /tmp/tmp9wy86d67
2022-04-26 16:51:41,491 alphaction.inference INFO: CATEGORIES (12):
[ {'id': 1, 'name': 'cut (an object)'},
  {'id': 2, 'name': 'holding for (a person)'},
  {'id': 3, 'name': 'handover to (a person)'},
  {'id': 4, 'name': 'squeeze (an object)'},
  {'id': 5, 'name': 'sprinkle (an object)'},
  {'id': 6, 'name': 'transfer (an object)'},
  {'id': 7, 'name': 'pour (an object)'},
  {'id': 8, 'name': 'heat (an object)'},
  {'id': 9, 'name': 'stir (an object)'},
  {'id': 10, 'name': 'wrap (an object)'},
  {'id': 11, 'name': 'roll (an object)'},
  {'id': 12, 'name': 'dip (an object)'}]
2022-04-26 16:51:41,491 alphaction.inference INFO: ==> 0.000580072 seconds to read file data/lfv_robalo/annotations/lfv_robalo_val.csv
2022-04-26 16:51:41,509 alphaction.inference INFO: ==> 0.0174911 seconds to convert groundtruth
2022-04-26 16:51:41,529 alphaction.inference INFO: ==> 0.0199063 seconds to read file /tmp/tmp9wy86d67
2022-04-26 16:51:41,867 alphaction.inference INFO: ==> 0.337839 seconds to convert detections
2022-04-26 16:51:41,867 alphaction.inference INFO: The following classes have no ground truth examples: [ 2  3 10 11 12]
2022-04-26 16:51:41,870 alphaction.inference INFO: ==> 0.00270414 seconds to run_evaluator
2022-04-26 16:51:41,871 alphaction.inference INFO: { 'PascalBoxes_PerformanceByCategory/AP@0.5IOU/cut (an object)': 0.6722934636736743,
  'PascalBoxes_PerformanceByCategory/AP@0.5IOU/dip (an object)': nan,
  'PascalBoxes_PerformanceByCategory/AP@0.5IOU/handover to (a person)': nan,
  'PascalBoxes_PerformanceByCategory/AP@0.5IOU/heat (an object)': 0.7377976714728647,
  'PascalBoxes_PerformanceByCategory/AP@0.5IOU/holding for (a person)': nan,
  'PascalBoxes_PerformanceByCategory/AP@0.5IOU/pour (an object)': 0.146845694799659,
  'PascalBoxes_PerformanceByCategory/AP@0.5IOU/roll (an object)': nan,
  'PascalBoxes_PerformanceByCategory/AP@0.5IOU/sprinkle (an object)': 0.08695652173913043,
  'PascalBoxes_PerformanceByCategory/AP@0.5IOU/squeeze (an object)': 0.21494098606560613,
  'PascalBoxes_PerformanceByCategory/AP@0.5IOU/stir (an object)': 0.34251579775298546,
  'PascalBoxes_PerformanceByCategory/AP@0.5IOU/transfer (an object)': 0.4613993258068204,
  'PascalBoxes_PerformanceByCategory/AP@0.5IOU/wrap (an object)': nan,
  'PascalBoxes_Precision/mAP@0.5IOU': 0.38039278018724865}
2022-04-26 16:51:51,939 alphaction.trainer INFO: eta: 5 days, 3:32:38  iter: 5820  loss_pose_action: 0.0000 (0.3117)  loss_object_interaction: 0.0000 (0.0004)  loss_person_interaction: 0.0000 (0.0004)  total_loss: 0.0005 (0.3993)  accuracy_pose_action: 1.0000 (0.8360)  accuracy_object_interaction: 1.0000 (0.9986)  accuracy_person_interaction: 1.0000 (0.9988)  time: 0.5025 (0.5088)  data: 0.0141 (0.0142)  lr: 0.000125  max mem: 2403
2022-04-26 16:52:02,095 alphaction.trainer INFO: eta: 5 days, 3:32:25  iter: 5840  loss_pose_action: 0.0000 (0.3106)  loss_object_interaction: 0.0000 (0.0004)  loss_person_interaction: 0.0000 (0.0004)  total_loss: 0.0006 (0.3979)  accuracy_pose_action: 1.0000 (0.8366)  accuracy_object_interaction: 1.0000 (0.9986)  accuracy_person_interaction: 1.0000 (0.9988)  time: 0.5125 (0.5088)  data: 0.0141 (0.0142)  lr: 0.000125  max mem: 2403
2022-04-26 16:52:12,253 alphaction.trainer INFO: eta: 5 days, 3:32:13  iter: 5860  loss_pose_action: 0.0000 (0.3096)  loss_object_interaction: 0.0000 (0.0004)  loss_person_interaction: 0.0000 (0.0004)  total_loss: 0.0003 (0.3966)  accuracy_pose_action: 1.0000 (0.8371)  accuracy_object_interaction: 1.0000 (0.9986)  accuracy_person_interaction: 1.0000 (0.9988)  time: 0.5121 (0.5088)  data: 0.0139 (0.0142)  lr: 0.000125  max mem: 2403
2022-04-26 16:52:22,506 alphaction.trainer INFO: eta: 5 days, 3:32:14  iter: 5880  loss_pose_action: 0.0000 (0.3088)  loss_object_interaction: 0.0000 (0.0004)  loss_person_interaction: 0.0000 (0.0004)  total_loss: 0.0004 (0.3956)  accuracy_pose_action: 1.0000 (0.8376)  accuracy_object_interaction: 1.0000 (0.9986)  accuracy_person_interaction: 1.0000 (0.9988)  time: 0.5128 (0.5088)  data: 0.0142 (0.0142)  lr: 0.000125  max mem: 2403
2022-04-26 16:52:32,745 alphaction.trainer INFO: eta: 5 days, 3:32:13  iter: 5900  loss_pose_action: 0.0000 (0.3078)  loss_object_interaction: 0.0000 (0.0004)  loss_person_interaction: 0.0000 (0.0004)  total_loss: 0.0007 (0.3943)  accuracy_pose_action: 1.0000 (0.8381)  accuracy_object_interaction: 1.0000 (0.9986)  accuracy_person_interaction: 1.0000 (0.9988)  time: 0.5136 (0.5088)  data: 0.0143 (0.0142)  lr: 0.000125  max mem: 2403
2022-04-26 16:52:32,748 alphaction.utils.checkpoint INFO: Saving checkpoint to data/output/resnet50_4x16f_baseline_robalo/model_0005900.pth
2022-04-26 16:52:33,016 alphaction.inference INFO: Start evaluation on lfv_robalo_val_ava_video dataset(135 videos).
2022-04-26 16:52:47,906 alphaction.inference INFO: Total inference time: 0:00:14.890710 (0.11030155641061289 s / video per device, on 1 devices)
2022-04-26 16:52:47,907 alphaction.inference INFO: performing ava evaluation.
2022-04-26 16:52:47,907 alphaction.inference INFO: Preparing results for AVA format
2022-04-26 16:52:47,924 alphaction.inference INFO: Evaluating predictions
2022-04-26 16:52:47,978 alphaction.inference INFO: ==> 0.0532215 seconds to write file /tmp/tmpcy0szc_k
2022-04-26 16:52:47,978 alphaction.inference INFO: CATEGORIES (12):
[ {'id': 1, 'name': 'cut (an object)'},
  {'id': 2, 'name': 'holding for (a person)'},
  {'id': 3, 'name': 'handover to (a person)'},
  {'id': 4, 'name': 'squeeze (an object)'},
  {'id': 5, 'name': 'sprinkle (an object)'},
  {'id': 6, 'name': 'transfer (an object)'},
  {'id': 7, 'name': 'pour (an object)'},
  {'id': 8, 'name': 'heat (an object)'},
  {'id': 9, 'name': 'stir (an object)'},
  {'id': 10, 'name': 'wrap (an object)'},
  {'id': 11, 'name': 'roll (an object)'},
  {'id': 12, 'name': 'dip (an object)'}]
2022-04-26 16:52:47,979 alphaction.inference INFO: ==> 0.00053072 seconds to read file data/lfv_robalo/annotations/lfv_robalo_val.csv
2022-04-26 16:52:47,996 alphaction.inference INFO: ==> 0.0166552 seconds to convert groundtruth
2022-04-26 16:52:48,015 alphaction.inference INFO: ==> 0.0193419 seconds to read file /tmp/tmpcy0szc_k
2022-04-26 16:52:48,356 alphaction.inference INFO: ==> 0.34092 seconds to convert detections
2022-04-26 16:52:48,356 alphaction.inference INFO: The following classes have no ground truth examples: [ 2  3 10 11 12]
2022-04-26 16:52:48,359 alphaction.inference INFO: ==> 0.00279522 seconds to run_evaluator
2022-04-26 16:52:48,360 alphaction.inference INFO: { 'PascalBoxes_PerformanceByCategory/AP@0.5IOU/cut (an object)': 0.5475422248831099,
  'PascalBoxes_PerformanceByCategory/AP@0.5IOU/dip (an object)': nan,
  'PascalBoxes_PerformanceByCategory/AP@0.5IOU/handover to (a person)': nan,
  'PascalBoxes_PerformanceByCategory/AP@0.5IOU/heat (an object)': 0.7373877293028501,
  'PascalBoxes_PerformanceByCategory/AP@0.5IOU/holding for (a person)': nan,
  'PascalBoxes_PerformanceByCategory/AP@0.5IOU/pour (an object)': 0.15577651515151514,
  'PascalBoxes_PerformanceByCategory/AP@0.5IOU/roll (an object)': nan,
  'PascalBoxes_PerformanceByCategory/AP@0.5IOU/sprinkle (an object)': 0.0392156862745098,
  'PascalBoxes_PerformanceByCategory/AP@0.5IOU/squeeze (an object)': 0.07592058562555457,
  'PascalBoxes_PerformanceByCategory/AP@0.5IOU/stir (an object)': 0.3152889221060205,
  'PascalBoxes_PerformanceByCategory/AP@0.5IOU/transfer (an object)': 0.41272024286876635,
  'PascalBoxes_PerformanceByCategory/AP@0.5IOU/wrap (an object)': nan,
  'PascalBoxes_Precision/mAP@0.5IOU': 0.3262645580303324}
2022-04-26 16:52:58,414 alphaction.trainer INFO: eta: 5 days, 3:31:45  iter: 5920  loss_pose_action: 0.0000 (0.3069)  loss_object_interaction: 0.0000 (0.0004)  loss_person_interaction: 0.0000 (0.0004)  total_loss: 0.0009 (0.3931)  accuracy_pose_action: 1.0000 (0.8385)  accuracy_object_interaction: 1.0000 (0.9986)  accuracy_person_interaction: 1.0000 (0.9988)  time: 0.5018 (0.5088)  data: 0.0136 (0.0142)  lr: 0.000125  max mem: 2403
2022-04-26 16:53:08,581 alphaction.trainer INFO: eta: 5 days, 3:31:33  iter: 5940  loss_pose_action: 0.0002 (0.3059)  loss_object_interaction: 0.0000 (0.0004)  loss_person_interaction: 0.0000 (0.0004)  total_loss: 0.0014 (0.3918)  accuracy_pose_action: 1.0000 (0.8391)  accuracy_object_interaction: 1.0000 (0.9987)  accuracy_person_interaction: 1.0000 (0.9988)  time: 0.5119 (0.5088)  data: 0.0141 (0.0142)  lr: 0.000125  max mem: 2403
2022-04-26 16:53:18,792 alphaction.trainer INFO: eta: 5 days, 3:31:28  iter: 5960  loss_pose_action: 0.0001 (0.3049)  loss_object_interaction: 0.0000 (0.0004)  loss_person_interaction: 0.0000 (0.0004)  total_loss: 0.0007 (0.3906)  accuracy_pose_action: 1.0000 (0.8396)  accuracy_object_interaction: 1.0000 (0.9987)  accuracy_person_interaction: 1.0000 (0.9988)  time: 0.5114 (0.5088)  data: 0.0140 (0.0142)  lr: 0.000125  max mem: 2403
2022-04-26 16:53:29,009 alphaction.trainer INFO: eta: 5 days, 3:31:24  iter: 5980  loss_pose_action: 0.0000 (0.3039)  loss_object_interaction: 0.0000 (0.0004)  loss_person_interaction: 0.0000 (0.0004)  total_loss: 0.0001 (0.3893)  accuracy_pose_action: 1.0000 (0.8401)  accuracy_object_interaction: 1.0000 (0.9987)  accuracy_person_interaction: 1.0000 (0.9988)  time: 0.5140 (0.5088)  data: 0.0142 (0.0142)  lr: 0.000125  max mem: 2403
2022-04-26 16:53:39,223 alphaction.trainer INFO: eta: 5 days, 3:31:20  iter: 6000  loss_pose_action: 0.0000 (0.3029)  loss_object_interaction: 0.0000 (0.0004)  loss_person_interaction: 0.0000 (0.0004)  total_loss: 0.0001 (0.3880)  accuracy_pose_action: 1.0000 (0.8405)  accuracy_object_interaction: 1.0000 (0.9987)  accuracy_person_interaction: 1.0000 (0.9988)  time: 0.5142 (0.5088)  data: 0.0143 (0.0142)  lr: 0.000125  max mem: 2403
2022-04-26 16:53:39,227 alphaction.utils.checkpoint INFO: Saving checkpoint to data/output/resnet50_4x16f_baseline_robalo/model_0006000.pth
2022-04-26 16:53:39,497 alphaction.inference INFO: Start evaluation on lfv_robalo_val_ava_video dataset(135 videos).
2022-04-26 16:53:54,677 alphaction.inference INFO: Total inference time: 0:00:15.180389 (0.1124473253885905 s / video per device, on 1 devices)
2022-04-26 16:53:54,678 alphaction.inference INFO: performing ava evaluation.
2022-04-26 16:53:54,678 alphaction.inference INFO: Preparing results for AVA format
2022-04-26 16:53:54,695 alphaction.inference INFO: Evaluating predictions
2022-04-26 16:53:54,745 alphaction.inference INFO: ==> 0.0499823 seconds to write file /tmp/tmpsucbqcsg
2022-04-26 16:53:54,746 alphaction.inference INFO: CATEGORIES (12):
[ {'id': 1, 'name': 'cut (an object)'},
  {'id': 2, 'name': 'holding for (a person)'},
  {'id': 3, 'name': 'handover to (a person)'},
  {'id': 4, 'name': 'squeeze (an object)'},
  {'id': 5, 'name': 'sprinkle (an object)'},
  {'id': 6, 'name': 'transfer (an object)'},
  {'id': 7, 'name': 'pour (an object)'},
  {'id': 8, 'name': 'heat (an object)'},
  {'id': 9, 'name': 'stir (an object)'},
  {'id': 10, 'name': 'wrap (an object)'},
  {'id': 11, 'name': 'roll (an object)'},
  {'id': 12, 'name': 'dip (an object)'}]
2022-04-26 16:53:54,747 alphaction.inference INFO: ==> 0.000969648 seconds to read file data/lfv_robalo/annotations/lfv_robalo_val.csv
2022-04-26 16:53:54,764 alphaction.inference INFO: ==> 0.0170455 seconds to convert groundtruth
2022-04-26 16:53:54,785 alphaction.inference INFO: ==> 0.0207736 seconds to read file /tmp/tmpsucbqcsg
2022-04-26 16:53:55,123 alphaction.inference INFO: ==> 0.337937 seconds to convert detections
2022-04-26 16:53:55,123 alphaction.inference INFO: The following classes have no ground truth examples: [ 2  3 10 11 12]
2022-04-26 16:53:55,126 alphaction.inference INFO: ==> 0.00282431 seconds to run_evaluator
2022-04-26 16:53:55,127 alphaction.inference INFO: { 'PascalBoxes_PerformanceByCategory/AP@0.5IOU/cut (an object)': 0.5968390182694729,
  'PascalBoxes_PerformanceByCategory/AP@0.5IOU/dip (an object)': nan,
  'PascalBoxes_PerformanceByCategory/AP@0.5IOU/handover to (a person)': nan,
  'PascalBoxes_PerformanceByCategory/AP@0.5IOU/heat (an object)': 0.7315899826028381,
  'PascalBoxes_PerformanceByCategory/AP@0.5IOU/holding for (a person)': nan,
  'PascalBoxes_PerformanceByCategory/AP@0.5IOU/pour (an object)': 0.09378287900526064,
  'PascalBoxes_PerformanceByCategory/AP@0.5IOU/roll (an object)': nan,
  'PascalBoxes_PerformanceByCategory/AP@0.5IOU/sprinkle (an object)': 0.044444444444444446,
  'PascalBoxes_PerformanceByCategory/AP@0.5IOU/squeeze (an object)': 0.09897284264372871,
  'PascalBoxes_PerformanceByCategory/AP@0.5IOU/stir (an object)': 0.35164192532613586,
  'PascalBoxes_PerformanceByCategory/AP@0.5IOU/transfer (an object)': 0.47558855121164817,
  'PascalBoxes_PerformanceByCategory/AP@0.5IOU/wrap (an object)': nan,
  'PascalBoxes_Precision/mAP@0.5IOU': 0.3418370919290756}
2022-04-26 16:54:05,165 alphaction.trainer INFO: eta: 5 days, 3:30:49  iter: 6020  loss_pose_action: 0.0000 (0.3019)  loss_object_interaction: 0.0000 (0.0004)  loss_person_interaction: 0.0000 (0.0004)  total_loss: 0.0001 (0.3867)  accuracy_pose_action: 1.0000 (0.8411)  accuracy_object_interaction: 1.0000 (0.9987)  accuracy_person_interaction: 1.0000 (0.9988)  time: 0.5005 (0.5088)  data: 0.0143 (0.0142)  lr: 0.000125  max mem: 2403
2022-04-26 16:54:15,311 alphaction.trainer INFO: eta: 5 days, 3:30:35  iter: 6040  loss_pose_action: 0.0000 (0.3009)  loss_object_interaction: 0.0000 (0.0004)  loss_person_interaction: 0.0000 (0.0004)  total_loss: 0.0005 (0.3855)  accuracy_pose_action: 1.0000 (0.8416)  accuracy_object_interaction: 1.0000 (0.9987)  accuracy_person_interaction: 1.0000 (0.9988)  time: 0.5086 (0.5088)  data: 0.0139 (0.0142)  lr: 0.000125  max mem: 2403
2022-04-26 16:54:25,510 alphaction.trainer INFO: eta: 5 days, 3:30:28  iter: 6060  loss_pose_action: 0.0000 (0.3002)  loss_object_interaction: 0.0000 (0.0004)  loss_person_interaction: 0.0000 (0.0004)  total_loss: 0.0008 (0.3845)  accuracy_pose_action: 1.0000 (0.8420)  accuracy_object_interaction: 1.0000 (0.9987)  accuracy_person_interaction: 1.0000 (0.9988)  time: 0.5125 (0.5088)  data: 0.0143 (0.0142)  lr: 0.000125  max mem: 2403
2022-04-26 16:54:35,725 alphaction.trainer INFO: eta: 5 days, 3:30:23  iter: 6080  loss_pose_action: 0.0000 (0.2992)  loss_object_interaction: 0.0000 (0.0004)  loss_person_interaction: 0.0000 (0.0004)  total_loss: 0.0013 (0.3833)  accuracy_pose_action: 1.0000 (0.8425)  accuracy_object_interaction: 1.0000 (0.9987)  accuracy_person_interaction: 1.0000 (0.9988)  time: 0.5136 (0.5088)  data: 0.0142 (0.0142)  lr: 0.000125  max mem: 2403
2022-04-26 16:54:45,950 alphaction.trainer INFO: eta: 5 days, 3:30:20  iter: 6100  loss_pose_action: 0.0000 (0.2983)  loss_object_interaction: 0.0000 (0.0004)  loss_person_interaction: 0.0000 (0.0004)  total_loss: 0.0003 (0.3821)  accuracy_pose_action: 1.0000 (0.8430)  accuracy_object_interaction: 1.0000 (0.9987)  accuracy_person_interaction: 1.0000 (0.9989)  time: 0.5123 (0.5088)  data: 0.0143 (0.0142)  lr: 0.000125  max mem: 2403
2022-04-26 16:54:45,953 alphaction.utils.checkpoint INFO: Saving checkpoint to data/output/resnet50_4x16f_baseline_robalo/model_0006100.pth
2022-04-26 16:54:46,222 alphaction.inference INFO: Start evaluation on lfv_robalo_val_ava_video dataset(135 videos).
2022-04-26 16:55:00,867 alphaction.inference INFO: Total inference time: 0:00:14.644854 (0.10848039874324092 s / video per device, on 1 devices)
2022-04-26 16:55:00,867 alphaction.inference INFO: performing ava evaluation.
2022-04-26 16:55:00,867 alphaction.inference INFO: Preparing results for AVA format
2022-04-26 16:55:00,884 alphaction.inference INFO: Evaluating predictions
2022-04-26 16:55:00,936 alphaction.inference INFO: ==> 0.051789 seconds to write file /tmp/tmpt8mb7kea
2022-04-26 16:55:00,937 alphaction.inference INFO: CATEGORIES (12):
[ {'id': 1, 'name': 'cut (an object)'},
  {'id': 2, 'name': 'holding for (a person)'},
  {'id': 3, 'name': 'handover to (a person)'},
  {'id': 4, 'name': 'squeeze (an object)'},
  {'id': 5, 'name': 'sprinkle (an object)'},
  {'id': 6, 'name': 'transfer (an object)'},
  {'id': 7, 'name': 'pour (an object)'},
  {'id': 8, 'name': 'heat (an object)'},
  {'id': 9, 'name': 'stir (an object)'},
  {'id': 10, 'name': 'wrap (an object)'},
  {'id': 11, 'name': 'roll (an object)'},
  {'id': 12, 'name': 'dip (an object)'}]
2022-04-26 16:55:00,937 alphaction.inference INFO: ==> 0.00048399 seconds to read file data/lfv_robalo/annotations/lfv_robalo_val.csv
2022-04-26 16:55:00,954 alphaction.inference INFO: ==> 0.0164862 seconds to convert groundtruth
2022-04-26 16:55:00,975 alphaction.inference INFO: ==> 0.0214756 seconds to read file /tmp/tmpt8mb7kea
2022-04-26 16:55:01,329 alphaction.inference INFO: ==> 0.353866 seconds to convert detections
2022-04-26 16:55:01,330 alphaction.inference INFO: The following classes have no ground truth examples: [ 2  3 10 11 12]
2022-04-26 16:55:01,332 alphaction.inference INFO: ==> 0.00284243 seconds to run_evaluator
2022-04-26 16:55:01,335 alphaction.inference INFO: { 'PascalBoxes_PerformanceByCategory/AP@0.5IOU/cut (an object)': 0.649670546550186,
  'PascalBoxes_PerformanceByCategory/AP@0.5IOU/dip (an object)': nan,
  'PascalBoxes_PerformanceByCategory/AP@0.5IOU/handover to (a person)': nan,
  'PascalBoxes_PerformanceByCategory/AP@0.5IOU/heat (an object)': 0.7462414885882293,
  'PascalBoxes_PerformanceByCategory/AP@0.5IOU/holding for (a person)': nan,
  'PascalBoxes_PerformanceByCategory/AP@0.5IOU/pour (an object)': 0.12560386473429952,
  'PascalBoxes_PerformanceByCategory/AP@0.5IOU/roll (an object)': nan,
  'PascalBoxes_PerformanceByCategory/AP@0.5IOU/sprinkle (an object)': 0.03773584905660377,
  'PascalBoxes_PerformanceByCategory/AP@0.5IOU/squeeze (an object)': 0.10253623188405796,
  'PascalBoxes_PerformanceByCategory/AP@0.5IOU/stir (an object)': 0.3318251638190651,
  'PascalBoxes_PerformanceByCategory/AP@0.5IOU/transfer (an object)': 0.5175719840633873,
  'PascalBoxes_PerformanceByCategory/AP@0.5IOU/wrap (an object)': nan,
  'PascalBoxes_Precision/mAP@0.5IOU': 0.3587407326708327}
2022-04-26 16:55:11,377 alphaction.trainer INFO: eta: 5 days, 3:29:51  iter: 6120  loss_pose_action: 0.0000 (0.2973)  loss_object_interaction: 0.0000 (0.0004)  loss_person_interaction: 0.0000 (0.0004)  total_loss: 0.0001 (0.3808)  accuracy_pose_action: 1.0000 (0.8434)  accuracy_object_interaction: 1.0000 (0.9987)  accuracy_person_interaction: 1.0000 (0.9989)  time: 0.5001 (0.5088)  data: 0.0141 (0.0142)  lr: 0.000125  max mem: 2403
2022-04-26 16:55:21,558 alphaction.trainer INFO: eta: 5 days, 3:29:42  iter: 6140  loss_pose_action: 0.0000 (0.2963)  loss_object_interaction: 0.0000 (0.0004)  loss_person_interaction: 0.0000 (0.0004)  total_loss: 0.0003 (0.3796)  accuracy_pose_action: 1.0000 (0.8439)  accuracy_object_interaction: 1.0000 (0.9987)  accuracy_person_interaction: 1.0000 (0.9989)  time: 0.5111 (0.5088)  data: 0.0136 (0.0142)  lr: 0.000125  max mem: 2403
2022-04-26 16:55:31,733 alphaction.trainer INFO: eta: 5 days, 3:29:31  iter: 6160  loss_pose_action: 0.0000 (0.2954)  loss_object_interaction: 0.0000 (0.0004)  loss_person_interaction: 0.0000 (0.0004)  total_loss: 0.0005 (0.3784)  accuracy_pose_action: 1.0000 (0.8444)  accuracy_object_interaction: 1.0000 (0.9987)  accuracy_person_interaction: 1.0000 (0.9989)  time: 0.5119 (0.5088)  data: 0.0145 (0.0142)  lr: 0.000125  max mem: 2403
2022-04-26 16:55:41,977 alphaction.trainer INFO: eta: 5 days, 3:29:31  iter: 6180  loss_pose_action: 0.0000 (0.2945)  loss_object_interaction: 0.0000 (0.0004)  loss_person_interaction: 0.0000 (0.0004)  total_loss: 0.0003 (0.3772)  accuracy_pose_action: 1.0000 (0.8449)  accuracy_object_interaction: 1.0000 (0.9987)  accuracy_person_interaction: 1.0000 (0.9989)  time: 0.5132 (0.5088)  data: 0.0144 (0.0142)  lr: 0.000125  max mem: 2403
2022-04-26 16:55:52,215 alphaction.trainer INFO: eta: 5 days, 3:29:30  iter: 6200  loss_pose_action: 0.0000 (0.2937)  loss_object_interaction: 0.0000 (0.0004)  loss_person_interaction: 0.0000 (0.0004)  total_loss: 0.0002 (0.3761)  accuracy_pose_action: 1.0000 (0.8453)  accuracy_object_interaction: 1.0000 (0.9987)  accuracy_person_interaction: 1.0000 (0.9989)  time: 0.5118 (0.5088)  data: 0.0145 (0.0142)  lr: 0.000125  max mem: 2403
2022-04-26 16:55:52,219 alphaction.utils.checkpoint INFO: Saving checkpoint to data/output/resnet50_4x16f_baseline_robalo/model_0006200.pth
2022-04-26 16:55:52,491 alphaction.inference INFO: Start evaluation on lfv_robalo_val_ava_video dataset(135 videos).
2022-04-26 16:56:07,232 alphaction.inference INFO: Total inference time: 0:00:14.740173 (0.10918646565190068 s / video per device, on 1 devices)
2022-04-26 16:56:07,232 alphaction.inference INFO: performing ava evaluation.
2022-04-26 16:56:07,232 alphaction.inference INFO: Preparing results for AVA format
2022-04-26 16:56:07,249 alphaction.inference INFO: Evaluating predictions
2022-04-26 16:56:07,300 alphaction.inference INFO: ==> 0.0507154 seconds to write file /tmp/tmpppi3_56y
2022-04-26 16:56:07,300 alphaction.inference INFO: CATEGORIES (12):
[ {'id': 1, 'name': 'cut (an object)'},
  {'id': 2, 'name': 'holding for (a person)'},
  {'id': 3, 'name': 'handover to (a person)'},
  {'id': 4, 'name': 'squeeze (an object)'},
  {'id': 5, 'name': 'sprinkle (an object)'},
  {'id': 6, 'name': 'transfer (an object)'},
  {'id': 7, 'name': 'pour (an object)'},
  {'id': 8, 'name': 'heat (an object)'},
  {'id': 9, 'name': 'stir (an object)'},
  {'id': 10, 'name': 'wrap (an object)'},
  {'id': 11, 'name': 'roll (an object)'},
  {'id': 12, 'name': 'dip (an object)'}]
2022-04-26 16:56:07,301 alphaction.inference INFO: ==> 0.000469446 seconds to read file data/lfv_robalo/annotations/lfv_robalo_val.csv
2022-04-26 16:56:07,317 alphaction.inference INFO: ==> 0.0162926 seconds to convert groundtruth
2022-04-26 16:56:07,337 alphaction.inference INFO: ==> 0.0197494 seconds to read file /tmp/tmpppi3_56y
2022-04-26 16:56:07,677 alphaction.inference INFO: ==> 0.340356 seconds to convert detections
2022-04-26 16:56:07,678 alphaction.inference INFO: The following classes have no ground truth examples: [ 2  3 10 11 12]
2022-04-26 16:56:07,680 alphaction.inference INFO: ==> 0.00279164 seconds to run_evaluator
2022-04-26 16:56:07,681 alphaction.inference INFO: { 'PascalBoxes_PerformanceByCategory/AP@0.5IOU/cut (an object)': 0.5891274919160197,
  'PascalBoxes_PerformanceByCategory/AP@0.5IOU/dip (an object)': nan,
  'PascalBoxes_PerformanceByCategory/AP@0.5IOU/handover to (a person)': nan,
  'PascalBoxes_PerformanceByCategory/AP@0.5IOU/heat (an object)': 0.7511634060798484,
  'PascalBoxes_PerformanceByCategory/AP@0.5IOU/holding for (a person)': nan,
  'PascalBoxes_PerformanceByCategory/AP@0.5IOU/pour (an object)': 0.12408810325476992,
  'PascalBoxes_PerformanceByCategory/AP@0.5IOU/roll (an object)': nan,
  'PascalBoxes_PerformanceByCategory/AP@0.5IOU/sprinkle (an object)': 0.045454545454545456,
  'PascalBoxes_PerformanceByCategory/AP@0.5IOU/squeeze (an object)': 0.08213667827759907,
  'PascalBoxes_PerformanceByCategory/AP@0.5IOU/stir (an object)': 0.31842251950947603,
  'PascalBoxes_PerformanceByCategory/AP@0.5IOU/transfer (an object)': 0.4815573636069747,
  'PascalBoxes_PerformanceByCategory/AP@0.5IOU/wrap (an object)': nan,
  'PascalBoxes_Precision/mAP@0.5IOU': 0.34170715829989046}
2022-04-26 16:56:17,727 alphaction.trainer INFO: eta: 5 days, 3:29:01  iter: 6220  loss_pose_action: 0.0000 (0.2928)  loss_object_interaction: 0.0000 (0.0004)  loss_person_interaction: 0.0000 (0.0004)  total_loss: 0.0002 (0.3750)  accuracy_pose_action: 1.0000 (0.8457)  accuracy_object_interaction: 1.0000 (0.9987)  accuracy_person_interaction: 1.0000 (0.9989)  time: 0.5004 (0.5088)  data: 0.0144 (0.0142)  lr: 0.000125  max mem: 2403
2022-04-26 16:56:27,914 alphaction.trainer INFO: eta: 5 days, 3:28:52  iter: 6240  loss_pose_action: 0.0000 (0.2919)  loss_object_interaction: 0.0000 (0.0004)  loss_person_interaction: 0.0000 (0.0004)  total_loss: 0.0004 (0.3739)  accuracy_pose_action: 1.0000 (0.8461)  accuracy_object_interaction: 1.0000 (0.9987)  accuracy_person_interaction: 1.0000 (0.9989)  time: 0.5110 (0.5088)  data: 0.0144 (0.0142)  lr: 0.000125  max mem: 2403
2022-04-26 16:56:38,090 alphaction.trainer INFO: eta: 5 days, 3:28:42  iter: 6260  loss_pose_action: 0.0000 (0.2910)  loss_object_interaction: 0.0000 (0.0004)  loss_person_interaction: 0.0000 (0.0004)  total_loss: 0.0001 (0.3727)  accuracy_pose_action: 1.0000 (0.8465)  accuracy_object_interaction: 1.0000 (0.9987)  accuracy_person_interaction: 1.0000 (0.9989)  time: 0.5102 (0.5088)  data: 0.0138 (0.0142)  lr: 0.000125  max mem: 2403
2022-04-26 16:56:48,303 alphaction.trainer INFO: eta: 5 days, 3:28:37  iter: 6280  loss_pose_action: 0.0000 (0.2901)  loss_object_interaction: 0.0000 (0.0004)  loss_person_interaction: 0.0000 (0.0004)  total_loss: 0.0001 (0.3715)  accuracy_pose_action: 1.0000 (0.8470)  accuracy_object_interaction: 1.0000 (0.9987)  accuracy_person_interaction: 1.0000 (0.9989)  time: 0.5131 (0.5088)  data: 0.0141 (0.0142)  lr: 0.000125  max mem: 2403
2022-04-26 16:56:58,519 alphaction.trainer INFO: eta: 5 days, 3:28:33  iter: 6300  loss_pose_action: 0.0000 (0.2891)  loss_object_interaction: 0.0000 (0.0004)  loss_person_interaction: 0.0000 (0.0004)  total_loss: 0.0001 (0.3704)  accuracy_pose_action: 1.0000 (0.8475)  accuracy_object_interaction: 1.0000 (0.9987)  accuracy_person_interaction: 1.0000 (0.9989)  time: 0.5124 (0.5088)  data: 0.0140 (0.0142)  lr: 0.000125  max mem: 2403
2022-04-26 16:56:58,522 alphaction.utils.checkpoint INFO: Saving checkpoint to data/output/resnet50_4x16f_baseline_robalo/model_0006300.pth
2022-04-26 16:56:58,796 alphaction.inference INFO: Start evaluation on lfv_robalo_val_ava_video dataset(135 videos).
2022-04-26 16:57:13,808 alphaction.inference INFO: Total inference time: 0:00:15.011394 (0.11119551128811306 s / video per device, on 1 devices)
2022-04-26 16:57:13,808 alphaction.inference INFO: performing ava evaluation.
2022-04-26 16:57:13,808 alphaction.inference INFO: Preparing results for AVA format
2022-04-26 16:57:13,826 alphaction.inference INFO: Evaluating predictions
2022-04-26 16:57:13,875 alphaction.inference INFO: ==> 0.049623 seconds to write file /tmp/tmpyu0q7wrd
2022-04-26 16:57:13,876 alphaction.inference INFO: CATEGORIES (12):
[ {'id': 1, 'name': 'cut (an object)'},
  {'id': 2, 'name': 'holding for (a person)'},
  {'id': 3, 'name': 'handover to (a person)'},
  {'id': 4, 'name': 'squeeze (an object)'},
  {'id': 5, 'name': 'sprinkle (an object)'},
  {'id': 6, 'name': 'transfer (an object)'},
  {'id': 7, 'name': 'pour (an object)'},
  {'id': 8, 'name': 'heat (an object)'},
  {'id': 9, 'name': 'stir (an object)'},
  {'id': 10, 'name': 'wrap (an object)'},
  {'id': 11, 'name': 'roll (an object)'},
  {'id': 12, 'name': 'dip (an object)'}]
2022-04-26 16:57:13,876 alphaction.inference INFO: ==> 0.00045228 seconds to read file data/lfv_robalo/annotations/lfv_robalo_val.csv
2022-04-26 16:57:13,895 alphaction.inference INFO: ==> 0.0185838 seconds to convert groundtruth
2022-04-26 16:57:13,915 alphaction.inference INFO: ==> 0.0195012 seconds to read file /tmp/tmpyu0q7wrd
2022-04-26 16:57:14,243 alphaction.inference INFO: ==> 0.328714 seconds to convert detections
2022-04-26 16:57:14,244 alphaction.inference INFO: The following classes have no ground truth examples: [ 2  3 10 11 12]
2022-04-26 16:57:14,246 alphaction.inference INFO: ==> 0.00268936 seconds to run_evaluator
2022-04-26 16:57:14,247 alphaction.inference INFO: { 'PascalBoxes_PerformanceByCategory/AP@0.5IOU/cut (an object)': 0.5991755616714978,
  'PascalBoxes_PerformanceByCategory/AP@0.5IOU/dip (an object)': nan,
  'PascalBoxes_PerformanceByCategory/AP@0.5IOU/handover to (a person)': nan,
  'PascalBoxes_PerformanceByCategory/AP@0.5IOU/heat (an object)': 0.8254791693237713,
  'PascalBoxes_PerformanceByCategory/AP@0.5IOU/holding for (a person)': nan,
  'PascalBoxes_PerformanceByCategory/AP@0.5IOU/pour (an object)': 0.10491106256826338,
  'PascalBoxes_PerformanceByCategory/AP@0.5IOU/roll (an object)': nan,
  'PascalBoxes_PerformanceByCategory/AP@0.5IOU/sprinkle (an object)': 0.037037037037037035,
  'PascalBoxes_PerformanceByCategory/AP@0.5IOU/squeeze (an object)': 0.06543127367830813,
  'PascalBoxes_PerformanceByCategory/AP@0.5IOU/stir (an object)': 0.4218786245461183,
  'PascalBoxes_PerformanceByCategory/AP@0.5IOU/transfer (an object)': 0.40796508791923947,
  'PascalBoxes_PerformanceByCategory/AP@0.5IOU/wrap (an object)': nan,
  'PascalBoxes_Precision/mAP@0.5IOU': 0.3516968309634622}
2022-04-26 16:57:24,273 alphaction.trainer INFO: eta: 5 days, 3:28:02  iter: 6320  loss_pose_action: 0.0000 (0.2882)  loss_object_interaction: 0.0000 (0.0003)  loss_person_interaction: 0.0000 (0.0004)  total_loss: 0.0002 (0.3692)  accuracy_pose_action: 1.0000 (0.8480)  accuracy_object_interaction: 1.0000 (0.9987)  accuracy_person_interaction: 1.0000 (0.9989)  time: 0.4988 (0.5087)  data: 0.0134 (0.0142)  lr: 0.000125  max mem: 2403
2022-04-26 16:57:34,442 alphaction.trainer INFO: eta: 5 days, 3:27:51  iter: 6340  loss_pose_action: 0.0000 (0.2873)  loss_object_interaction: 0.0000 (0.0003)  loss_person_interaction: 0.0000 (0.0004)  total_loss: 0.0002 (0.3681)  accuracy_pose_action: 1.0000 (0.8484)  accuracy_object_interaction: 1.0000 (0.9987)  accuracy_person_interaction: 1.0000 (0.9989)  time: 0.5123 (0.5087)  data: 0.0143 (0.0142)  lr: 0.000125  max mem: 2403
2022-04-26 16:57:44,650 alphaction.trainer INFO: eta: 5 days, 3:27:45  iter: 6360  loss_pose_action: 0.0000 (0.2864)  loss_object_interaction: 0.0000 (0.0003)  loss_person_interaction: 0.0000 (0.0004)  total_loss: 0.0003 (0.3669)  accuracy_pose_action: 1.0000 (0.8489)  accuracy_object_interaction: 1.0000 (0.9987)  accuracy_person_interaction: 1.0000 (0.9989)  time: 0.5133 (0.5088)  data: 0.0146 (0.0142)  lr: 0.000125  max mem: 2403
2022-04-26 16:57:54,863 alphaction.trainer INFO: eta: 5 days, 3:27:40  iter: 6380  loss_pose_action: 0.0000 (0.2856)  loss_object_interaction: 0.0000 (0.0003)  loss_person_interaction: 0.0000 (0.0004)  total_loss: 0.0001 (0.3658)  accuracy_pose_action: 1.0000 (0.8494)  accuracy_object_interaction: 1.0000 (0.9987)  accuracy_person_interaction: 1.0000 (0.9989)  time: 0.5125 (0.5088)  data: 0.0141 (0.0142)  lr: 0.000125  max mem: 2403
2022-04-26 16:58:05,057 alphaction.trainer INFO: eta: 5 days, 3:27:32  iter: 6400  loss_pose_action: 0.0000 (0.2847)  loss_object_interaction: 0.0000 (0.0003)  loss_person_interaction: 0.0000 (0.0004)  total_loss: 0.0001 (0.3646)  accuracy_pose_action: 1.0000 (0.8499)  accuracy_object_interaction: 1.0000 (0.9988)  accuracy_person_interaction: 1.0000 (0.9989)  time: 0.5140 (0.5088)  data: 0.0143 (0.0142)  lr: 0.000125  max mem: 2403
2022-04-26 16:58:05,061 alphaction.utils.checkpoint INFO: Saving checkpoint to data/output/resnet50_4x16f_baseline_robalo/model_0006400.pth
2022-04-26 16:58:05,349 alphaction.inference INFO: Start evaluation on lfv_robalo_val_ava_video dataset(135 videos).
2022-04-26 16:58:19,584 alphaction.inference INFO: Total inference time: 0:00:14.235608 (0.10544895066155327 s / video per device, on 1 devices)
2022-04-26 16:58:19,585 alphaction.inference INFO: performing ava evaluation.
2022-04-26 16:58:19,585 alphaction.inference INFO: Preparing results for AVA format
2022-04-26 16:58:19,602 alphaction.inference INFO: Evaluating predictions
2022-04-26 16:58:19,651 alphaction.inference INFO: ==> 0.0490019 seconds to write file /tmp/tmp0iffcpl2
2022-04-26 16:58:19,651 alphaction.inference INFO: CATEGORIES (12):
[ {'id': 1, 'name': 'cut (an object)'},
  {'id': 2, 'name': 'holding for (a person)'},
  {'id': 3, 'name': 'handover to (a person)'},
  {'id': 4, 'name': 'squeeze (an object)'},
  {'id': 5, 'name': 'sprinkle (an object)'},
  {'id': 6, 'name': 'transfer (an object)'},
  {'id': 7, 'name': 'pour (an object)'},
  {'id': 8, 'name': 'heat (an object)'},
  {'id': 9, 'name': 'stir (an object)'},
  {'id': 10, 'name': 'wrap (an object)'},
  {'id': 11, 'name': 'roll (an object)'},
  {'id': 12, 'name': 'dip (an object)'}]
2022-04-26 16:58:19,652 alphaction.inference INFO: ==> 0.000698566 seconds to read file data/lfv_robalo/annotations/lfv_robalo_val.csv
2022-04-26 16:58:19,671 alphaction.inference INFO: ==> 0.0186927 seconds to convert groundtruth
2022-04-26 16:58:19,691 alphaction.inference INFO: ==> 0.0202069 seconds to read file /tmp/tmp0iffcpl2
2022-04-26 16:58:20,028 alphaction.inference INFO: ==> 0.336404 seconds to convert detections
2022-04-26 16:58:20,028 alphaction.inference INFO: The following classes have no ground truth examples: [ 2  3 10 11 12]
2022-04-26 16:58:20,031 alphaction.inference INFO: ==> 0.00276136 seconds to run_evaluator
2022-04-26 16:58:20,032 alphaction.inference INFO: { 'PascalBoxes_PerformanceByCategory/AP@0.5IOU/cut (an object)': 0.6688318770564027,
  'PascalBoxes_PerformanceByCategory/AP@0.5IOU/dip (an object)': nan,
  'PascalBoxes_PerformanceByCategory/AP@0.5IOU/handover to (a person)': nan,
  'PascalBoxes_PerformanceByCategory/AP@0.5IOU/heat (an object)': 0.8240603581420332,
  'PascalBoxes_PerformanceByCategory/AP@0.5IOU/holding for (a person)': nan,
  'PascalBoxes_PerformanceByCategory/AP@0.5IOU/pour (an object)': 0.10919540229885057,
  'PascalBoxes_PerformanceByCategory/AP@0.5IOU/roll (an object)': nan,
  'PascalBoxes_PerformanceByCategory/AP@0.5IOU/sprinkle (an object)': 0.0392156862745098,
  'PascalBoxes_PerformanceByCategory/AP@0.5IOU/squeeze (an object)': 0.06562987012987014,
  'PascalBoxes_PerformanceByCategory/AP@0.5IOU/stir (an object)': 0.4000364219114219,
  'PascalBoxes_PerformanceByCategory/AP@0.5IOU/transfer (an object)': 0.4460820367648926,
  'PascalBoxes_PerformanceByCategory/AP@0.5IOU/wrap (an object)': nan,
  'PascalBoxes_Precision/mAP@0.5IOU': 0.3647216646539973}
2022-04-26 16:58:30,081 alphaction.trainer INFO: eta: 5 days, 3:27:05  iter: 6420  loss_pose_action: 0.0000 (0.2838)  loss_object_interaction: 0.0000 (0.0003)  loss_person_interaction: 0.0000 (0.0004)  total_loss: 0.0001 (0.3635)  accuracy_pose_action: 1.0000 (0.8503)  accuracy_object_interaction: 1.0000 (0.9988)  accuracy_person_interaction: 1.0000 (0.9989)  time: 0.4999 (0.5087)  data: 0.0135 (0.0142)  lr: 0.000125  max mem: 2403
2022-04-26 16:58:40,263 alphaction.trainer INFO: eta: 5 days, 3:26:56  iter: 6440  loss_pose_action: 0.0000 (0.2829)  loss_object_interaction: 0.0000 (0.0003)  loss_person_interaction: 0.0000 (0.0004)  total_loss: 0.0000 (0.3624)  accuracy_pose_action: 1.0000 (0.8508)  accuracy_object_interaction: 1.0000 (0.9988)  accuracy_person_interaction: 1.0000 (0.9989)  time: 0.5128 (0.5087)  data: 0.0143 (0.0142)  lr: 0.000125  max mem: 2403
2022-04-26 16:58:50,457 alphaction.trainer INFO: eta: 5 days, 3:26:48  iter: 6460  loss_pose_action: 0.0000 (0.2820)  loss_object_interaction: 0.0000 (0.0003)  loss_person_interaction: 0.0000 (0.0004)  total_loss: 0.0002 (0.3613)  accuracy_pose_action: 1.0000 (0.8513)  accuracy_object_interaction: 1.0000 (0.9988)  accuracy_person_interaction: 1.0000 (0.9989)  time: 0.5116 (0.5087)  data: 0.0143 (0.0142)  lr: 0.000125  max mem: 2403
2022-04-26 16:59:00,631 alphaction.trainer INFO: eta: 5 days, 3:26:38  iter: 6480  loss_pose_action: 0.0000 (0.2812)  loss_object_interaction: 0.0000 (0.0003)  loss_person_interaction: 0.0000 (0.0004)  total_loss: 0.0001 (0.3602)  accuracy_pose_action: 1.0000 (0.8517)  accuracy_object_interaction: 1.0000 (0.9988)  accuracy_person_interaction: 1.0000 (0.9989)  time: 0.5122 (0.5087)  data: 0.0146 (0.0142)  lr: 0.000125  max mem: 2403
2022-04-26 16:59:10,872 alphaction.trainer INFO: eta: 5 days, 3:26:36  iter: 6500  loss_pose_action: 0.0000 (0.2803)  loss_object_interaction: 0.0000 (0.0003)  loss_person_interaction: 0.0000 (0.0004)  total_loss: 0.0003 (0.3591)  accuracy_pose_action: 1.0000 (0.8522)  accuracy_object_interaction: 1.0000 (0.9988)  accuracy_person_interaction: 1.0000 (0.9989)  time: 0.5130 (0.5088)  data: 0.0147 (0.0142)  lr: 0.000125  max mem: 2403
2022-04-26 16:59:10,877 alphaction.utils.checkpoint INFO: Saving checkpoint to data/output/resnet50_4x16f_baseline_robalo/model_0006500.pth
2022-04-26 16:59:11,152 alphaction.inference INFO: Start evaluation on lfv_robalo_val_ava_video dataset(135 videos).
2022-04-26 16:59:25,742 alphaction.inference INFO: Total inference time: 0:00:14.589417 (0.10806975188078703 s / video per device, on 1 devices)
2022-04-26 16:59:25,742 alphaction.inference INFO: performing ava evaluation.
2022-04-26 16:59:25,742 alphaction.inference INFO: Preparing results for AVA format
2022-04-26 16:59:25,758 alphaction.inference INFO: Evaluating predictions
2022-04-26 16:59:25,807 alphaction.inference INFO: ==> 0.048209 seconds to write file /tmp/tmp1tzyplcz
2022-04-26 16:59:25,807 alphaction.inference INFO: CATEGORIES (12):
[ {'id': 1, 'name': 'cut (an object)'},
  {'id': 2, 'name': 'holding for (a person)'},
  {'id': 3, 'name': 'handover to (a person)'},
  {'id': 4, 'name': 'squeeze (an object)'},
  {'id': 5, 'name': 'sprinkle (an object)'},
  {'id': 6, 'name': 'transfer (an object)'},
  {'id': 7, 'name': 'pour (an object)'},
  {'id': 8, 'name': 'heat (an object)'},
  {'id': 9, 'name': 'stir (an object)'},
  {'id': 10, 'name': 'wrap (an object)'},
  {'id': 11, 'name': 'roll (an object)'},
  {'id': 12, 'name': 'dip (an object)'}]
2022-04-26 16:59:25,808 alphaction.inference INFO: ==> 0.000451326 seconds to read file data/lfv_robalo/annotations/lfv_robalo_val.csv
2022-04-26 16:59:25,825 alphaction.inference INFO: ==> 0.017513 seconds to convert groundtruth
2022-04-26 16:59:25,845 alphaction.inference INFO: ==> 0.0191143 seconds to read file /tmp/tmp1tzyplcz
2022-04-26 16:59:26,174 alphaction.inference INFO: ==> 0.329069 seconds to convert detections
2022-04-26 16:59:26,174 alphaction.inference INFO: The following classes have no ground truth examples: [ 2  3 10 11 12]
2022-04-26 16:59:26,177 alphaction.inference INFO: ==> 0.00267005 seconds to run_evaluator
2022-04-26 16:59:26,177 alphaction.inference INFO: { 'PascalBoxes_PerformanceByCategory/AP@0.5IOU/cut (an object)': 0.709722758807427,
  'PascalBoxes_PerformanceByCategory/AP@0.5IOU/dip (an object)': nan,
  'PascalBoxes_PerformanceByCategory/AP@0.5IOU/handover to (a person)': nan,
  'PascalBoxes_PerformanceByCategory/AP@0.5IOU/heat (an object)': 0.8043646564048869,
  'PascalBoxes_PerformanceByCategory/AP@0.5IOU/holding for (a person)': nan,
  'PascalBoxes_PerformanceByCategory/AP@0.5IOU/pour (an object)': 0.1075268817204301,
  'PascalBoxes_PerformanceByCategory/AP@0.5IOU/roll (an object)': nan,
  'PascalBoxes_PerformanceByCategory/AP@0.5IOU/sprinkle (an object)': 0.043478260869565216,
  'PascalBoxes_PerformanceByCategory/AP@0.5IOU/squeeze (an object)': 0.07903536649181248,
  'PascalBoxes_PerformanceByCategory/AP@0.5IOU/stir (an object)': 0.40539961189227797,
  'PascalBoxes_PerformanceByCategory/AP@0.5IOU/transfer (an object)': 0.458930581190407,
  'PascalBoxes_PerformanceByCategory/AP@0.5IOU/wrap (an object)': nan,
  'PascalBoxes_Precision/mAP@0.5IOU': 0.3726368739109724}
2022-04-26 16:59:36,288 alphaction.trainer INFO: eta: 5 days, 3:26:17  iter: 6520  loss_pose_action: 0.0000 (0.2794)  loss_object_interaction: 0.0000 (0.0003)  loss_person_interaction: 0.0000 (0.0004)  total_loss: 0.0001 (0.3580)  accuracy_pose_action: 1.0000 (0.8526)  accuracy_object_interaction: 1.0000 (0.9988)  accuracy_person_interaction: 1.0000 (0.9989)  time: 0.5036 (0.5087)  data: 0.0142 (0.0142)  lr: 0.000125  max mem: 2403
2022-04-26 16:59:46,447 alphaction.trainer INFO: eta: 5 days, 3:26:05  iter: 6540  loss_pose_action: 0.0000 (0.2786)  loss_object_interaction: 0.0000 (0.0003)  loss_person_interaction: 0.0000 (0.0004)  total_loss: 0.0001 (0.3569)  accuracy_pose_action: 1.0000 (0.8531)  accuracy_object_interaction: 1.0000 (0.9988)  accuracy_person_interaction: 1.0000 (0.9989)  time: 0.5110 (0.5087)  data: 0.0144 (0.0142)  lr: 0.000125  max mem: 2403
2022-04-26 16:59:56,640 alphaction.trainer INFO: eta: 5 days, 3:25:57  iter: 6560  loss_pose_action: 0.0000 (0.2777)  loss_object_interaction: 0.0000 (0.0003)  loss_person_interaction: 0.0000 (0.0004)  total_loss: 0.0000 (0.3558)  accuracy_pose_action: 1.0000 (0.8535)  accuracy_object_interaction: 1.0000 (0.9988)  accuracy_person_interaction: 1.0000 (0.9989)  time: 0.5126 (0.5087)  data: 0.0142 (0.0142)  lr: 0.000125  max mem: 2403
2022-04-26 17:00:06,883 alphaction.trainer INFO: eta: 5 days, 3:25:56  iter: 6580  loss_pose_action: 0.0000 (0.2769)  loss_object_interaction: 0.0000 (0.0003)  loss_person_interaction: 0.0000 (0.0003)  total_loss: 0.0001 (0.3547)  accuracy_pose_action: 1.0000 (0.8540)  accuracy_object_interaction: 1.0000 (0.9988)  accuracy_person_interaction: 1.0000 (0.9989)  time: 0.5132 (0.5088)  data: 0.0142 (0.0142)  lr: 0.000125  max mem: 2403
2022-04-26 17:00:17,113 alphaction.trainer INFO: eta: 5 days, 3:25:53  iter: 6600  loss_pose_action: 0.0000 (0.2761)  loss_object_interaction: 0.0000 (0.0003)  loss_person_interaction: 0.0000 (0.0003)  total_loss: 0.0001 (0.3536)  accuracy_pose_action: 1.0000 (0.8544)  accuracy_object_interaction: 1.0000 (0.9988)  accuracy_person_interaction: 1.0000 (0.9989)  time: 0.5132 (0.5088)  data: 0.0141 (0.0142)  lr: 0.000125  max mem: 2403
2022-04-26 17:00:17,117 alphaction.utils.checkpoint INFO: Saving checkpoint to data/output/resnet50_4x16f_baseline_robalo/model_0006600.pth
2022-04-26 17:00:17,382 alphaction.inference INFO: Start evaluation on lfv_robalo_val_ava_video dataset(135 videos).
2022-04-26 17:00:31,840 alphaction.inference INFO: Total inference time: 0:00:14.457660 (0.10709378101207592 s / video per device, on 1 devices)
2022-04-26 17:00:31,840 alphaction.inference INFO: performing ava evaluation.
2022-04-26 17:00:31,840 alphaction.inference INFO: Preparing results for AVA format
2022-04-26 17:00:31,857 alphaction.inference INFO: Evaluating predictions
2022-04-26 17:00:31,907 alphaction.inference INFO: ==> 0.0502052 seconds to write file /tmp/tmpgwfkch3v
2022-04-26 17:00:31,908 alphaction.inference INFO: CATEGORIES (12):
[ {'id': 1, 'name': 'cut (an object)'},
  {'id': 2, 'name': 'holding for (a person)'},
  {'id': 3, 'name': 'handover to (a person)'},
  {'id': 4, 'name': 'squeeze (an object)'},
  {'id': 5, 'name': 'sprinkle (an object)'},
  {'id': 6, 'name': 'transfer (an object)'},
  {'id': 7, 'name': 'pour (an object)'},
  {'id': 8, 'name': 'heat (an object)'},
  {'id': 9, 'name': 'stir (an object)'},
  {'id': 10, 'name': 'wrap (an object)'},
  {'id': 11, 'name': 'roll (an object)'},
  {'id': 12, 'name': 'dip (an object)'}]
2022-04-26 17:00:31,908 alphaction.inference INFO: ==> 0.00048852 seconds to read file data/lfv_robalo/annotations/lfv_robalo_val.csv
2022-04-26 17:00:31,925 alphaction.inference INFO: ==> 0.0162647 seconds to convert groundtruth
2022-04-26 17:00:31,944 alphaction.inference INFO: ==> 0.0195045 seconds to read file /tmp/tmpgwfkch3v
2022-04-26 17:00:32,281 alphaction.inference INFO: ==> 0.336927 seconds to convert detections
2022-04-26 17:00:32,282 alphaction.inference INFO: The following classes have no ground truth examples: [ 2  3 10 11 12]
2022-04-26 17:00:32,284 alphaction.inference INFO: ==> 0.00279737 seconds to run_evaluator
2022-04-26 17:00:32,285 alphaction.inference INFO: { 'PascalBoxes_PerformanceByCategory/AP@0.5IOU/cut (an object)': 0.7074959998099047,
  'PascalBoxes_PerformanceByCategory/AP@0.5IOU/dip (an object)': nan,
  'PascalBoxes_PerformanceByCategory/AP@0.5IOU/handover to (a person)': nan,
  'PascalBoxes_PerformanceByCategory/AP@0.5IOU/heat (an object)': 0.795186687957349,
  'PascalBoxes_PerformanceByCategory/AP@0.5IOU/holding for (a person)': nan,
  'PascalBoxes_PerformanceByCategory/AP@0.5IOU/pour (an object)': 0.1075268817204301,
  'PascalBoxes_PerformanceByCategory/AP@0.5IOU/roll (an object)': nan,
  'PascalBoxes_PerformanceByCategory/AP@0.5IOU/sprinkle (an object)': 0.041666666666666664,
  'PascalBoxes_PerformanceByCategory/AP@0.5IOU/squeeze (an object)': 0.07859009605267622,
  'PascalBoxes_PerformanceByCategory/AP@0.5IOU/stir (an object)': 0.40476004325749654,
  'PascalBoxes_PerformanceByCategory/AP@0.5IOU/transfer (an object)': 0.46299898786811305,
  'PascalBoxes_PerformanceByCategory/AP@0.5IOU/wrap (an object)': nan,
  'PascalBoxes_Precision/mAP@0.5IOU': 0.3711750519046624}
2022-04-26 17:00:42,370 alphaction.trainer INFO: eta: 5 days, 3:25:31  iter: 6620  loss_pose_action: 0.0000 (0.2752)  loss_object_interaction: 0.0000 (0.0003)  loss_person_interaction: 0.0000 (0.0003)  total_loss: 0.0000 (0.3526)  accuracy_pose_action: 1.0000 (0.8548)  accuracy_object_interaction: 1.0000 (0.9988)  accuracy_person_interaction: 1.0000 (0.9989)  time: 0.5040 (0.5087)  data: 0.0140 (0.0142)  lr: 0.000125  max mem: 2403
2022-04-26 17:00:52,479 alphaction.trainer INFO: eta: 5 days, 3:25:12  iter: 6640  loss_pose_action: 0.0000 (0.2744)  loss_object_interaction: 0.0000 (0.0003)  loss_person_interaction: 0.0000 (0.0003)  total_loss: 0.0001 (0.3515)  accuracy_pose_action: 1.0000 (0.8553)  accuracy_object_interaction: 1.0000 (0.9988)  accuracy_person_interaction: 1.0000 (0.9989)  time: 0.5090 (0.5087)  data: 0.0145 (0.0142)  lr: 0.000125  max mem: 2403
2022-04-26 17:01:02,685 alphaction.trainer INFO: eta: 5 days, 3:25:06  iter: 6660  loss_pose_action: 0.0000 (0.2736)  loss_object_interaction: 0.0000 (0.0003)  loss_person_interaction: 0.0000 (0.0003)  total_loss: 0.0000 (0.3505)  accuracy_pose_action: 1.0000 (0.8556)  accuracy_object_interaction: 1.0000 (0.9988)  accuracy_person_interaction: 1.0000 (0.9989)  time: 0.5133 (0.5087)  data: 0.0145 (0.0142)  lr: 0.000125  max mem: 2403
2022-04-26 17:01:12,929 alphaction.trainer INFO: eta: 5 days, 3:25:05  iter: 6680  loss_pose_action: 0.0000 (0.2728)  loss_object_interaction: 0.0000 (0.0003)  loss_person_interaction: 0.0000 (0.0003)  total_loss: 0.0001 (0.3495)  accuracy_pose_action: 1.0000 (0.8561)  accuracy_object_interaction: 1.0000 (0.9988)  accuracy_person_interaction: 1.0000 (0.9990)  time: 0.5136 (0.5088)  data: 0.0142 (0.0142)  lr: 0.000125  max mem: 2403
2022-04-26 17:01:23,170 alphaction.trainer INFO: eta: 5 days, 3:25:03  iter: 6700  loss_pose_action: 0.0000 (0.2720)  loss_object_interaction: 0.0000 (0.0003)  loss_person_interaction: 0.0000 (0.0003)  total_loss: 0.0001 (0.3484)  accuracy_pose_action: 1.0000 (0.8565)  accuracy_object_interaction: 1.0000 (0.9988)  accuracy_person_interaction: 1.0000 (0.9990)  time: 0.5125 (0.5088)  data: 0.0144 (0.0142)  lr: 0.000125  max mem: 2403
2022-04-26 17:01:23,173 alphaction.utils.checkpoint INFO: Saving checkpoint to data/output/resnet50_4x16f_baseline_robalo/model_0006700.pth
2022-04-26 17:01:23,436 alphaction.inference INFO: Start evaluation on lfv_robalo_val_ava_video dataset(135 videos).
2022-04-26 17:01:38,612 alphaction.inference INFO: Total inference time: 0:00:15.176298 (0.11241701973809136 s / video per device, on 1 devices)
2022-04-26 17:01:38,612 alphaction.inference INFO: performing ava evaluation.
2022-04-26 17:01:38,612 alphaction.inference INFO: Preparing results for AVA format
2022-04-26 17:01:38,629 alphaction.inference INFO: Evaluating predictions
2022-04-26 17:01:38,680 alphaction.inference INFO: ==> 0.0511985 seconds to write file /tmp/tmpp1hx_hp4
2022-04-26 17:01:38,681 alphaction.inference INFO: CATEGORIES (12):
[ {'id': 1, 'name': 'cut (an object)'},
  {'id': 2, 'name': 'holding for (a person)'},
  {'id': 3, 'name': 'handover to (a person)'},
  {'id': 4, 'name': 'squeeze (an object)'},
  {'id': 5, 'name': 'sprinkle (an object)'},
  {'id': 6, 'name': 'transfer (an object)'},
  {'id': 7, 'name': 'pour (an object)'},
  {'id': 8, 'name': 'heat (an object)'},
  {'id': 9, 'name': 'stir (an object)'},
  {'id': 10, 'name': 'wrap (an object)'},
  {'id': 11, 'name': 'roll (an object)'},
  {'id': 12, 'name': 'dip (an object)'}]
2022-04-26 17:01:38,681 alphaction.inference INFO: ==> 0.000424862 seconds to read file data/lfv_robalo/annotations/lfv_robalo_val.csv
2022-04-26 17:01:38,698 alphaction.inference INFO: ==> 0.0162508 seconds to convert groundtruth
2022-04-26 17:01:38,717 alphaction.inference INFO: ==> 0.0189743 seconds to read file /tmp/tmpp1hx_hp4
2022-04-26 17:01:39,056 alphaction.inference INFO: ==> 0.339598 seconds to convert detections
2022-04-26 17:01:39,056 alphaction.inference INFO: The following classes have no ground truth examples: [ 2  3 10 11 12]
2022-04-26 17:01:39,061 alphaction.inference INFO: ==> 0.00428915 seconds to run_evaluator
2022-04-26 17:01:39,062 alphaction.inference INFO: { 'PascalBoxes_PerformanceByCategory/AP@0.5IOU/cut (an object)': 0.7021461932309446,
  'PascalBoxes_PerformanceByCategory/AP@0.5IOU/dip (an object)': nan,
  'PascalBoxes_PerformanceByCategory/AP@0.5IOU/handover to (a person)': nan,
  'PascalBoxes_PerformanceByCategory/AP@0.5IOU/heat (an object)': 0.7118675226904043,
  'PascalBoxes_PerformanceByCategory/AP@0.5IOU/holding for (a person)': nan,
  'PascalBoxes_PerformanceByCategory/AP@0.5IOU/pour (an object)': 0.11416490486257927,
  'PascalBoxes_PerformanceByCategory/AP@0.5IOU/roll (an object)': nan,
  'PascalBoxes_PerformanceByCategory/AP@0.5IOU/sprinkle (an object)': 0.047619047619047616,
  'PascalBoxes_PerformanceByCategory/AP@0.5IOU/squeeze (an object)': 0.09126678406339422,
  'PascalBoxes_PerformanceByCategory/AP@0.5IOU/stir (an object)': 0.38788860711937634,
  'PascalBoxes_PerformanceByCategory/AP@0.5IOU/transfer (an object)': 0.4422857846964963,
  'PascalBoxes_PerformanceByCategory/AP@0.5IOU/wrap (an object)': nan,
  'PascalBoxes_Precision/mAP@0.5IOU': 0.35674840632603466}
2022-04-26 17:01:49,090 alphaction.trainer INFO: eta: 5 days, 3:24:34  iter: 6720  loss_pose_action: 0.0000 (0.2712)  loss_object_interaction: 0.0000 (0.0003)  loss_person_interaction: 0.0000 (0.0003)  total_loss: 0.0002 (0.3474)  accuracy_pose_action: 1.0000 (0.8568)  accuracy_object_interaction: 1.0000 (0.9988)  accuracy_person_interaction: 1.0000 (0.9990)  time: 0.4997 (0.5087)  data: 0.0135 (0.0142)  lr: 0.000125  max mem: 2403
2022-04-26 17:01:59,262 alphaction.trainer INFO: eta: 5 days, 3:24:23  iter: 6740  loss_pose_action: 0.0000 (0.2705)  loss_object_interaction: 0.0000 (0.0003)  loss_person_interaction: 0.0000 (0.0003)  total_loss: 0.0000 (0.3464)  accuracy_pose_action: 1.0000 (0.8572)  accuracy_object_interaction: 1.0000 (0.9988)  accuracy_person_interaction: 1.0000 (0.9990)  time: 0.5121 (0.5087)  data: 0.0143 (0.0142)  lr: 0.000125  max mem: 2403
2022-04-26 17:02:09,435 alphaction.trainer INFO: eta: 5 days, 3:24:13  iter: 6760  loss_pose_action: 0.0000 (0.2697)  loss_object_interaction: 0.0000 (0.0003)  loss_person_interaction: 0.0000 (0.0003)  total_loss: 0.0001 (0.3454)  accuracy_pose_action: 1.0000 (0.8576)  accuracy_object_interaction: 1.0000 (0.9988)  accuracy_person_interaction: 1.0000 (0.9990)  time: 0.5121 (0.5087)  data: 0.0138 (0.0142)  lr: 0.000125  max mem: 2403
2022-04-26 17:02:19,625 alphaction.trainer INFO: eta: 5 days, 3:24:05  iter: 6780  loss_pose_action: 0.0000 (0.2689)  loss_object_interaction: 0.0000 (0.0003)  loss_person_interaction: 0.0000 (0.0003)  total_loss: 0.0001 (0.3444)  accuracy_pose_action: 1.0000 (0.8580)  accuracy_object_interaction: 1.0000 (0.9988)  accuracy_person_interaction: 1.0000 (0.9990)  time: 0.5119 (0.5087)  data: 0.0141 (0.0142)  lr: 0.000125  max mem: 2403
2022-04-26 17:02:29,830 alphaction.trainer INFO: eta: 5 days, 3:23:58  iter: 6800  loss_pose_action: 0.0000 (0.2681)  loss_object_interaction: 0.0000 (0.0003)  loss_person_interaction: 0.0000 (0.0003)  total_loss: 0.0000 (0.3434)  accuracy_pose_action: 1.0000 (0.8585)  accuracy_object_interaction: 1.0000 (0.9988)  accuracy_person_interaction: 1.0000 (0.9990)  time: 0.5136 (0.5087)  data: 0.0144 (0.0142)  lr: 0.000125  max mem: 2403
2022-04-26 17:02:29,834 alphaction.utils.checkpoint INFO: Saving checkpoint to data/output/resnet50_4x16f_baseline_robalo/model_0006800.pth
2022-04-26 17:02:30,096 alphaction.inference INFO: Start evaluation on lfv_robalo_val_ava_video dataset(135 videos).
2022-04-26 17:02:45,126 alphaction.inference INFO: Total inference time: 0:00:15.029527 (0.11132983101738823 s / video per device, on 1 devices)
2022-04-26 17:02:45,126 alphaction.inference INFO: performing ava evaluation.
2022-04-26 17:02:45,126 alphaction.inference INFO: Preparing results for AVA format
2022-04-26 17:02:45,143 alphaction.inference INFO: Evaluating predictions
2022-04-26 17:02:45,193 alphaction.inference INFO: ==> 0.0504274 seconds to write file /tmp/tmpjvl_okcj
2022-04-26 17:02:45,194 alphaction.inference INFO: CATEGORIES (12):
[ {'id': 1, 'name': 'cut (an object)'},
  {'id': 2, 'name': 'holding for (a person)'},
  {'id': 3, 'name': 'handover to (a person)'},
  {'id': 4, 'name': 'squeeze (an object)'},
  {'id': 5, 'name': 'sprinkle (an object)'},
  {'id': 6, 'name': 'transfer (an object)'},
  {'id': 7, 'name': 'pour (an object)'},
  {'id': 8, 'name': 'heat (an object)'},
  {'id': 9, 'name': 'stir (an object)'},
  {'id': 10, 'name': 'wrap (an object)'},
  {'id': 11, 'name': 'roll (an object)'},
  {'id': 12, 'name': 'dip (an object)'}]
2022-04-26 17:02:45,195 alphaction.inference INFO: ==> 0.000658751 seconds to read file data/lfv_robalo/annotations/lfv_robalo_val.csv
2022-04-26 17:02:45,211 alphaction.inference INFO: ==> 0.0166941 seconds to convert groundtruth
2022-04-26 17:02:45,231 alphaction.inference INFO: ==> 0.0192006 seconds to read file /tmp/tmpjvl_okcj
2022-04-26 17:02:45,568 alphaction.inference INFO: ==> 0.337481 seconds to convert detections
2022-04-26 17:02:45,568 alphaction.inference INFO: The following classes have no ground truth examples: [ 2  3 10 11 12]
2022-04-26 17:02:45,571 alphaction.inference INFO: ==> 0.00283861 seconds to run_evaluator
2022-04-26 17:02:45,572 alphaction.inference INFO: { 'PascalBoxes_PerformanceByCategory/AP@0.5IOU/cut (an object)': 0.6738419082205185,
  'PascalBoxes_PerformanceByCategory/AP@0.5IOU/dip (an object)': nan,
  'PascalBoxes_PerformanceByCategory/AP@0.5IOU/handover to (a person)': nan,
  'PascalBoxes_PerformanceByCategory/AP@0.5IOU/heat (an object)': 0.7563211517911531,
  'PascalBoxes_PerformanceByCategory/AP@0.5IOU/holding for (a person)': nan,
  'PascalBoxes_PerformanceByCategory/AP@0.5IOU/pour (an object)': 0.11115942028985507,
  'PascalBoxes_PerformanceByCategory/AP@0.5IOU/roll (an object)': nan,
  'PascalBoxes_PerformanceByCategory/AP@0.5IOU/sprinkle (an object)': 0.05405405405405406,
  'PascalBoxes_PerformanceByCategory/AP@0.5IOU/squeeze (an object)': 0.08246687788018434,
  'PascalBoxes_PerformanceByCategory/AP@0.5IOU/stir (an object)': 0.31933278997217623,
  'PascalBoxes_PerformanceByCategory/AP@0.5IOU/transfer (an object)': 0.42909684126543524,
  'PascalBoxes_PerformanceByCategory/AP@0.5IOU/wrap (an object)': nan,
  'PascalBoxes_Precision/mAP@0.5IOU': 0.34661043478191095}
2022-04-26 17:02:55,610 alphaction.trainer INFO: eta: 5 days, 3:23:30  iter: 6820  loss_pose_action: 0.0000 (0.2673)  loss_object_interaction: 0.0000 (0.0003)  loss_person_interaction: 0.0000 (0.0003)  total_loss: 0.0001 (0.3424)  accuracy_pose_action: 1.0000 (0.8589)  accuracy_object_interaction: 1.0000 (0.9988)  accuracy_person_interaction: 1.0000 (0.9990)  time: 0.4979 (0.5087)  data: 0.0138 (0.0142)  lr: 0.000125  max mem: 2403
2022-04-26 17:03:05,774 alphaction.trainer INFO: eta: 5 days, 3:23:19  iter: 6840  loss_pose_action: 0.0000 (0.2665)  loss_object_interaction: 0.0000 (0.0003)  loss_person_interaction: 0.0000 (0.0003)  total_loss: 0.0000 (0.3414)  accuracy_pose_action: 1.0000 (0.8593)  accuracy_object_interaction: 1.0000 (0.9988)  accuracy_person_interaction: 1.0000 (0.9990)  time: 0.5098 (0.5087)  data: 0.0146 (0.0142)  lr: 0.000125  max mem: 2403
2022-04-26 17:03:16,015 alphaction.trainer INFO: eta: 5 days, 3:23:17  iter: 6860  loss_pose_action: 0.0000 (0.2657)  loss_object_interaction: 0.0000 (0.0003)  loss_person_interaction: 0.0000 (0.0003)  total_loss: 0.0000 (0.3404)  accuracy_pose_action: 1.0000 (0.8597)  accuracy_object_interaction: 1.0000 (0.9988)  accuracy_person_interaction: 1.0000 (0.9990)  time: 0.5129 (0.5087)  data: 0.0144 (0.0142)  lr: 0.000125  max mem: 2403
2022-04-26 17:03:26,210 alphaction.trainer INFO: eta: 5 days, 3:23:10  iter: 6880  loss_pose_action: 0.0000 (0.2650)  loss_object_interaction: 0.0000 (0.0003)  loss_person_interaction: 0.0000 (0.0003)  total_loss: 0.0000 (0.3394)  accuracy_pose_action: 1.0000 (0.8601)  accuracy_object_interaction: 1.0000 (0.9988)  accuracy_person_interaction: 1.0000 (0.9990)  time: 0.5121 (0.5087)  data: 0.0145 (0.0142)  lr: 0.000125  max mem: 2403
2022-04-26 17:03:36,400 alphaction.trainer INFO: eta: 5 days, 3:23:01  iter: 6900  loss_pose_action: 0.0000 (0.2642)  loss_object_interaction: 0.0000 (0.0003)  loss_person_interaction: 0.0000 (0.0003)  total_loss: 0.0000 (0.3385)  accuracy_pose_action: 1.0000 (0.8605)  accuracy_object_interaction: 1.0000 (0.9988)  accuracy_person_interaction: 1.0000 (0.9990)  time: 0.5135 (0.5087)  data: 0.0145 (0.0142)  lr: 0.000125  max mem: 2403
2022-04-26 17:03:36,404 alphaction.utils.checkpoint INFO: Saving checkpoint to data/output/resnet50_4x16f_baseline_robalo/model_0006900.pth
2022-04-26 17:03:36,657 alphaction.inference INFO: Start evaluation on lfv_robalo_val_ava_video dataset(135 videos).
2022-04-26 17:03:51,196 alphaction.inference INFO: Total inference time: 0:00:14.538800 (0.10769481482329192 s / video per device, on 1 devices)
2022-04-26 17:03:51,196 alphaction.inference INFO: performing ava evaluation.
2022-04-26 17:03:51,196 alphaction.inference INFO: Preparing results for AVA format
2022-04-26 17:03:51,213 alphaction.inference INFO: Evaluating predictions
2022-04-26 17:03:51,262 alphaction.inference INFO: ==> 0.0491657 seconds to write file /tmp/tmpyqypt57n
2022-04-26 17:03:51,263 alphaction.inference INFO: CATEGORIES (12):
[ {'id': 1, 'name': 'cut (an object)'},
  {'id': 2, 'name': 'holding for (a person)'},
  {'id': 3, 'name': 'handover to (a person)'},
  {'id': 4, 'name': 'squeeze (an object)'},
  {'id': 5, 'name': 'sprinkle (an object)'},
  {'id': 6, 'name': 'transfer (an object)'},
  {'id': 7, 'name': 'pour (an object)'},
  {'id': 8, 'name': 'heat (an object)'},
  {'id': 9, 'name': 'stir (an object)'},
  {'id': 10, 'name': 'wrap (an object)'},
  {'id': 11, 'name': 'roll (an object)'},
  {'id': 12, 'name': 'dip (an object)'}]
2022-04-26 17:03:51,263 alphaction.inference INFO: ==> 0.000756264 seconds to read file data/lfv_robalo/annotations/lfv_robalo_val.csv
2022-04-26 17:03:51,280 alphaction.inference INFO: ==> 0.0167572 seconds to convert groundtruth
2022-04-26 17:03:51,300 alphaction.inference INFO: ==> 0.0194664 seconds to read file /tmp/tmpyqypt57n
2022-04-26 17:03:51,633 alphaction.inference INFO: ==> 0.333081 seconds to convert detections
2022-04-26 17:03:51,633 alphaction.inference INFO: The following classes have no ground truth examples: [ 2  3 10 11 12]
2022-04-26 17:03:51,636 alphaction.inference INFO: ==> 0.00267172 seconds to run_evaluator
2022-04-26 17:03:51,637 alphaction.inference INFO: { 'PascalBoxes_PerformanceByCategory/AP@0.5IOU/cut (an object)': 0.6789865177771767,
  'PascalBoxes_PerformanceByCategory/AP@0.5IOU/dip (an object)': nan,
  'PascalBoxes_PerformanceByCategory/AP@0.5IOU/handover to (a person)': nan,
  'PascalBoxes_PerformanceByCategory/AP@0.5IOU/heat (an object)': 0.7498945706723669,
  'PascalBoxes_PerformanceByCategory/AP@0.5IOU/holding for (a person)': nan,
  'PascalBoxes_PerformanceByCategory/AP@0.5IOU/pour (an object)': 0.11027765338110165,
  'PascalBoxes_PerformanceByCategory/AP@0.5IOU/roll (an object)': nan,
  'PascalBoxes_PerformanceByCategory/AP@0.5IOU/sprinkle (an object)': 0.058823529411764705,
  'PascalBoxes_PerformanceByCategory/AP@0.5IOU/squeeze (an object)': 0.08142974738900036,
  'PascalBoxes_PerformanceByCategory/AP@0.5IOU/stir (an object)': 0.29296585767174,
  'PascalBoxes_PerformanceByCategory/AP@0.5IOU/transfer (an object)': 0.4653621900815879,
  'PascalBoxes_PerformanceByCategory/AP@0.5IOU/wrap (an object)': nan,
  'PascalBoxes_Precision/mAP@0.5IOU': 0.3482485809121054}
2022-04-26 17:04:01,689 alphaction.trainer INFO: eta: 5 days, 3:22:35  iter: 6920  loss_pose_action: 0.0000 (0.2635)  loss_object_interaction: 0.0000 (0.0003)  loss_person_interaction: 0.0000 (0.0003)  total_loss: 0.0001 (0.3376)  accuracy_pose_action: 1.0000 (0.8608)  accuracy_object_interaction: 1.0000 (0.9988)  accuracy_person_interaction: 1.0000 (0.9990)  time: 0.4997 (0.5087)  data: 0.0144 (0.0142)  lr: 0.000125  max mem: 2403
2022-04-26 17:04:11,839 alphaction.trainer INFO: eta: 5 days, 3:22:22  iter: 6940  loss_pose_action: 0.0000 (0.2630)  loss_object_interaction: 0.0000 (0.0003)  loss_person_interaction: 0.0000 (0.0003)  total_loss: 0.0002 (0.3368)  accuracy_pose_action: 1.0000 (0.8611)  accuracy_object_interaction: 1.0000 (0.9988)  accuracy_person_interaction: 1.0000 (0.9990)  time: 0.5112 (0.5087)  data: 0.0141 (0.0142)  lr: 0.000125  max mem: 2403
2022-04-26 17:04:22,010 alphaction.trainer INFO: eta: 5 days, 3:22:12  iter: 6960  loss_pose_action: 0.0000 (0.2622)  loss_object_interaction: 0.0000 (0.0003)  loss_person_interaction: 0.0000 (0.0003)  total_loss: 0.0001 (0.3359)  accuracy_pose_action: 1.0000 (0.8615)  accuracy_object_interaction: 1.0000 (0.9989)  accuracy_person_interaction: 1.0000 (0.9990)  time: 0.5108 (0.5087)  data: 0.0145 (0.0142)  lr: 0.000125  max mem: 2403
2022-04-26 17:04:32,199 alphaction.trainer INFO: eta: 5 days, 3:22:03  iter: 6980  loss_pose_action: 0.0000 (0.2615)  loss_object_interaction: 0.0000 (0.0003)  loss_person_interaction: 0.0000 (0.0003)  total_loss: 0.0001 (0.3350)  accuracy_pose_action: 1.0000 (0.8618)  accuracy_object_interaction: 1.0000 (0.9989)  accuracy_person_interaction: 1.0000 (0.9990)  time: 0.5119 (0.5087)  data: 0.0135 (0.0142)  lr: 0.000125  max mem: 2403
2022-04-26 17:04:42,434 alphaction.trainer INFO: eta: 5 days, 3:22:01  iter: 7000  loss_pose_action: 0.0000 (0.2610)  loss_object_interaction: 0.0000 (0.0003)  loss_person_interaction: 0.0000 (0.0003)  total_loss: 0.0001 (0.3343)  accuracy_pose_action: 1.0000 (0.8622)  accuracy_object_interaction: 1.0000 (0.9989)  accuracy_person_interaction: 1.0000 (0.9990)  time: 0.5135 (0.5087)  data: 0.0144 (0.0142)  lr: 0.000125  max mem: 2403
2022-04-26 17:04:42,437 alphaction.utils.checkpoint INFO: Saving checkpoint to data/output/resnet50_4x16f_baseline_robalo/model_0007000.pth
2022-04-26 17:04:42,699 alphaction.inference INFO: Start evaluation on lfv_robalo_val_ava_video dataset(135 videos).
2022-04-26 17:04:57,564 alphaction.inference INFO: Total inference time: 0:00:14.864399 (0.11010666070161042 s / video per device, on 1 devices)
2022-04-26 17:04:57,564 alphaction.inference INFO: performing ava evaluation.
2022-04-26 17:04:57,564 alphaction.inference INFO: Preparing results for AVA format
2022-04-26 17:04:57,580 alphaction.inference INFO: Evaluating predictions
2022-04-26 17:04:57,631 alphaction.inference INFO: ==> 0.0501659 seconds to write file /tmp/tmp5n2y46ou
2022-04-26 17:04:57,631 alphaction.inference INFO: CATEGORIES (12):
[ {'id': 1, 'name': 'cut (an object)'},
  {'id': 2, 'name': 'holding for (a person)'},
  {'id': 3, 'name': 'handover to (a person)'},
  {'id': 4, 'name': 'squeeze (an object)'},
  {'id': 5, 'name': 'sprinkle (an object)'},
  {'id': 6, 'name': 'transfer (an object)'},
  {'id': 7, 'name': 'pour (an object)'},
  {'id': 8, 'name': 'heat (an object)'},
  {'id': 9, 'name': 'stir (an object)'},
  {'id': 10, 'name': 'wrap (an object)'},
  {'id': 11, 'name': 'roll (an object)'},
  {'id': 12, 'name': 'dip (an object)'}]
2022-04-26 17:04:57,632 alphaction.inference INFO: ==> 0.000831842 seconds to read file data/lfv_robalo/annotations/lfv_robalo_val.csv
2022-04-26 17:04:57,649 alphaction.inference INFO: ==> 0.0164483 seconds to convert groundtruth
2022-04-26 17:04:57,670 alphaction.inference INFO: ==> 0.0213768 seconds to read file /tmp/tmp5n2y46ou
2022-04-26 17:04:58,003 alphaction.inference INFO: ==> 0.332808 seconds to convert detections
2022-04-26 17:04:58,003 alphaction.inference INFO: The following classes have no ground truth examples: [ 2  3 10 11 12]
2022-04-26 17:04:58,006 alphaction.inference INFO: ==> 0.002702 seconds to run_evaluator
2022-04-26 17:04:58,007 alphaction.inference INFO: { 'PascalBoxes_PerformanceByCategory/AP@0.5IOU/cut (an object)': 0.5754773263296191,
  'PascalBoxes_PerformanceByCategory/AP@0.5IOU/dip (an object)': nan,
  'PascalBoxes_PerformanceByCategory/AP@0.5IOU/handover to (a person)': nan,
  'PascalBoxes_PerformanceByCategory/AP@0.5IOU/heat (an object)': 0.6850093755362874,
  'PascalBoxes_PerformanceByCategory/AP@0.5IOU/holding for (a person)': nan,
  'PascalBoxes_PerformanceByCategory/AP@0.5IOU/pour (an object)': 0.1607142857142857,
  'PascalBoxes_PerformanceByCategory/AP@0.5IOU/roll (an object)': nan,
  'PascalBoxes_PerformanceByCategory/AP@0.5IOU/sprinkle (an object)': 0.037037037037037035,
  'PascalBoxes_PerformanceByCategory/AP@0.5IOU/squeeze (an object)': 0.08889511688797815,
  'PascalBoxes_PerformanceByCategory/AP@0.5IOU/stir (an object)': 0.25350688527159115,
  'PascalBoxes_PerformanceByCategory/AP@0.5IOU/transfer (an object)': 0.45100073538481333,
  'PascalBoxes_PerformanceByCategory/AP@0.5IOU/wrap (an object)': nan,
  'PascalBoxes_Precision/mAP@0.5IOU': 0.32166296602308747}
2022-04-26 17:05:08,077 alphaction.trainer INFO: eta: 5 days, 3:21:37  iter: 7020  loss_pose_action: 0.0000 (0.2603)  loss_object_interaction: 0.0000 (0.0003)  loss_person_interaction: 0.0000 (0.0003)  total_loss: 0.0002 (0.3333)  accuracy_pose_action: 1.0000 (0.8626)  accuracy_object_interaction: 1.0000 (0.9989)  accuracy_person_interaction: 1.0000 (0.9990)  time: 0.5030 (0.5087)  data: 0.0137 (0.0142)  lr: 0.000125  max mem: 2403
2022-04-26 17:05:18,215 alphaction.trainer INFO: eta: 5 days, 3:21:23  iter: 7040  loss_pose_action: 0.0000 (0.2595)  loss_object_interaction: 0.0000 (0.0003)  loss_person_interaction: 0.0000 (0.0003)  total_loss: 0.0007 (0.3324)  accuracy_pose_action: 1.0000 (0.8629)  accuracy_object_interaction: 1.0000 (0.9989)  accuracy_person_interaction: 1.0000 (0.9990)  time: 0.5054 (0.5087)  data: 0.0146 (0.0142)  lr: 0.000125  max mem: 2403
2022-04-26 17:05:28,386 alphaction.trainer INFO: eta: 5 days, 3:21:12  iter: 7060  loss_pose_action: 0.0000 (0.2588)  loss_object_interaction: 0.0000 (0.0003)  loss_person_interaction: 0.0000 (0.0003)  total_loss: 0.0004 (0.3315)  accuracy_pose_action: 1.0000 (0.8633)  accuracy_object_interaction: 1.0000 (0.9989)  accuracy_person_interaction: 1.0000 (0.9990)  time: 0.5107 (0.5087)  data: 0.0139 (0.0142)  lr: 0.000125  max mem: 2403
2022-04-26 17:05:38,546 alphaction.trainer INFO: eta: 5 days, 3:21:00  iter: 7080  loss_pose_action: 0.0000 (0.2581)  loss_object_interaction: 0.0000 (0.0003)  loss_person_interaction: 0.0000 (0.0003)  total_loss: 0.0004 (0.3306)  accuracy_pose_action: 1.0000 (0.8637)  accuracy_object_interaction: 1.0000 (0.9989)  accuracy_person_interaction: 1.0000 (0.9990)  time: 0.5119 (0.5087)  data: 0.0143 (0.0142)  lr: 0.000125  max mem: 2403
2022-04-26 17:05:48,796 alphaction.trainer INFO: eta: 5 days, 3:20:59  iter: 7100  loss_pose_action: 0.0000 (0.2573)  loss_object_interaction: 0.0000 (0.0003)  loss_person_interaction: 0.0000 (0.0003)  total_loss: 0.0001 (0.3296)  accuracy_pose_action: 1.0000 (0.8641)  accuracy_object_interaction: 1.0000 (0.9989)  accuracy_person_interaction: 1.0000 (0.9990)  time: 0.5129 (0.5087)  data: 0.0147 (0.0142)  lr: 0.000125  max mem: 2403
2022-04-26 17:05:48,799 alphaction.utils.checkpoint INFO: Saving checkpoint to data/output/resnet50_4x16f_baseline_robalo/model_0007100.pth
2022-04-26 17:05:49,065 alphaction.inference INFO: Start evaluation on lfv_robalo_val_ava_video dataset(135 videos).
2022-04-26 17:06:03,326 alphaction.inference INFO: Total inference time: 0:00:14.260809 (0.10563562181260851 s / video per device, on 1 devices)
2022-04-26 17:06:03,326 alphaction.inference INFO: performing ava evaluation.
2022-04-26 17:06:03,326 alphaction.inference INFO: Preparing results for AVA format
2022-04-26 17:06:03,343 alphaction.inference INFO: Evaluating predictions
2022-04-26 17:06:03,395 alphaction.inference INFO: ==> 0.0520744 seconds to write file /tmp/tmprdlt8civ
2022-04-26 17:06:03,395 alphaction.inference INFO: CATEGORIES (12):
[ {'id': 1, 'name': 'cut (an object)'},
  {'id': 2, 'name': 'holding for (a person)'},
  {'id': 3, 'name': 'handover to (a person)'},
  {'id': 4, 'name': 'squeeze (an object)'},
  {'id': 5, 'name': 'sprinkle (an object)'},
  {'id': 6, 'name': 'transfer (an object)'},
  {'id': 7, 'name': 'pour (an object)'},
  {'id': 8, 'name': 'heat (an object)'},
  {'id': 9, 'name': 'stir (an object)'},
  {'id': 10, 'name': 'wrap (an object)'},
  {'id': 11, 'name': 'roll (an object)'},
  {'id': 12, 'name': 'dip (an object)'}]
2022-04-26 17:06:03,396 alphaction.inference INFO: ==> 0.000474691 seconds to read file data/lfv_robalo/annotations/lfv_robalo_val.csv
2022-04-26 17:06:03,414 alphaction.inference INFO: ==> 0.0175881 seconds to convert groundtruth
2022-04-26 17:06:03,434 alphaction.inference INFO: ==> 0.0198495 seconds to read file /tmp/tmprdlt8civ
2022-04-26 17:06:03,766 alphaction.inference INFO: ==> 0.33185 seconds to convert detections
2022-04-26 17:06:03,766 alphaction.inference INFO: The following classes have no ground truth examples: [ 2  3 10 11 12]
2022-04-26 17:06:03,769 alphaction.inference INFO: ==> 0.00274968 seconds to run_evaluator
2022-04-26 17:06:03,769 alphaction.inference INFO: { 'PascalBoxes_PerformanceByCategory/AP@0.5IOU/cut (an object)': 0.5719984589257465,
  'PascalBoxes_PerformanceByCategory/AP@0.5IOU/dip (an object)': nan,
  'PascalBoxes_PerformanceByCategory/AP@0.5IOU/handover to (a person)': nan,
  'PascalBoxes_PerformanceByCategory/AP@0.5IOU/heat (an object)': 0.6734913793791826,
  'PascalBoxes_PerformanceByCategory/AP@0.5IOU/holding for (a person)': nan,
  'PascalBoxes_PerformanceByCategory/AP@0.5IOU/pour (an object)': 0.1372103386809269,
  'PascalBoxes_PerformanceByCategory/AP@0.5IOU/roll (an object)': nan,
  'PascalBoxes_PerformanceByCategory/AP@0.5IOU/sprinkle (an object)': 0.034482758620689655,
  'PascalBoxes_PerformanceByCategory/AP@0.5IOU/squeeze (an object)': 0.0948168054705585,
  'PascalBoxes_PerformanceByCategory/AP@0.5IOU/stir (an object)': 0.2620015582678589,
  'PascalBoxes_PerformanceByCategory/AP@0.5IOU/transfer (an object)': 0.44228117346966445,
  'PascalBoxes_PerformanceByCategory/AP@0.5IOU/wrap (an object)': nan,
  'PascalBoxes_Precision/mAP@0.5IOU': 0.3166117818306611}
2022-04-26 17:06:13,786 alphaction.trainer INFO: eta: 5 days, 3:20:29  iter: 7120  loss_pose_action: 0.0000 (0.2566)  loss_object_interaction: 0.0000 (0.0003)  loss_person_interaction: 0.0000 (0.0003)  total_loss: 0.0000 (0.3287)  accuracy_pose_action: 1.0000 (0.8645)  accuracy_object_interaction: 1.0000 (0.9989)  accuracy_person_interaction: 1.0000 (0.9990)  time: 0.5003 (0.5087)  data: 0.0142 (0.0142)  lr: 0.000125  max mem: 2403
2022-04-26 17:06:23,959 alphaction.trainer INFO: eta: 5 days, 3:20:19  iter: 7140  loss_pose_action: 0.0000 (0.2559)  loss_object_interaction: 0.0000 (0.0003)  loss_person_interaction: 0.0000 (0.0003)  total_loss: 0.0003 (0.3278)  accuracy_pose_action: 1.0000 (0.8648)  accuracy_object_interaction: 1.0000 (0.9989)  accuracy_person_interaction: 1.0000 (0.9990)  time: 0.5120 (0.5087)  data: 0.0142 (0.0142)  lr: 0.000125  max mem: 2403
2022-04-26 17:06:34,159 alphaction.trainer INFO: eta: 5 days, 3:20:12  iter: 7160  loss_pose_action: 0.0000 (0.2553)  loss_object_interaction: 0.0000 (0.0003)  loss_person_interaction: 0.0000 (0.0003)  total_loss: 0.0001 (0.3270)  accuracy_pose_action: 1.0000 (0.8650)  accuracy_object_interaction: 1.0000 (0.9989)  accuracy_person_interaction: 1.0000 (0.9990)  time: 0.5122 (0.5087)  data: 0.0142 (0.0142)  lr: 0.000125  max mem: 2403
2022-04-26 17:06:44,384 alphaction.trainer INFO: eta: 5 days, 3:20:08  iter: 7180  loss_pose_action: 0.0000 (0.2546)  loss_object_interaction: 0.0000 (0.0003)  loss_person_interaction: 0.0000 (0.0003)  total_loss: 0.0001 (0.3261)  accuracy_pose_action: 1.0000 (0.8653)  accuracy_object_interaction: 1.0000 (0.9989)  accuracy_person_interaction: 1.0000 (0.9990)  time: 0.5126 (0.5087)  data: 0.0143 (0.0142)  lr: 0.000125  max mem: 2403
2022-04-26 17:06:54,636 alphaction.trainer INFO: eta: 5 days, 3:20:07  iter: 7200  loss_pose_action: 0.0000 (0.2539)  loss_object_interaction: 0.0000 (0.0003)  loss_person_interaction: 0.0000 (0.0003)  total_loss: 0.0001 (0.3252)  accuracy_pose_action: 1.0000 (0.8657)  accuracy_object_interaction: 1.0000 (0.9989)  accuracy_person_interaction: 1.0000 (0.9990)  time: 0.5128 (0.5087)  data: 0.0143 (0.0142)  lr: 0.000125  max mem: 2403
2022-04-26 17:06:54,640 alphaction.utils.checkpoint INFO: Saving checkpoint to data/output/resnet50_4x16f_baseline_robalo/model_0007200.pth
2022-04-26 17:06:54,896 alphaction.inference INFO: Start evaluation on lfv_robalo_val_ava_video dataset(135 videos).
2022-04-26 17:07:09,451 alphaction.inference INFO: Total inference time: 0:00:14.555443 (0.10781809842145001 s / video per device, on 1 devices)
2022-04-26 17:07:09,452 alphaction.inference INFO: performing ava evaluation.
2022-04-26 17:07:09,452 alphaction.inference INFO: Preparing results for AVA format
2022-04-26 17:07:09,469 alphaction.inference INFO: Evaluating predictions
2022-04-26 17:07:09,521 alphaction.inference INFO: ==> 0.0522285 seconds to write file /tmp/tmpzxmx01og
2022-04-26 17:07:09,522 alphaction.inference INFO: CATEGORIES (12):
[ {'id': 1, 'name': 'cut (an object)'},
  {'id': 2, 'name': 'holding for (a person)'},
  {'id': 3, 'name': 'handover to (a person)'},
  {'id': 4, 'name': 'squeeze (an object)'},
  {'id': 5, 'name': 'sprinkle (an object)'},
  {'id': 6, 'name': 'transfer (an object)'},
  {'id': 7, 'name': 'pour (an object)'},
  {'id': 8, 'name': 'heat (an object)'},
  {'id': 9, 'name': 'stir (an object)'},
  {'id': 10, 'name': 'wrap (an object)'},
  {'id': 11, 'name': 'roll (an object)'},
  {'id': 12, 'name': 'dip (an object)'}]
2022-04-26 17:07:09,523 alphaction.inference INFO: ==> 0.00101948 seconds to read file data/lfv_robalo/annotations/lfv_robalo_val.csv
2022-04-26 17:07:09,541 alphaction.inference INFO: ==> 0.0182829 seconds to convert groundtruth
2022-04-26 17:07:09,562 alphaction.inference INFO: ==> 0.020077 seconds to read file /tmp/tmpzxmx01og
2022-04-26 17:07:09,909 alphaction.inference INFO: ==> 0.347191 seconds to convert detections
2022-04-26 17:07:09,909 alphaction.inference INFO: The following classes have no ground truth examples: [ 2  3 10 11 12]
2022-04-26 17:07:09,913 alphaction.inference INFO: ==> 0.00413465 seconds to run_evaluator
2022-04-26 17:07:09,914 alphaction.inference INFO: { 'PascalBoxes_PerformanceByCategory/AP@0.5IOU/cut (an object)': 0.5402894186068522,
  'PascalBoxes_PerformanceByCategory/AP@0.5IOU/dip (an object)': nan,
  'PascalBoxes_PerformanceByCategory/AP@0.5IOU/handover to (a person)': nan,
  'PascalBoxes_PerformanceByCategory/AP@0.5IOU/heat (an object)': 0.7039686826227047,
  'PascalBoxes_PerformanceByCategory/AP@0.5IOU/holding for (a person)': nan,
  'PascalBoxes_PerformanceByCategory/AP@0.5IOU/pour (an object)': 0.10599816849816848,
  'PascalBoxes_PerformanceByCategory/AP@0.5IOU/roll (an object)': nan,
  'PascalBoxes_PerformanceByCategory/AP@0.5IOU/sprinkle (an object)': 0.043478260869565216,
  'PascalBoxes_PerformanceByCategory/AP@0.5IOU/squeeze (an object)': 0.12487468671679199,
  'PascalBoxes_PerformanceByCategory/AP@0.5IOU/stir (an object)': 0.2783464087050949,
  'PascalBoxes_PerformanceByCategory/AP@0.5IOU/transfer (an object)': 0.4346230349304181,
  'PascalBoxes_PerformanceByCategory/AP@0.5IOU/wrap (an object)': nan,
  'PascalBoxes_Precision/mAP@0.5IOU': 0.318796951564228}
2022-04-26 17:07:19,953 alphaction.trainer INFO: eta: 5 days, 3:19:41  iter: 7220  loss_pose_action: 0.0000 (0.2535)  loss_object_interaction: 0.0000 (0.0003)  loss_person_interaction: 0.0000 (0.0003)  total_loss: 0.0004 (0.3247)  accuracy_pose_action: 1.0000 (0.8659)  accuracy_object_interaction: 1.0000 (0.9989)  accuracy_person_interaction: 1.0000 (0.9990)  time: 0.5012 (0.5087)  data: 0.0141 (0.0142)  lr: 0.000125  max mem: 2403
2022-04-26 17:07:30,122 alphaction.trainer INFO: eta: 5 days, 3:19:30  iter: 7240  loss_pose_action: 0.0000 (0.2529)  loss_object_interaction: 0.0000 (0.0003)  loss_person_interaction: 0.0000 (0.0003)  total_loss: 0.0003 (0.3239)  accuracy_pose_action: 1.0000 (0.8662)  accuracy_object_interaction: 1.0000 (0.9989)  accuracy_person_interaction: 1.0000 (0.9990)  time: 0.5125 (0.5087)  data: 0.0140 (0.0142)  lr: 0.000125  max mem: 2403
2022-04-26 17:07:40,338 alphaction.trainer INFO: eta: 5 days, 3:19:25  iter: 7260  loss_pose_action: 0.0000 (0.2522)  loss_object_interaction: 0.0000 (0.0003)  loss_person_interaction: 0.0000 (0.0003)  total_loss: 0.0001 (0.3230)  accuracy_pose_action: 1.0000 (0.8665)  accuracy_object_interaction: 1.0000 (0.9989)  accuracy_person_interaction: 1.0000 (0.9990)  time: 0.5151 (0.5087)  data: 0.0146 (0.0142)  lr: 0.000125  max mem: 2403
2022-04-26 17:07:50,518 alphaction.trainer INFO: eta: 5 days, 3:19:15  iter: 7280  loss_pose_action: 0.0000 (0.2515)  loss_object_interaction: 0.0000 (0.0003)  loss_person_interaction: 0.0000 (0.0003)  total_loss: 0.0002 (0.3221)  accuracy_pose_action: 1.0000 (0.8669)  accuracy_object_interaction: 1.0000 (0.9989)  accuracy_person_interaction: 1.0000 (0.9990)  time: 0.5111 (0.5087)  data: 0.0141 (0.0142)  lr: 0.000125  max mem: 2403
2022-04-26 17:08:00,680 alphaction.trainer INFO: eta: 5 days, 3:19:04  iter: 7300  loss_pose_action: 0.0000 (0.2508)  loss_object_interaction: 0.0000 (0.0003)  loss_person_interaction: 0.0000 (0.0003)  total_loss: 0.0001 (0.3213)  accuracy_pose_action: 1.0000 (0.8672)  accuracy_object_interaction: 1.0000 (0.9989)  accuracy_person_interaction: 1.0000 (0.9990)  time: 0.5066 (0.5087)  data: 0.0145 (0.0142)  lr: 0.000125  max mem: 2403
2022-04-26 17:08:00,684 alphaction.utils.checkpoint INFO: Saving checkpoint to data/output/resnet50_4x16f_baseline_robalo/model_0007300.pth
2022-04-26 17:08:00,958 alphaction.inference INFO: Start evaluation on lfv_robalo_val_ava_video dataset(135 videos).
2022-04-26 17:08:15,683 alphaction.inference INFO: Total inference time: 0:00:14.724353 (0.10906928027117693 s / video per device, on 1 devices)
2022-04-26 17:08:15,683 alphaction.inference INFO: performing ava evaluation.
2022-04-26 17:08:15,683 alphaction.inference INFO: Preparing results for AVA format
2022-04-26 17:08:15,700 alphaction.inference INFO: Evaluating predictions
2022-04-26 17:08:15,750 alphaction.inference INFO: ==> 0.0500484 seconds to write file /tmp/tmpt6rqg7d5
2022-04-26 17:08:15,750 alphaction.inference INFO: CATEGORIES (12):
[ {'id': 1, 'name': 'cut (an object)'},
  {'id': 2, 'name': 'holding for (a person)'},
  {'id': 3, 'name': 'handover to (a person)'},
  {'id': 4, 'name': 'squeeze (an object)'},
  {'id': 5, 'name': 'sprinkle (an object)'},
  {'id': 6, 'name': 'transfer (an object)'},
  {'id': 7, 'name': 'pour (an object)'},
  {'id': 8, 'name': 'heat (an object)'},
  {'id': 9, 'name': 'stir (an object)'},
  {'id': 10, 'name': 'wrap (an object)'},
  {'id': 11, 'name': 'roll (an object)'},
  {'id': 12, 'name': 'dip (an object)'}]
2022-04-26 17:08:15,751 alphaction.inference INFO: ==> 0.000473499 seconds to read file data/lfv_robalo/annotations/lfv_robalo_val.csv
2022-04-26 17:08:15,768 alphaction.inference INFO: ==> 0.0174003 seconds to convert groundtruth
2022-04-26 17:08:15,789 alphaction.inference INFO: ==> 0.0204582 seconds to read file /tmp/tmpt6rqg7d5
2022-04-26 17:08:16,120 alphaction.inference INFO: ==> 0.331215 seconds to convert detections
2022-04-26 17:08:16,120 alphaction.inference INFO: The following classes have no ground truth examples: [ 2  3 10 11 12]
2022-04-26 17:08:16,123 alphaction.inference INFO: ==> 0.0027194 seconds to run_evaluator
2022-04-26 17:08:16,124 alphaction.inference INFO: { 'PascalBoxes_PerformanceByCategory/AP@0.5IOU/cut (an object)': 0.7363498014805406,
  'PascalBoxes_PerformanceByCategory/AP@0.5IOU/dip (an object)': nan,
  'PascalBoxes_PerformanceByCategory/AP@0.5IOU/handover to (a person)': nan,
  'PascalBoxes_PerformanceByCategory/AP@0.5IOU/heat (an object)': 0.7598345988728069,
  'PascalBoxes_PerformanceByCategory/AP@0.5IOU/holding for (a person)': nan,
  'PascalBoxes_PerformanceByCategory/AP@0.5IOU/pour (an object)': 0.09444444444444446,
  'PascalBoxes_PerformanceByCategory/AP@0.5IOU/roll (an object)': nan,
  'PascalBoxes_PerformanceByCategory/AP@0.5IOU/sprinkle (an object)': 0.029411764705882353,
  'PascalBoxes_PerformanceByCategory/AP@0.5IOU/squeeze (an object)': 0.08021063258217406,
  'PascalBoxes_PerformanceByCategory/AP@0.5IOU/stir (an object)': 0.418402110709803,
  'PascalBoxes_PerformanceByCategory/AP@0.5IOU/transfer (an object)': 0.4960613263922793,
  'PascalBoxes_PerformanceByCategory/AP@0.5IOU/wrap (an object)': nan,
  'PascalBoxes_Precision/mAP@0.5IOU': 0.37353066845541866}
